> ChÃ o má»i ngÆ°á»i, trong Series Machine Learning From Scratch nÃ y mÃ¬nh vÃ  cÃ¡c báº¡n sáº½ cÃ¹ng Ä‘i triá»ƒn khai cÃ¡c thuáº­t toÃ¡n cÆ¡ báº£n trong há»c mÃ¡y Ä‘á»ƒ cÃ¹ng hiá»ƒu rÃµ hÆ¡n báº£n cháº¥t cá»§a cÃ¡c thuáº­t toÃ¡n nÃ y nhÃ©.
![image.png](https://images.viblo.asia/ff39f14b-6685-40fa-b21f-8d25a0682410.png)
# 1. VÃ¬ sao cáº§n giáº£m chiá»u dá»¯ liá»‡u?
NhÆ° má»i ngÆ°á»i Ä‘Ã£ biáº¿t, trong cÃ¡c bÃ i toÃ¡n há»c mÃ¡y thÃ¬ dá»¯ liá»‡u cÃ³ kÃ­ch thÆ°á»›c ráº¥t lá»›n. MÃ¡y tÃ­nh cÃ³ thá»ƒ hiá»ƒu vÃ  thá»±c thi cÃ¡c thuáº­t toÃ¡n trÃªn dá»¯ liá»‡u nÃ y, tuy nhiÃªn Ä‘á»‘i vá»›i con ngÆ°á»i Ä‘á»ƒ "nhÃ¬n" dá»¯ liá»‡u nhiá»u chiá»u tháº­t sá»± lÃ  ráº¥t khÃ³. VÃ¬ váº­y bÃ i toÃ¡n giáº£m chiá»u dá»¯ liá»‡u ra Ä‘á»i giÃºp Ä‘Æ°a ra cÃ¡i nhÃ¬n má»›i cho con ngÆ°á»i vá» dá»¯ liá»‡u nhiá»u chiá»u. NgoÃ i Ä‘á»ƒ trá»±c quan dá»¯ liá»‡u, cÃ¡c phÆ°Æ¡ng phÃ¡p giáº£m chiá»u dá»¯ liá»‡u cÃ²n giÃºp Ä‘Æ°a dá»¯ liá»‡u vá» má»™t khÃ´ng gian má»›i giÃºp khai phÃ¡ cÃ¡c thuá»™c tÃ­nh áº©n mÃ  trong chiá»u dá»¯ liá»‡u ban Ä‘áº§u khÃ´ng thá»ƒ hiá»‡n rÃµ, hoáº·c Ä‘Æ¡n giáº£n lÃ  giáº£m kÃ­ch thÆ°á»›c dá»¯ liá»‡u Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ thá»±c thi cho mÃ¡y tÃ­nh.
![image.png](https://images.viblo.asia/d96aa9fb-e529-4001-b97e-b2c47bd87720.png)
VÃ­ dá»¥ vá» táº­p dá»¯ liá»‡u huyá»n thoáº¡i Iris bao gá»“m 4 thuá»™c tÃ­nh vÃ  3 nhÃ£n tÆ°Æ¡ng á»©ng vá»›i 3 loÃ i hoa. Ráº¥t khÃ³ Ä‘á»ƒ cÃ³ thá»ƒ nháº­n biáº¿t ráº±ng 4 thuá»™c tÃ­nh nÃ y cÃ³ phÃ¢n tÃ¡ch vá»›i nhau theo má»—i loÃ i hay khÃ´ng vÃ¬ cáº§n biá»ƒu diá»…n khÃ´ng gian nÃ y trÃªn dá»¯ liá»‡u 4 chiá»u. VÃ¬ váº­y, thuáº­t toÃ¡n giáº£m chiá»u dá»¯ liá»‡u giÃºp Ä‘Æ°a vá» khÃ´ng gian 2 chiá»u Ä‘á»ƒ dá»… dÃ ng trá»±c quan hÃ³a trÃªn há»‡ toáº¡n Ä‘á»™ Oxy, Ä‘á»•i láº¡i lÃ  chÃºng ta pháº£i cháº¥p nháº­n máº¥t mÃ¡t Ä‘i má»™t lÆ°á»£ng thÃ´ng tin. VÃ  Ä‘Ã¢y lÃ  káº¿t quáº£: 

![image.png](https://images.viblo.asia/732faf5e-5198-41fd-b18e-bfe6a812f507.png)
NhÃ¬n vÃ o Ä‘Ã¢y chÃºng ta cÃ³ thá»ƒ dá»… dÃ ng phÃ¢n tÃ­ch hÆ¡n, cÃ³ thá»ƒ tháº¥y lá»›p nÃ o dá»… nháº§m láº«n vá»›i nhau, má»©c Ä‘á»™ tÃ¡ch biá»‡t giá»¯a cÃ¡c lá»›p,...

# 2. Thuáº­t toÃ¡n PCA (Principal component analysis)
Vá» máº·t Ã½ tÆ°á»Ÿng, thuáº­t toÃ¡n PCA tÃ¬m má»™t há»‡ khÃ´ng gian má»›i vÃ  tá»‘i Ä‘a hÃ³a phÆ°Æ¡ng sai dá»¯ liá»‡u cá»§a khÃ´ng gian má»›i Ä‘Ã³. Sau Ä‘Ã³ lá»±a chá»n ra n chiá»u cÃ³ phÆ°Æ¡ng sai lá»›n nháº¥t (giáº£ thuyáº¿t ráº±ng dá»¯ liá»‡u cÃ ng phÃ¢n tÃ¡n, phÆ°Æ¡ng sai cÃ ng lá»›n thÃ¬ cÃ ng cÃ³ giÃ¡ trá»‹) 
![image.png](https://images.viblo.asia/7be7df83-ad92-47c7-a49e-10f5b38d034f.png)

HÃ¬nh trÃªn Ä‘Ã¢y thá»ƒ hiá»‡n Ä‘Æ°á»£c giÃ¡ trá»‹ cá»§a phÆ°Æ¡ng sai, khi mÃ  Ä‘á»‘i vá»›i khÃ´ng gian ban Ä‘áº§u ($O_1$ xy) thÃ¬ pháº§n overlape cá»§a 2 lá»›p khi Ã¡nh xáº¡ lÃªn má»—i trá»¥c lÃ  khÃ¡ lá»›n. Khi Ä‘Ã³ khÃ´ng gian má»›i ($O_{2}$ zt) Ä‘Æ°á»£c  cá»±c Ä‘áº¡i hÃ³a phÆ°Æ¡ng sai cho trá»¥c $O_2$ z nÃªn khi Ã¡nh xáº¡ lÃªn Ä‘Ã¢y cÃ¡c lá»›p sáº½ tÃ¡ch biá»‡t vá»›i nhau khÃ¡ rÃµ. Äá»ƒ tÃ¬m Ä‘Æ°á»£c khÃ´ng gian má»›i, PCA Ä‘i tÃ¬m cÃ¡c trá»‹ riÃªng cá»§a ma tráº­n hiá»‡p phÆ°Æ¡ng sai cá»§a dá»¯ liá»‡u Ä‘áº§u vÃ o. CÃ¡c trá»‹ riÃªng thá»ƒ hiá»‡n phÆ°Æ¡ng sai cá»§a chiá»u dá»¯ liá»‡u má»›i, cÃ¡c vector riÃªng á»©ng vá»›i trá»‹ riÃªng Ä‘Ã³ tÆ°Æ¡ng á»©ng vá»›i má»™t khÃ´ng gian dá»¯ liá»‡u má»›i. Váº­y nÃªn sau bÆ°á»›c nÃ y chÃºng ta chá»n cÃ¡c vector riÃªng á»©ng vá»›i cÃ¡c trá»‹ riÃªng cÃ³ giÃ¡ trá»‹ lá»›n nháº¥t Ä‘á»ƒ Ä‘Æ°á»£c má»™t khÃ´ng gian má»›i Ä‘Æ°á»£c cá»±c Ä‘áº¡i hÃ³a phÆ°Æ¡ng sai. Chi tiáº¿t vá» pháº§n Ä‘áº¡i sá»‘ má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘á»c thÃªm táº¡i [Ä‘Ã¢y](https://machinelearningcoban.com/2017/06/15/pca/) 

Äá»ƒ lÃ m Ä‘Æ°á»£c viá»‡c nÃ y, thuáº­t toÃ¡n PCA cáº§n thá»±c hiá»‡n qua cÃ¡c bÆ°á»›c:
- Step 1: Chuáº©n bá»‹ dá»¯ liá»‡u cáº§n giáº£m chiá»u lÃ  X vá»›i kÃ­ch thÆ°á»›c (n_sample, n_feature), tÆ°Æ¡ng á»©ng má»—i hÃ ng lÃ  1 máº«u dá»¯ liá»‡u cÃ³ n_feature thuá»™c tÃ­nh
- Step 2: Trá»« má»—i Ä‘iá»ƒm dá»¯ liá»‡u cho vector ká»³ vá»ng: $X_k$ = $X_k$ - $X_{mean}$  vá»›i k = 1..n_sample vÃ  $X_{mean}$ lÃ  vector trung bÃ¬nh cá»§a táº¥t cáº£ cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u
- Step 3: TÃ­nh ma tráº­n hiá»‡u phÆ°Æ¡ng sai : S = $\frac{1}{n-sample}*X^T*X$
- Step 4: TÃ¬m trá»‹ riÃªng, vector riÃªng cá»§a ma tráº­n S
- Step 5: Láº¥y k trá»‹ riÃªng cÃ³ giÃ¡ trá»‹ lá»›n nháº¥t, táº¡o ma tráº­n U vá»›i cÃ¡c hÃ ng lÃ  cÃ¡c vector riÃªng á»©ng vá»›i k trá»‹ riÃªng Ä‘Ã£ chá»n
- Step 6: Ãnh xáº¡ khÃ´ng gian ban Ä‘áº§u sang khÃ´ng gian k chiá»u: $X_{new}$ = X*U 
- Note: Náº¿u khÃ´ng hiá»ƒu phÃ©p nhÃ¢n á»Ÿ Step 6 báº¡n cÃ³ thá»ƒ láº¥y tá»«ng máº«u dá»¯ liá»‡u nhÃ¢n vá»›i tá»«ng vector riÃªng, khi Ä‘Ã³ má»—i máº«u dá»¯ liá»‡u ban Ä‘áº§u sáº½ Ä‘Æ°á»£c nhÃ¢n vá»›i k vector nÃªn sáº½ cÃ³ k chiá»u.

# 3. Python implement:
Giáº£ sá»­ Ä‘Ã£ cÃ³ ma tráº­n dá»¯ liá»‡u X, mÃ¬nh sáº½ thá»±c hiá»‡n láº§n lÆ°á»£c tá»« Step 2 Ä‘áº¿n Step 6 cho má»i ngÆ°á»i tiá»‡n theo giá»i nhÃ©:
- Step 2: TÃ­nh vector trung bÃ¬nh, sau Ä‘Ã³ trá»« cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u cho vector Ä‘Ã³
```
mean = np.mean(X, axis=0)
X = X - mean
```
- Step 3: TÃ¬m ma tráº­n hiá»‡p phÆ°Æ¡ng sai
```
cov = X.T.dot(X) / X.shape[0]
```
- Step 4: TÃ­nh trá»‹ riÃªng, vector riÃªng
```
eigen_values, eigen_vectors, = np.linalg.eig(cov)
```
- Step 5: á» bÆ°á»›c nÃ y mÃ¬nh sáº½ láº¥y chá»‰ sá»‘ index cá»§a trá»‹ riÃªng tá»« lá»›n Ä‘áº¿n nhá», rá»“i chá»n k vector riÃªng táº¡o ma tráº­n U tÆ°Æ¡ng á»©ng vá»›i k index Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c
```
select_index = np.argsort(eigen_values)[::-1][:k]
U = eigen_vectors[:, select_index]
```
- Step 6: Ãnh xáº¡ dá»¯ liá»‡u sang khÃ´ng gian má»›i
```
X_new = X.dot(U)
```
VÃ  Ä‘Ã¢y lÃ  toÃ n bá»™ code mÃ¬nh cháº¡y thá»­ trÃªn táº­p dá»¯ liá»‡u Iris, má»i ngÆ°á»i cÃ³ thá»ƒ tÃ¬m tháº¥y táº­p dá»¯ liá»‡u nÃ y trÃªn Google nhÃ©
```
import numpy as np
import pandas as pd
fá»m matplotlib import pyplot as plt

class PCA:
  def __init__(self, n_dimention: int):
    self.n_dimention = n_dimention

  def fit_transform(self, X):
    mean = np.mean(X, axis=0)
    X = X - mean
    cov = X.T.dot(X) / X.shape[0] 
    eigen_values, eigen_vectors, = np.linalg.eig(cov)
    select_index = np.argsort(eigen_values)[::-1][:self.n_dimention]
    U = eigen_vectors[:, select_index]
    X_new = X.dot(U)
    return X_new
    
if __name__ == "__main__":
  df = pd.read_csv(r"/content/iris.csv")
  X = df[["sepal_length",	"sepal_width",	"petal_length",	"petal_width"]].to_numpy()
  Y = df["species"].to_numpy()

  pca = PCA(n_dimention=2)
  new_X = pca.fit_transform(X)
  
  for label in set(Y):
    X_class = new_X[Y == label]
    plt.scatter(X_class[:, 0], X_class[:, 1], label=label)

  plt.legend()
```
VÃ  Ä‘Ã¢y lÃ  káº¿t quáº£ khi chuyá»ƒn táº­p dá»¯ liá»‡u Iris tá»« 4 chiá»u vá» 2 chiá»u nhÃ©
![image.png](https://images.viblo.asia/ca147212-4f09-4648-b744-84f4d85a35e7.png)
# 4. Káº¿t luáº­n
Trong bÃ i viáº¿t nÃ y mÃ¬nh vÃ  cÃ¡c báº¡n Ä‘Ã£ cÃ¹ng tÃ¬m hiá»ƒu qua vá» cÃ¡ch mÃ  thuáº­t toÃ¡n PCA hoáº¡t Ä‘á»™ng trong bÃ i toÃ¡n giáº£m chiá»u dá»¯ liá»‡u cá»§ng nhÆ° cÃ¡ch triá»ƒn khai nÃ³ báº±ng ngÃ´n ngá»¯ Python. Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ Ä‘á»c bÃ i viáº¿t vÃ  nhá»› Upvote cho mÃ¬nh náº¿u tháº¥y bÃ i viáº¿t há»¯u Ã­ch nhÃ©.ğŸ˜€
# TÃ i liá»‡u tham kháº£o:
- [BÃ i 27: Principal Component Analysis (pháº§n 1/2)](https://machinelearningcoban.com/2017/06/15/pca/)