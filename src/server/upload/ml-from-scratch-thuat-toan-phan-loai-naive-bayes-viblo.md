> ChÃ o má»i ngÆ°á»i, trong Series `Machine Learning From Scratch` nÃ y mÃ¬nh vÃ  cÃ¡c báº¡n sáº½ cÃ¹ng Ä‘i triá»ƒn khai cÃ¡c thuáº­t toÃ¡n cÆ¡ báº£n trong há»c mÃ¡y Ä‘á»ƒ cÃ¹ng hiá»ƒu rÃµ hÆ¡n báº£n cháº¥t cá»§a cÃ¡c thuáº­t toÃ¡n nÃ y nhÃ©.
## 1. LÃ½ thuyáº¿t vá» Ä‘á»‹nh lÃ½ Bayes
![image.png](https://images.viblo.asia/b1e62856-84b0-4bf1-a03b-4277a3614ead.png)
TrÃªn Ä‘Ã¢y lÃ  cÃ´ng thá»©c xÃ¡c suáº¥t Ä‘iá»u kiá»‡n, Ä‘Æ°á»£c sá»­ dá»¥ng khi tÃ­nh xÃ¡c xuáº¥t xáº£y ra biáº¿n cá»‘ phá»¥ thuá»™c vÃ o biáº¿n cá»‘ Ä‘Ã£ xáº£y ra. VÃ­ dá»¥: XÃ¡c xuáº¥t báº¡n RÆ°áº£ chÃ©n nÃ³ sáº½ khÃ¡c vá»›i xÃ¡c suáº¥t báº¡n Rá»­a chÃ©n khi cÃ³ bá»‘ máº¹ á»Ÿ nhÃ , vÃ  khÃ¡c vá»›i xÃ¡c suáº¥t báº¡n rá»©a chÃ©n khi khÃ´ng cÃ³ máº¹ á»Ÿ nhÃ . Khi Ä‘Ã³, Ä‘á»ƒ phÃ¹ há»£p vá»›i cÃ´ng thá»©c trÃªn thÃ¬ A lÃ  biáº¿n cá»‘ báº¡n rá»­a chÃ©n, B lÃ  biáº¿n cá»‘ máº¹ báº¡n cÃ³ á»Ÿ nhÃ  thÃ¬ cÃ´ng thá»©c trÃªn thá»ƒ hiá»‡n cho xÃ¡c xuáº¥t báº¡n rá»­a chÃ©n khi máº¹ cÃ³ á»Ÿ nhÃ , cá»¥ thá»ƒ nÃ³ sáº½ phá»¥ thuá»™c vÃ o:
- P(B): XÃ¡c xuáº¥t máº¹ á»Ÿ nhÃ 
- P(B|A) XÃ¡c xuáº¥t máº¹ á»Ÿ nhÃ  khi báº¡n rá»­a chÃ©n
- P(A): XÃ¡c suáº¥t báº¡n rá»­a chÃ©n

![image.png](https://images.viblo.asia/f35a83a2-c7c2-4d99-9320-8b65c2663ef8.png)

CÃ²n Ä‘Ã¢y lÃ  Ä‘á»‹nh lÃ½ Bayes Ä‘Æ°á»£c sá»­ dá»¥ng trong thuáº­t toÃ¡n phÃ¢n loáº¡i. Khi sá»­ dá»¥ng cÃ´ng thá»©c nÃ y Ä‘á»ƒ phÃ¢n lá»›p chÃºng ta giáº£ sá»­ cÃ¡c thuá»™c tÃ­nh phÃ¢n lá»›p Ä‘á»™c láº­p vá»›i nhau (Chá»‰ lÃ  giáº£ sá»­ thÃ´i cÃ²n trong thá»±c táº¿ hÆ¡i khÃ³). Biáº¿n cá»‘ dá»¯ liá»‡u Ä‘áº§u vÃ o thuá»™c vá» má»™t lá»›p nÃ o Ä‘Ã³ trong n lá»›p Ä‘Æ°á»£c xem lÃ  má»™t há»‡ Ä‘áº§y Ä‘á»§ ($B_1$, $B_2$, ..., $B_n$). A lÃ  biáº¿n cá»‘ má»™t dá»¯ liá»‡u nÃ o Ä‘Ã³ cáº§n dá»¯ Ä‘oÃ¡n, váº­y Ä‘á»ƒ phÃ¢n loáº¡i má»™t dá»¯ liá»‡u nÃ o Ä‘Ã³ cÃ¹ng Ä‘á»“ng nghÄ©a vá»›i viá»‡c tÃ­nh P($B_k$, A) vá»›i k=1, 2, ...n vÃ  dá»¯ liá»‡u A sáº½ thuá»™c vÃ o lá»›p cÃ³ xÃ¡c suáº¥t cao nháº¥t vá»«a tÃ¬m Ä‘Æ°á»£c.
LÆ°u Ã½: Biáº¿n cá»‘ A lÃ  má»™t Ä‘iá»ƒm dá»¯ liá»‡u cáº§n dá»± Ä‘oÃ¡n, váº­y nÃªn sáº½ A cÃ³ thá»ƒ cÃ³ nhiá»u thuá»™c tÃ­nh vÃ  vÃ¬ cÃ¡c thuá»™c tÃ­nh nÃ y Ä‘á»™c láº­p (giáº£ sá»­ á»Ÿ trÃªn) nÃªn sáº½ Ä‘Æ°á»£c tÃ­nh theo cÃ´ng thá»©c nhÃ¢n dÆ°á»›i Ä‘Ã¢y.

![image.png](https://images.viblo.asia/e89b0f1b-7947-4888-b798-c55bcb028c69.png)

## 2. VÃ­ dá»¥

![image.png](https://images.viblo.asia/7e29dd63-45d1-4fa9-9e82-478adcaf8fb4.png)

Vá»›i dá»¯ liá»‡u trÃªn mÃ¬nh cáº§n dá»± Ä‘oÃ¡n nhÃ£n C1 hay C2 cho Ä‘iá»ƒm dá»¯ liá»‡u X($A_1$=1, $A_2$=1). MÃ¬nh sáº½ Ä‘i tÃ­nh cÃ¡c xÃ¡c suáº¥t thÃ nh pháº§n cá»§a cÃ´ng thá»©c á»Ÿ trÃªn trÆ°á»›c khi tÃ­nh P($C_1$| X) vÃ  P($C_2$| X)
- P($C_1$) = 3/5 = 0.6
- P($C_2$) = 2/5 = 0.4
- P(X | $C_1$) = P($A_1$=1| $C_1$)*P($A_2$=1| $C_1$)  = 1/3 * 1/3 = 1/9
- P(X | $C_2$) = P($A_1$=1| $C_2$)*P($A_2$=1| $C_2$)  = 1/2 * 1/2 = 0.25

Cuá»‘i cÃ¹ng lÃ  2 xÃ¡c xuáº¥t quan trá»ng nháº¥t Ä‘á»ƒ so sÃ¡nh (folllow theo Ä‘Ãºng nhÆ° cÃ´ng thá»©c Bayes):
- P($C_1$| X) = $\frac{P(C_1).P(X|C_1)}{P(X|C_1).P(C_1) + P(X|C_2).P(C_2)}$ = 0.4
- P($C_2$| X) = $\frac{P(C_2).P(X|C_2)}{P(X|C_1).P(C_1) + P(X|C_2).P(C_2)}$ = 0.6

Váº­y Ä‘iá»ƒm dá»¯ liá»‡u X($A_1$=1, $A_2$=1) thuá»™c lá»›p $C_2$

LÆ°u Ã½: Äá»ƒ phÃ¢n lá»›p chÃºng ta chá»‰ cáº§n tÃ­nh pháº§n tá»­ sá»‘ vÃ  so sÃ¡nh vÃ¬ pháº§n máº«u sá»‘ lÃ  giá»‘ng nhau. Tuy nhiÃªn á»Ÿ Ä‘Ã¢y mÃ¬nh váº«n tÃ­nh Ä‘áº§y Ä‘á»§ Ä‘á»ƒ thá»ƒ hiá»‡n biáº¿n cá»‘ dá»¯ liá»‡u thuá»™c vá» tá»«ng lá»›p lÃ  há»‡ Ä‘áº§y Ä‘á»§ nÃªn sáº½ cÃ³ tá»•ng báº±ng 1.
## 3. Code python
Ok sau khi hiá»ƒu lÃ½ thuyáº¿t chÃºng ta sáº½ cÃ¹ng Ä‘i implement thuáº­t toÃ¡n phÃ¢n lá»›p Naive Bayes báº±ng ngÃ´n ngá»¯ python nhÃ©
Äáº§u tiÃªn chÃºng ta sáº½ Ä‘i khá»Ÿi táº¡o dá»¯ liá»‡u nhÆ° báº£ng trÃªn
```
X = np.array([
    [1, 0],
    [0, 0],
    [2, 1],
    [1, 2],
    [0, 1],
])

y = np.array(["C1", "C1", "C2", "C2", "C1"])
```
Äá»u tiÃªn lÃ  hÃ m tÃ­nh xÃ¡c xuáº¥t cá»§a lá»›p  P($C_1$) vÃ   P($C_2$). HÃ m nÃ y Ä‘Æ¡n giáº£n lÃ  Ä‘áº¿m sá»‘ láº§n xuáº¥t hiá»‡n cá»§a lá»›p Ä‘Ã³ tá»ng táº­p dá»¯ liá»‡u.
```
def get_class_prob(y: np.array):
  prob = {}
  n = len(y)
  for c in np.unique(y):
    prob[c] = np.count_nonzero(y == c) / n
  return prob

get_class_prob(y)

# output {'C1': 0.6, 'C2': 0.4} 
```
Tiáº¿p theo lÃ  hÃ m tÃ­nh xÃ¡c suáº¥t cá»§a táº­p thuá»™c tÃ­nh theo Ä‘iá»u kiá»‡n lÃ  cÃ¡c lá»›p Ä‘á»ƒ tÃ­nh  P(X | $C_2$),  P(X | $C_2$)
```
def get_condition_prob(X: np.ndarray, y: np.array, record: np.array):
  prob = {}
  for c in np.unique(y):
    # Lay tat ca record co class Ci
    class_records = X[y == c]
    n = class_records.shape[0]
    # Tinh xac xuat cua diem du lieu trong lop Ci theo cong thuc nhan
    prob[c] = np.prod(np.count_nonzero(class_records == record, axis=0)/n)
  return prob

input = np.array([1, 1])
get_condition_prob(X, y, input)

# output: {'C1': 0.1111111111111111, 'C2': 0.25}
```
HÃ m nÃ y sáº½ tráº£ vá» xÃ¡c xuáº¥t Ä‘iá»u kiá»‡n cá»§a record Ä‘áº§u vÃ o theoc cÃ¡c lá»›p cÃ³ trong táº­p dá»¯ liá»‡u. Äáº§u tiÃªn táº¡i dÃ²ng 5, chÃºng ta sáº½ láº¥y cÃ¡c dá»¯ liá»‡u theo Ä‘iá»u kiá»‡n lÃ  lá»›p hiá»‡n táº¡i Ä‘ang tÃ­nh. Sau Ä‘Ã³ táº¡i dÃ²ng 8, chÃºng ta sáº½ tÃ¬m sá»‘ láº§n xuáº¥t hiá»‡n cá»§a cÃ¡c thuá»™c tÃ­nh cÃ³ trong record (np.count_nonzero), tá»« Ä‘Ã³ tÃ­nh xÃ¡c xuáº¥t (/n) vÃ  tÃ­ch cá»§a chÃºng Ä‘á»ƒ Ä‘Æ°á»£c kÃªt quáº£ (np.prod)

VÃ  cuá»‘i dÃ¹ng lÃ  xÃ¢y dá»± hÃ m Ä‘á»ƒ dá»± Ä‘oÃ¡n cho má»™t Ä‘iá»ƒm dá»¯ liá»‡u
```
def predict(X: np.ndarray, y: np.array, record: np.array):
  class_prob = get_class_prob(y)
  condition_prob = get_condition_prob(X, y, record)
  prob = {}
  for c in np.unique(y):
    prob[c] = (class_prob[c]*condition_prob[c])/ np.sum([class_prob[ci]*condition_prob[ci] for ci in class_prob])
  return prob

input = np.array([1, 1])
predict(X, y, input)

#output: {'C1': 0.39999999999999997, 'C2': 0.6}
```
HÃ m nÃ y tÃ­nh xÃ¡c xuáº¥t Ä‘iá»ƒm dá»¯ liá»‡u Ä‘áº§u vÃ o thuá»™c vá» má»—i lá»›p dá»±a vÃ o cÃ´ng thá»©c á»Ÿ trÃªn, tá»« Ä‘Ã³ cÃ³ thá»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Ã³ thuá»™c vÃ o lá»›p nÃ o.

VÃ  Ä‘Ã¢y lÃ  full code:
```
import numpy as np

def get_class_prob(y: np.array):
  prob = {}
  n = len(y)
  for c in np.unique(y):
    prob[c] = np.count_nonzero(y == c) / n
  return prob

def get_condition_prob(X: np.ndarray, y: np.array, record: np.array):
  prob = {}
  for c in np.unique(y):
    # Lay tat ca record co class Ci
    class_records = X[y == c]
    n = class_records.shape[0]
    # Tinh xac xuat cua diem du lieu trong lop Ci theo cong thuc nhan
    prob[c] = np.prod(np.count_nonzero(class_records == record, axis=0)/n)
  return prob

def predict(X: np.ndarray, y: np.array, record: np.array):
  class_prob = get_class_prob(y)
  condition_prob = get_condition_prob(X, y, record)
  prob = {}
  for c in np.unique(y):
    prob[c] = (class_prob[c]*condition_prob[c])/ np.sum([class_prob[ci]*condition_prob[ci] for ci in class_prob])
  return prob

if __name__ == "__main__":
  X = np.array([
    [1, 0],
    [0, 0],
    [2, 1],
    [1, 2],
    [0, 1],
  ])

  y = np.array(["C1", "C1", "C2", "C2", "C1"])
  input = np.array([1, 1])
  result = predict(X, y, input)
  print(result)
```
## 4. Káº¿t luáº­n
Trong bÃ i viáº¿t nÃ y mÃ¬nh vÃ  cÃ¡c báº¡n Ä‘Ã£ cÃ¹ng tÃ¬m hiá»ƒu qua vá» cÃ¡ch mÃ  thuáº­t toÃ¡n Naive Bayes hoáº¡t Ä‘á»™ng trong bÃ i toÃ¡n phÃ¢n loáº¡i. Tuy nhiÃªn, Ä‘á»ƒ cÃ³ thá»ƒ xÃ¢y dá»±ng má»™t chÆ°Æ¡ng trÃ¬nh hoÃ n thiá»‡n Ä‘á»ƒ phÃ¢n loáº¡i cáº§n pháº£i tá»‘i Æ°u hÃ³a vÃ  chá»‰nh sá»­a ráº¥t nhiá»u thá»© nhÆ° tá»‘i Æ°u tá»‘c Ä‘á»™ cháº¡y cá»§a code, xá»­ lÃ½ cÃ¡c trÆ°á»ng há»£p Ä‘áº·c biá»‡t (VÃ­ dá»¥ vá»›i cÃ´ng thá»©c á»Ÿ trÃªn náº¿u cÃ³ má»™t xÃ¡c xuáº¥t Ä‘iá»u kiá»‡n cá»§a thuá»™c tÃ­nh theo lá»›p báº±ng 0 thÃ¬ dáº«n Ä‘áº¿n xÃ¡c xuáº¥t cuá»‘i cÃ¹ng cá»§ng sáº½ báº±ng 0, cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o cÃ¡c giáº£i quyáº¿t á»Ÿ [Ä‘Ã¢y](https://www.atoti.io/articles/how-to-solve-the-zero-frequency-problem-in-naive-bayes/))
Cuá»‘i cÃ¹ng, cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ Ä‘á»c bÃ i viáº¿t vÃ  nhá»› Upvote cho mÃ¬nh náº¿u tháº¥y bÃ i viáº¿t há»¯u Ã­ch nhÃ©.ğŸ˜€