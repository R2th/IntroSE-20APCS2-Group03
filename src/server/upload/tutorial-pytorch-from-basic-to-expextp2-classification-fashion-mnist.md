# Tá»•ng quan
ChÃºng ta Ä‘Ã£ há»c qua lÃ­ thuyáº¿t cÆ¡ báº£n á»Ÿ pháº§n má»™t rá»“i, bÃ¢y giá» báº¯t tay vÃ o code thá»­ 1 model Ä‘Æ¡n giáº£n. á» Ä‘Ã¢y mÃ¬nh sáº½ phÃ¢n loáº¡i quáº§n Ã¡o dá»±a trÃªn bá»™ dá»¯ liá»‡u [Fashion-MNIST.](https://github.com/zalandoresearch/fashion-mnist)<br>
MNIST thá»±c sá»± khÃ¡ táº§m thÆ°á»ng vá»›i cÃ¡c máº¡ng neuron networks mÃ  báº¡n cÃ³ thá»ƒ dá»… dÃ ng Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c lá»›n hÆ¡n 97%. Fashion-MNIST lÃ  má»™t táº­p há»£p cÃ¡c hÃ¬nh áº£nh quáº§n Ã¡o cÃ³ tá»· lá»‡ 28x28 mÃ u xÃ¡m. NÃ³ phá»©c táº¡p hÆ¡n MNIST, vÃ¬ váº­y nÃ³ thá»ƒ hiá»‡n tá»‘t hÆ¡n hiá»‡u suáº¥t thá»±c táº¿ trong máº¡ng cá»§a báº¡n vÃ  thá»ƒ hiá»‡n tá»‘t hÆ¡n cÃ¡c táº­p dá»¯ liá»‡u mÃ  báº¡n sáº½ sá»­ dá»¥ng trong tháº¿ giá»›i thá»±c.<br>
![](https://images.viblo.asia/f88ad97d-1ab2-4e2f-9ca2-82f021192d1b.png)<br>
Tiáº¿p theo chÃºng ta cáº§n pháº£i Ä‘á» ra phÆ°Æ¡ng hÆ°á»›ng tiáº¿p cáº­n.
# PhÆ°Æ¡ng hÆ°á»›ng tiáº¿p cáº­n
Theo kinh nghiá»‡m code gÃ  cá»§a mÃ¬nh ğŸ˜‚ thÃ¬ cÃ¡ch tiáº¿p cáº­n bÃ i toÃ¡n theo cÃ¡c bÆ°á»›c sau Ä‘Ã¢y :<br>
B1. Thu tháº­p, chuáº©n bá»‹ dá»¯ liá»‡u<br>
*     ğŸ‘CÃ³ thá»ƒ thu tháº­p dá»¯ liá»‡u tá»« cÃ¡c nguá»“n cÃ³ sáº¯n trÃªn máº¡ng: dataset cÃ³ sáº¯n, crawl data,...
*     ğŸ‘DÃ¹ng GAN (Generative Adversarial Networks) Ä‘á»ƒ sinh thÃªm dá»¯ liá»‡u
B2. Xá»­ lÃ­, chuáº©n hÃ³a dá»¯ liá»‡u<br>
*     ğŸ‘ Augmentation data: resize, flip, affine,crop,...
*     ğŸ‘ Normalize data
*     ğŸ‘Chia lÃ m 2 táº­p dá»¯ liá»‡u : training Ä‘á»ƒ huáº¥n luyá»‡n vÃ  testing Ä‘á»ƒ kiá»ƒm tra káº¿t quáº£
B3. Viáº¿t class Dataset, DataLoader<br>
* CÃ¡i nÃ y mÃ¬nh sáº½ giÃ nh pháº§n riÃªng Ä‘á»ƒ nÃ³i vá» pháº§n nÃ y. CÃ¡c báº¡n cÃ³ thá»ƒ xem [pháº§n3](https://translate.google.com/?hl=vi&sl=auto&tl=en&text=b%C3%A0i%20t%E1%BA%ADp&op=translate) Ä‘á»ƒ hiá»ƒu thÃªm.

B4. Build model<br>
*     ğŸ‘ XÃ¢y dá»±ng kiáº¿n trÃºc model
*     ğŸ‘ Viáº¿t hÃ m loss, optimizer. CÃ³ thá»ƒ sá»­ dá»¥ng hÃ m cÃ³ sáºµn cho khá»e
B5. Train model<br>
*     ğŸ‘ Viáº¿t hÃ m train
*     ğŸ‘ Train trÃªn CPU hoáº·c GPU
B6. Test, visualize<br>

VÃ¬ bÃ i nÃ y Ä‘Æ¡n giáº£n Ä‘á»ƒ tiáº¿p cáº­n pytorch nÃªn mÃ¬nh chá»‰ code theo cÃ¡c bÆ°á»›c sau:<br>
*     ğŸ‘ Load dá»¯ liá»‡u FASHION-MNIST
*     ğŸ‘ Build model
*     ğŸ‘ Train model
*     ğŸ‘ Test, visualize
# Load dá»¯ liá»‡u FASHION-MNIST
Äáº§u tiÃªn cáº§n load dataset tá»« thÆ° viá»‡n torchvision
```
import torch
from torchvision import datasets, transforms
import helper

# Define a transform to normalize the data
transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize((0.5,), (0.5,))])
# Download and load the training data
trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)

# Download and load the test data
testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)
```
Táº¡i Ä‘Ã¢y báº¡n cÃ³ thá»ƒ xem má»™t sá»‘ bá»©c áº£nh trong dataset <br>
```
# example of loading the fashion mnist dataset
from matplotlib import pyplot
# plot first few images
for i in range(9):
	# define subplot
	pyplot.subplot(330 + 1 + i)
	# plot raw pixel data
	pyplot.imshow(trainset[i], cmap=pyplot.get_cmap('gray'))
# show the figure
pyplot.show()
```
![](https://images.viblo.asia/7cbac509-49e3-4ceb-bb9b-11ffdfc85676.png)

# Build model
Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t<br>
```
import torch
from torch import nn, optim
import torch.nn.functional as F
```
XÃ¢y dá»±ng kiáº¿n trÃºc máº¡ng <br>
```
# TODO: Define your network architecture here
class Classifier(nn.Module):
    def __init__(self):
        super().__init__()
        # Because images is 28x28 which is a total of 784 pixels
        self.fc1 = nn.Linear(784, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 64)
        # 10 classes
        self.fc4 = nn.Linear(64, 10)
        
    def forward(self, x):
        # make sure input tensor is flattened
        x = x.view(x.shape[0], -1)
        
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.relu(self.fc3(x))
        x = F.log_softmax(self.fc4(x), dim=1)
        
        return x
```
# Train model
Äáº§u tiÃªn báº¡n cáº§n Ä‘á»‹nh nghÄ©a hÃ m loss (vÃ­ dá»¥ nhÆ° *nn.CrossEntropyLoss* hoáº·c *nn.NLLLoss* hoáº·c *nn.MSELoss*) vÃ  hÃ m optimizers (vÃ­ dá»¥ nhÆ° *optim.SGD* hoáº·c *optim.Adam*).<br>
```
# TODO: Create the network, define the criterion and optimizer
model = Classifier()
criterion = nn.NLLLoss()
optimizer = optim.Adam(model.parameters(), lr=0.003)
```
Sau Ä‘Ã³ viáº¿t hÃ m train <br>
```
# TODO: Train the network here
epochs = 5
def train():
    for e in range(epochs):
        running_loss = 0.0
        for images, labels in trainloader:
            log_ps = model(images)
            loss = criterion(log_ps, labels)
            
            optimizer.zero_grad() # cáº§n xÃ³a gradient sau má»—i vÃ²ng láº·p Ä‘á»ƒ trÃ¡nh chá»“ng cháº¥t gradient vÃ¬ Ä‘áº¡o hÃ m hÃ m há»£p cá»§a backpropagation
            loss.backward() # backpropagation process
            optimizer.step() # update weights

            running_loss += loss.item()
        else:
            print(f"Training loss: {running_loss/len(trainloader)}")
```
QuÃ¡ trÃ¬nh training<br>
![](https://images.viblo.asia/709a67b5-f98c-456b-bdd4-da390a06eed8.png)

# Test , visualize
Visualize káº¿t quáº£ <br>
```
%matplotlib inline
%config InlineBackend.figure_format = 'retina'

import helper

# Test out your network!

dataiter = iter(testloader)
images, labels = dataiter.next()
img = images[1]

# TODO: Calculate the class probabilities (softmax) for img
ps = torch.exp(model(img))

# Plot the image and probabilities
helper.view_classify(img, ps, version='Fashion')
```
![](https://images.viblo.asia/2c3d196e-6778-445f-ac75-3045527d5e58.png)

# Exercise
Link all code : https://github.com/trungtruc123/Pytorch/blob/master/intro-to-pytorch/Part%204%20-%20Fashion-MNIST%20(Solution).ipynb<br>
CÃ¡c báº¡n cÃ³ thá»ƒ táº£i 8 bÃ i táº­p tá»« [link ](https://github.com/trungtruc123/Pytorch/tree/master/intro-to-pytorch) Ä‘á»ƒ lÃ m. BÃ i táº­p gá»“m 2 pháº§n exercises vÃ  solutions. LÃ m exercise xong má»›i quay láº¡i xem Ä‘Ã¡p Ã¡n nhÃ© ğŸ˜‚.
ChÃºc cÃ¡c báº¡n thÃ nh cÃ´ng!