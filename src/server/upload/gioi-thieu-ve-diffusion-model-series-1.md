# 1 . Gi·ªõi thi·ªáu v·ªÅ s∆° l∆∞·ª£c v·ªÅ diffusion model
Trong b√†i vi·∫øt n√†y m√¨nh s·∫Ω gi·ªõi thi·ªáu s∆° qua v·ªÅ m√¥ h√¨nh v√† ·ª©ng d·ª•ng c·ªßa ch√∫ng quan tr·ªçng h∆°n h·∫øt v·ªõi nh·ªØng th√†nh c√¥ng c·ªßa m√¥ h√¨nh diffussion hi·ªán nay v·ªÅ c√°c lƒ©nh v·ª±c **Text2Img** . Ch√∫ng ƒëang tr·ªü n√™n r·∫•t ph·ªï bi·∫øn khi ƒë∆∞·ª£c gi·ªõi thi·ªáu v√† ch√∫ √Ω ƒë·∫øn t·ª´ cu·ªëi nƒÉm 2021 ƒë·∫øn nƒÉm nay.

ƒê√°ng ch√∫ √Ω l√† v·ªõi c√°c m√¥ h√¨nh n·ªïi ti·∫øng hi·ªán nay nh∆∞ *stable diffusion* hay *Dall-e* v√† n·ªïi b·∫≠t nh·∫•t l√† ph·∫ßn m·ªÅn *mjourney* ƒë√£ t·∫°o n√™n nhi·ªÅu k·ª≥ t√≠ch trong lƒ©nh v·ª±c v·∫Ω tranh . C√≥ th·ªÉ n√≥i **Text2Img**  ƒë√°ng l√† ch·ªß ƒë·ªÅ h√≥t nh·∫•t hi·ªán nay c·ªßa m·ªçi paper . Trong b√†i b√°o n√†y ch√∫ng ta s·∫Ω c·ªë g·∫Øng hi·ªÉu chi ti·∫øt v·ªÅ h·ªôp ƒëen ƒë·∫±ng sau ch√∫ng.

Trong qu√° kh·ª© 2 m√¥ h√¨nh sinh l√† VAE v√† GAN ƒë√£ th·ªëng tr·ªã r·∫•t r·∫•t l√¢u , h∆°n h·∫øt l√† GAN . M·∫∑c d√π GAN ho·∫°t ƒë·ªông t·ªët v·ªõi r·∫•t nhi·ªÅu c√°c ·ª©ng d·ª•ng kh√°c nhau tuy nhi√™n r·∫•t kh√≥ ƒë·ªÉ ƒë√†o t·∫°o do b·ªã v√°n ƒë·ªÅ vanishing gradients t·ª©c khi ƒë√†o t·∫°o m·∫°ng l·ªõn v√† khi backward gradient tri·ªát ti√™u khi·∫øn ch√∫ng r·∫•t nh·ªè r·ªìi nh√¢n v·ªõi nhau c√†ng nh·ªè h∆°n n√™n c√°c parameter kh√≥ c√≥ th·ªÉ h·ªçc ƒë∆∞·ª£c th√¥ng tin v√† kh√¥ng th·ªÉ c·∫≠p nh·∫≠t ch√≠nh x√°c.H∆°n n·ªØa ƒë·∫ßu ra ·∫£nh c·ªßa GAN s·∫Ω thi·∫øu ƒëi t√≠nh ƒëa d·∫°ng phong ph√∫. b·∫°n c√≥ th·ªÉ hi·ªÉu ƒë·ªÉ t·∫°o ra m·ªôt h√¨nh ·∫£nh ƒëa d·∫°ng ƒë·ªôc ƒë√°o v√† phong ph√∫ n·ªôi dung GAN kh√¥ng ph·∫£i l√† m·ªôt gi·∫£i ph√°p h∆°n n·ªØa 

Kh√°i ni·ªám ch√≠nh trong M√¥ h√¨nh Diffussion l√† n·∫øu ch√∫ng ta c√≥ th·ªÉ x√¢y d·ª±ng m·ªôt m√¥ h√¨nh h·ªçc t·∫≠p c√≥ th·ªÉ t√¨m hi·ªÉu s·ª± ph√¢n r√£ c√≥ h·ªá th·ªëng c·ªßa th√¥ng tin do nhi·ªÖu, th√¨ c√≥ th·ªÉ ƒë·∫£o ng∆∞·ª£c qu√° tr√¨nh v√† do ƒë√≥, kh√¥i ph·ª•c th√¥ng tin tr·ªü l·∫°i t·ª´ nhi·ªÖu. Kh√°i ni·ªám n√†y t∆∞∆°ng t·ª± nh∆∞ VAE ·ªü ch·ªó n√≥ c·ªë g·∫Øng t·ªëi ∆∞u h√≥a m·ªôt h√†m m·ª•c ti√™u b·∫±ng c√°ch chi·∫øu d·ªØ li·ªáu v√†o kh√¥ng gian ti·ªÅm ·∫©n tr∆∞·ªõc ti√™n v√† sau ƒë√≥ kh√¥i ph·ª•c d·ªØ li·ªáu tr·ªü l·∫°i tr·∫°ng th√°i ban ƒë·∫ßu. Tuy nhi√™n, thay v√¨ h·ªçc c√°ch ph√¢n ph·ªëi d·ªØ li·ªáu, h·ªá th·ªëng h∆∞·ªõng t·ªõi vi·ªác l·∫≠p m√¥ h√¨nh m·ªôt lo·∫°t c√°c ph√¢n ph·ªëi nhi·ªÖu trong Chu·ªói Markov v√† ‚Äúgi·∫£i m√£‚Äù d·ªØ li·ªáu b·∫±ng c√°ch ho√†n t√°c / l√†m thay ƒë·ªïi d·ªØ li·ªáu theo ki·ªÉu ph√¢n c·∫•p.
# 2. N·ªÅn t·∫£ng
Ng∆∞·ªùi ƒë·ªçc ph·∫£i c√≥ n·ªÅn t·∫£ng v·ªÅ c√°c m√¥ h√¨nh sinh c∆° b·∫£n nh∆∞ h√†m loss ELBO, VAE v√† Hierarchical VAE.

H√¨nh 1: M√¥ t·∫£ qu√° tr√¨nh ho·∫°t ƒë·ªông diffussion model

![image.png](https://images.viblo.asia/54b4d5f8-1744-4077-bda4-c61c41dd1efc.png)

Nh√¨n v√†o h√¨nh ·∫£nh ta c√≥ th·ªÉ nh·∫≠n ra diffusion model t√¨m c√°ch l√†m nhi·ªÖu (noise) c√°c ·∫£nh theo T b∆∞·ªõc th·ªùi gian . T ·∫£nh cu·ªëi c√πng l√† m·ªôt Gaussion ti√™u chu·∫©n v·ªõi $N(0,I)$ t·ª©c l√† m·ªôt ·∫£nh nhi·ªÖu ho√†n to√†n kh√¥ng c√≥ th√¥ng tin ch√≠nh x√°c .

Nh·∫Øc l·∫°i v·ªÅ VAE th√¨ ta c√≥ th·ªÉ hi·ªÉu r·∫±ng ch√∫ng c·ªë g·∫Øng ho√†n to√†n t·∫°o ·∫£nh d·ª±a kh·∫£ nƒÉng t√°i t·∫°o c·ªßa ·∫£nh (ELBO) v√† KL ( ƒëo kho·∫£ng c√°ch gi·ªØa hai ph√¢n ph·ªëi bi·∫øn ti·ªÅm ·∫©n z t·∫°o ra t·ª´ gi√° tr·ªã d·ª± ƒë√≥an v√† ·∫£nh gi√° tr·ªã g·ªëc)

Ch√∫ng ta s·∫Ω nh·∫Øc l·∫°i ch√∫t v·ªÅ ELBO,VAE,v√† Hierarchical ƒë·ªÉ c√°c b·∫°n c√≥ th·ªÉ n·∫Øm r√µ h∆°n chi ti·∫øt v·ªÅ ch√∫ng nh∆∞ v·∫≠y ch√∫ng ta c≈©ng c√≥ th·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ diffussion model . Do b√†i vi·∫øt n√†y c·ª±c k·ª≥ d√†i n√™n m√¨nh s·∫Ω c·ªë g·∫Øng ƒë·∫øn nh·ªØng ƒëo·∫°n quan tr·ªçng nh·∫•t.

## 2.1 ELBO
·ªû ƒë√¢y ch√∫ng ta s·∫Ω c·ªë g·∫Øng quan s√°t ƒë∆∞·ª£c c√°c bi·∫øn ti·ªÅm ·∫©n z v√† d·ªØ li·ªáu x input l√† m·∫≠t ƒë·ªô ph√¢n ph·ªëi $p(x,z)$ .

H√¨nh 2: M√¥ t·∫£ qu√° tr√¨nh ho·∫°t ƒë·ªông VAE

![](https://images.viblo.asia/10d03d38-ea07-4179-9ea3-ede7657ee6be.png)

Nh·ªõ l·∫°i r·∫±ng ch√∫ng ta s·∫Ω c·ªë g·∫Øng t·ªëi ∆∞u h√≥a output $x$ ti·ªám c·∫≠n v·ªõi t·∫•t c·∫£ quan s√°t input $x$ . Hay c√≤n g·ªçi l√† "likehood-based" . T√¨m c√°ch t√≠nh x√°c su·∫•t cao nh·∫•t c·ªßa output x d·ª±a tr√™n quan s√°t x v√† bi·∫øn ti·ªÅm ·∫©n z. L∆∞u √Ω v·ªÅ VAE bi·∫øm ti·ªÅm ·∫©n z lu√¥n c√≥ chi·ªÅu hay s·ªë l∆∞·ª£ng n√∫t ·∫©n b√© h∆°n ƒë·∫ßu v√†o v√† ra c·ªßa d·ªØ li·ªáu.
Ch√∫ng ta s·∫Ω vi·∫øt ng·∫Øn g·ªçn b·ªõi to√°n h·ªçc v·ªõi c√¥ng th·ª©c m√¥ t·∫£ $p(x)$, ph∆∞∆°ng tr√¨nh s·ªë (1)

$$ p(x)= \int  p(x,z)dz $$                                                                                                            

Ho·∫∑c ch√∫ng ta c√≥ th·ªÉ vi·∫øt l·∫°i nh∆∞ sau d·ª±a tr√™n quy t·∫Øc chu·ªói x√°c su·∫•t:
$$ P(X,Y) =  P(X|Y). P(Y) $$
 $$P(Y) = P(X,Y)/ P(X|Y)$$
Suy ra , ph∆∞∆°ng tr√¨nh s·ªë (2)
$$p(x) = \frac{p(x,z)}{p(z|x)}$$

Tuy nhi√™n vi·ªác t√≠nh to√°n v√† t·ªëi ∆∞u h√≥a $p(x)$ d·ª±a tr√™n ph∆∞∆°ng tr√¨nh (1) l√† r·∫•t kh√≥ v√¨ ta ph·∫£i t√≠nh c·∫£ bi·∫øn ti·ªÅm ·∫©n z , h∆°n n·ªØa c≈©ng v√¨ v·∫≠y m√† ph∆∞∆°ng tr√¨nh (2) ta kh√¥ng c√≥ c√°ch ƒë·ªÉ t√≠nh $p(z|x)$ . Tuy nhi√™n n·∫øu ta k·∫øt h·ª£p c·∫£ hai ch√∫ng l·∫°i v·ªõi nhau ta s·∫Ω ƒë∆∞·ª£c ELBO t·ªëi ƒë√£ h√≥a kh·∫£ nƒÉng t√°i t·∫°o c·ªßa output x d·ª±a tr√™n input x v√† bi·∫øn ti·ªÅm ·∫©n z. Khi ƒë√≥ vi·ªác t·ªëi ƒëa h√≥a kh·∫£ nƒÉng x·∫£y ra c·ªßa ELBO s·∫Ω l√† t·ªëi ∆∞u h√≥a m√¥ h√¨nh lu√¥n.

ƒê·ªÉ ‚Äúl∆∞·ª£ng ho√°‚Äù l∆∞·ª£ng th√¥ng tin n√†y th√†nh s·ªë l∆∞·ª£ng bit, Shannon ƒë·ªÅ xu·∫•t m·ªôt h√†m ‚Äúl∆∞·ª£ng tin‚Äù, hay s·∫Ω ch·ªß y·∫øu ƒë·ªÅ c·∫≠p ƒë·∫øn v·ªõi t√™n entropy, nh·∫±m t√≠nh to√°n s·ªë ‚Äúbit‚Äù th√¥ng tin nh·∫≠n ƒë∆∞·ª£c ·ª©ng v·ªõi m·ªôt (nh√≥m) s·ª± ki·ªán  n√†o ƒë√≥.
$$I ( X ) = - \log _ { 2 } p ( X )$$
T·ª´ ƒë√≥ ta c√≥ th·ªÉ vi·∫øt ELBO , ph∆∞∆°ng tr√¨nh s·ªë (3) nh∆∞ sau , nh∆∞ tr√™n h√¨nh v·∫Ω ta kh√¥ng th·ªÉ t√≠nh ƒë∆∞·ª£c $p(z|x)$ tuy nhi√™n vi·ªác t√≠nh to√°n encoder $q_{\phi}(z|x)$ th√¨ ho√†n to√†n c√≥ th·ªÉ l∆∞u √Ω s·∫Ω c√≥ parameter ${\phi}$.






$$\log p ( x ) \geq E _ { q _ {\phi} ( z | x ) } [ \log \frac { p ( x , z ) } { q _ {\phi } ( z | x ) } ]$$

·ªû ƒë√¢y, $q_{\phi}(z|x)$ c√≥ tham s·ªë ${\phi}$ m√† ch√∫ng t√¥i t√¨m c√°ch t·ªëi ∆∞u h√≥a. Ch√∫ng ta s·∫Ω h·ªçc c√°ch tham s·ªë h√≥a ${\phi}$ sao cho t√≠nh g·∫ßn ƒë√∫ng $p (z | x)$. Ch√∫ng ta s·∫Ω ƒëi·ªÅu ch·ªânh c·∫≠p nh·∫≠t c√°c  ${\phi}$ ƒë·ªÉ t·ªëi ∆∞u h√≥a kh·∫£ nƒÉng ELBO khi ƒë√≥ ta s·∫Ω c√≥ ƒë∆∞·ª£c m√¥ h√¨nh sinh c√≥ ·∫£nh d·ª± ƒëo√°n gi·ªëng v·ªõi ƒë·∫ßu v√†o x . B√¢y gi·ªù ch√∫ng ta s·∫Ω t√¨m c√°ch t·ªëi ∆∞u h√≥a ELBO ƒë·ªÉ hi·ªÉu t·∫°i sao ta c·∫ßn t·ªëi ∆∞u h√≥a ch√∫ng, ch·ª©ng minh ph∆∞∆°ng tr√¨nh s·ªë (3)
T·ª´ ph∆∞∆°ng tr√¨nh s·ªë (1) ta c√≥:

(4)
$$ p(x)= \int  p(x,z).1dz $$
(5)
$$= \log \int \frac { p ( x , z ) q _ { \phi } ( z | x ) } { q _ { \phi } ( z | x ) } d z$$
m√† (6)
$$1 =\frac{q_{\phi}(z|x)}{q_{\phi}(z|x)}$$
T·ª´ ƒë·ªãnh nghƒ©a c·ªßa k·ª≥ v·ªçng
$$E ( x ) =  \int x p ( x ) d x$$

$$= \log  \int \frac { p ( x , z )} {q _ { \phi } ( z | x ) } { q _ { \phi } ( z | x ) } d z$$
suy ra , ph∆∞∆°ng tr√¨nh s√¥ (7) t·ª´ ƒë·ªãnh nghƒ©a c·ªßa k·ª≥ v·ªçng
$$= \log E _ { q_\phi } ( z | x ) [ \frac { p ( x , z ) } { q _ { \phi} ( z | x ) } ]$$
√Åp d·ª•ng b·∫•t ƒë·∫≥ng th·ª©c jense, ph∆∞∆°ng tr√¨nh s·ªë (8)-ELBO:
$$\geq E _ { q _ {\phi } ( z | z ) } [ \log \frac { p ( x , z ) } { q _ { \phi } ( z | x ) } ]$$

**$\text{BDT jense √°p d·ª•ng v·ªõi h√†m l·ªìi  v·ªõi quy t·∫Øc }\ F(E[x]) >=  E[F(x)]$**

H√¨nh 3: Ch·ª©ng minh ng·∫Øn g·ªçn ƒë·∫±ng sau BƒêT (b·∫•t ƒë·∫≥ng th·ª©c)

![image.png](https://images.viblo.asia/eeb1143a-e13e-488c-b07a-23498158f36f.png)

Nh√¨n v√†o hƒ©nh v·∫Ω ta th·∫•y ngay c√°c b·∫°n c≈©ng c√≥ th·ªÉ th·ª≠ v·ªõi $F(x)$ v√† $x$ b·∫•t k·ª≥ th√¨ ch√∫ng lu√¥n t·ªìn t·∫°i quy lu·∫≠t nh∆∞ v·∫≠y.
T·ª´ ph∆∞∆°ng tr√¨nh s·ªë (7) ta s·ª≠ d·ª•ng **BDT jense** nh∆∞ng ch√∫ng ta ch∆∞a th·ª±c s·ª± hi·ªÉu r√µ chi ti·∫øt t·∫°i sao ELBO l·∫°i l√† m·ª•c ti√™u t·ªëi ∆∞u h√≥a kh·∫£ nƒÉng x·∫£y ra khi sinh ra ·∫£nh v√¨ v·∫≠y ta d·ª±a tr√™n ph∆∞∆°ng tr√¨nh s·ªë (2) ta c√≥:

(9)
$$\log p ( x ) = \log p ( x )$$
(10)
$$\log p ( x ) =  \int \log p ( x )q _ { \phi } ( z | x ) d z$$

Do 
$$\int q _ { \phi } ( z | x ) d z = 1$$
(11)
$$=E _ { q_ { \phi} ( z | x ) } [ \log p ( x ) ]$$
√Åp d·ª•ng ph∆∞∆°ng tr√¨nh s·ªë (2) ta c√≥ ƒë∆∞·ª£c (11)
$$= E _ { q_ { \phi} ( z | x ) }[ \log \frac { p ( x , z ) } { p ( z | x ) } ]$$
(12) 
$$= E _ { q_ { \phi} ( z | x ) }[ \log \frac { p ( x , z ) { q_ { \phi} ( z | x ) }} { p ( z | x ){ q_ { \phi} ( z | x ) } } ]$$

**(*)**

$\text{B·∫£ng c√¥ng th·ª©c logarit}\ { \log _ { a } b + \log _ { a } c } { = \log _ { a } ( b . c ) } \text{ v√† }$
$$ {E[X+Y] = \int^‚àû_{-‚àû}\int^‚àû_{-‚àû}}$$

$$= \int^‚àû_{-‚àû}\int^‚àû_{-‚àû}xf(x,y)dydx + \int^‚àû_{-‚àû}\int^‚àû_{-‚àû}yf(x,y)dxdy$$

$$= \int^‚àû_{-‚àû}xf_X(x)dx + \int^‚àû_{-‚àû}yf_Y(y)dy$$

$$= E[X] + E[Y]$$



(13)
$$= E _ { q _ {\phi } \left ( z | z \right ) } \left [ \log \frac { p \left ( x , z \right ) } { q _ {\phi  } \left ( z | x \right ) } \right ] + E _ { q _ {\phi } \left ( z | z \right ) } \left [ \log \frac { q _ {\phi  } \left ( z | x \right ) } { p \left ( z | x \right ) } \right ]$$
(14) ƒê·ªãnh nghƒ©a KL

![image.png](https://images.viblo.asia/a42ab712-3275-4935-938a-7154498b5cf3.png)

N√≥i c√°ch kh√°c ƒë√≥ l√† s·ª± kh√°c bi·ªát gi·ªØa logarit **$P$** v√† **$Q$**.trong ƒë√≥ k·ª≥ v·ªçng ƒë∆∞·ª£c th·ª±c hi·ªán b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c x√°c su·∫•t **$P$**..

$$= E _ { q _ {\phi } } ( z | x) \left [ \log \frac { p \left ( x , z \right ) } { q _ {\phi  } \left ( z | x \right ) } \right ]+ D _ { K L } ( q _ { \phi } ( z | x ) \| p ( z | x ) )$$
(15) Do KL lu√¥n >=0
$$\geq E _ { q _ {\phi } } ( z | x)\left [ \log \frac { p \left ( x , z \right ) } { q _ {\phi  } \left ( z | x \right ) } \right ]$$

T·ª´ ph∆∞∆°ng tr√¨nh s·ªë 14 ta c√≥ th·ªÉ r√∫t ra hai k·∫øt lu·∫≠n v·ªÅ ELBO

1. ELBO lu√¥n l√† gi·ªõi h·∫°n d∆∞·ªõi v√† ch√∫ng s·∫Ω k·∫øt h·ª£p v·ªõi Kl ƒë·ªÉ c√≥ kh·∫£ nƒÉng ∆∞·ªõc t√≠nh t·ªët nh·∫•t ·∫£nh t·∫°o ra m·ª•c ti√™u maximun ch√∫ng
2.  Kl l√† kho·∫£ng c√°ch ph√¢n ph·ªëi gi·ªØa $p(x,z)$ v·ªõi $q_{\phi} (z|x)$ ƒëi·ªÅu ki·ªán t·ªët nh·∫•t l√† b·∫±ng 0 t·ª©c minimun ch√∫ng . T·ªëi ∆∞u h√≥a tham s√¥ ${\phi}$ sao cho  $q_{\phi} (z|x)$ v√†  $p(x,z)$ b·∫±ng nhau nh∆∞ng r·∫•t kh√≥ v√¨ ta kh√¥ng th·ªÉ truy c·∫≠p v√†o $p(z|x)$ n√™n ta c√≥ th·ªÉ bi·∫øt r·∫±ng c√†ng t·ªëi ∆∞u h√≥a ELBO th√¨ c√†ng g·∫ßn v·ªõi ·∫£nh g·ªëc , ·∫£nh t·∫°o ra c≈©ng s·∫Ω ƒë·∫°t ti·ªám c·∫≠n ·∫£nh g·ªëc

## 2.2 VAE
M√¨nh c≈©ng kh√¥ng ng·ªù vi·∫øt b·∫±ng latex kh√≥ v√† d√†i n·ªØa , mong m·ªçi ng∆∞·ªùi ·ªßng h·ªô m√¨nh . ·ªû ƒë√¢y ch√∫ng ta s·∫Ω ƒë√†o s√¢u h∆°n ti·∫øp v√†o ELBO d·ª±a tr√™n ph∆∞∆°ng tr√¨nh (15)

(16)
$$E _ { q \phi \left ( z | z \right ) } \left [ \log \frac { p \left ( x , z \right ) } { q _ { \phi } \left ( z | x \right ) } \right ] = E _ { q \phi \left ( z | z \right ) } \left [ \log \frac { p _ { \theta } \left ( x | z \right ) p \left ( z \right ) } { q _ { \phi } \left ( z | x \right ) } \right ]$$
$\text{L∆∞u √Ω r·∫±ng l√† quy t·∫Øc chu·ªói x√°c su·∫•t}\ P(x,z) = P(x|z).p(z)$

D·ª±a tr√™n (*)

(17)

$$E _ { q _ { \phi } ( z | x ) } [ \log p _ { \theta } ( x | z ) ] + E _ { q _ { \phi } ( z | x ) } [ \log \frac { p ( z ) } { q _ { \phi } ( z | x ) } ]$$


(18) ƒê·ªãnh nghƒ©a KL

$$= E _ { q _ { \phi } ( z | x ) } [ \log p _ { \theta } ( x | z ) ] - D _ { K L } ( q _ { \phi } ( z | x ) \| p ( z ) )$$
$$= E _ { q _ { \phi } ( z | x ) } [ \log p _ { \theta } ( x | z ) ] - 0 . 5 * \sum _ { i = 1 } ^ { N } 1 + \log \left ( z _ { \sigma _ { i } } ^ { 2 } \right ) - z _ { \mu _ { i } } ^ { 2 } - z _ { \sigma _ { i } } ^ { 2 }$$
Trong ph∆∞∆°ng tr√¨nh (18) c√≥ 2 ƒëo·∫°n do·∫°n 1 ti·∫øng anh g·ªçi l√† reconstruction term ƒëo·∫°n 2 g·ªçi l√† prior matching term . 
·ªü ƒëo·∫°n 1 ${p_{\theta}(x|z)}$ v·ªõi tham s·ªë ${_\theta}$ chuy·ªÉn c√°c bi·∫øn ti·ªÅm ·∫©n z th√†nh ·∫£nh d·ª± ƒëo√°n ch√∫ng ta c√≥ g·ªçi l√† decoder.
·ªü ƒëo·∫°n 2 ${q_{\phi}(z|x)}$ v·ªõi tham s·ªë  ${_\phi}$ l√† chuy·ªÉn ƒë·∫ßu v√†o th√†nh c√°c ti·ªÅm ·∫©n z ch√∫ng ta g·ªçi l√† encoder.

ƒêo·∫°n 1 reconstruction term ƒëo l∆∞·ªùng kh·∫£ nƒÉng t√°i t·∫°o ·∫£nh t·ª´ bi·∫øn ti·ªÅm ·∫©n z c·ªë g·∫Øng t·ªëi ∆∞u h√≥a max ƒë·ªÉ ti·ªám c·∫ßn sao cho gi·ªëng ·∫£nh g·ªëc nh·∫•t c√≥ th·ªÉ
ƒêo·∫°n 2 ƒëo l∆∞∆°ng kho·∫£ng c√°ch 2 ph√¢n ph·ªëi t·∫°o bi·∫øn ti·ªÅm ·∫©n z t·ª´ ƒë·∫ßu v√†o encoder so v·ªõi ti·ªÅm ·∫©n g·ªëc . ƒê·ªÉ √Ω ti·ªÅm ·∫©n g·ªëc p(z) (gaussian ti√™u chu·∫©n) l√† c√≥ s·∫µn kh√¥ng c√≥ tham s·ªë ta c·∫ßn t·ªëi ƒëa h√≥a min

T·ª´ ƒë√≥ ta c√≥ th·ªÉ nh·∫≠n ra r·∫±ng c√≥ 2 tham s·ªë  ${_\theta}$ v√† ${_\phi}$ v√† h∆°n h·∫øt b·ªô encoder ƒë∆∞·ª£c tham s·ªë v·ªõi ${_\phi}$ , decoder l√† ${_\theta}$ . B·ªô encoder c·ªßa VAE d·ª±a tr√™n ph√¢n ph·ªëi ƒëa bi·∫øn Gaussian v·ªõi hi·ªáp ph∆∞∆°ng sai ƒë∆∞·ªùng ch√©o hay ta c√≥ th·ªÉ vi·∫øt.

(19) Normal v·ªõi trung b√¨nh u v√† ƒë·ªô l·ªách chu·∫©n
$$q _ { \phi } ( z | x ) = N ( z ; \mu _ { \phi } ( x ) , \sigma _ { \phi } ^ { 2 } ( x ) I )$$

(20) Gaussian ti√™u chu·∫©n v·ªõi trung b√¨nh = 0 v√† ƒë·ªô l·ªách chu·∫©n l√† 1
$$p ( z ) = N ( z ; 0 , I )$$
Ti·∫øp theo ch√∫ng ta s·∫Ω t·∫°o ra bi·∫øn ti·ªÅm ·∫©n z t·ª´ trung b√¨nh m·∫´u v√† ƒë·ªô l·ªách chu·∫©n ƒë√¥i l√∫c g·ªçi l√† k·ªπ v·ªçng v√† ph∆∞∆°ng sai, l∆∞u √Ω r·∫±ng trung b√¨nh m·∫´u c√≥ tham s·ªë phi v√† ƒë·ªô l·ªách chu·∫©n c≈©ng v·∫≠y . Gi·∫£i ph√°p l√† reparameter trick hay c√≤n g·ªçi l√† th·ªß thu·∫≠t reparameter.
Th·ªß thu·∫≠t reparameterization vi·∫øt l·∫°i m·ªôt bi·∫øn ng·∫´u nhi√™n nh∆∞ m·ªôt h√†m x√°c ƒë·ªãnh c·ªßa m·ªôt bi·∫øn noise; ƒëi·ªÅu n√†y cho ph√©p optimizer c√°c thu·∫≠t ng·ªØ kh√¥ng ng·∫´u nhi√™n th√¥ng qua gradient. V√≠ d·ª•: c√°c m·∫´u t·ª´ ph√¢n ph·ªëi ${q_{\phi}(z|x)}$ v·ªõi tham s·ªë ${\phi}$ vi·∫øt l·∫°i th√†nh.
(21)
$$z = \mu _ { \phi } ( x ) + \sigma _ { \phi } ( x ) \odot \epsilon \quad \text { w i t h } \epsilon \sim N ( \epsilon ; 0 , I )$$
Do ƒë√≥ ta c√≥ th·ªÉ hi·ªÉu ph·∫ßn encoder s·∫Ω t·ªëi ∆∞u h√≥a $\mu _ { \phi } ( x )$ v·ªõi tham s·ªë ${\phi}$ v√† $\sigma _ { \phi } ( x )$ c≈©ng v·ªõi tham s·ªë ${\phi}$.
Sau khi b·∫°n train VAE qua encoder t·∫°o ra ti·ªÅm ·∫©n z vi·ªác t·∫°o ra ·∫£nh m·ªõi s·∫Ω th√¥ng qua b·ªô gi·∫£i m√£ v·ªõi tham s·ªë theta . ·ªü ƒë√¢y ph·∫ßn decoder v·ªõi tham s·ªë theta s·∫Ω th√¥ng qua  $P(x|z)$ hay l√† kho·∫£ng c√°ch mse gi·ªØa ·∫£nh ƒë√†o t·∫°o v√† ·∫£nh g·ªëc.

## 2.3 Hierarchical Variational Autoencoders
Ch√∫ng ta s·∫Øp xong series 1 v√† m√¨nh nh·∫≠n th·∫•y r·∫±ng kh√¥ng ƒë·ªß th·ªùi gian ƒë·ªÉ g√≥i g·ªçn diffussion model trong m·ªôt b√†i vi·∫øt n√™n m√¨nh s·∫Ω chia l√†m nhi·ªÅu series ƒë·ªÉ m·ªçi ng∆∞·ªùi c√≥ th·ªÉ hi·ªÉu v√† ph·∫ßn n√†y l√† ph·∫ßn r·∫•t quan tr·ªçng . C√≥ th·ªÉ hi·ªÉu m√¥ h√¨nh n√†y v·∫´n l√† VAE nh∆∞ng s·ª≠ d·ª•ng nhi·ªÅu bi·∫øn ti·ªÅm ·∫©n h∆°n b·∫°n ƒë·ª´ng nh·∫ßm l·∫´n s·ªë n√∫t ·∫©n m√† l√† s·ªë l∆∞·ª£ng ti·ªÅm ·∫©n thay v√¨ 1 gi·ªëng nh∆∞ vae ta c√≥ th·ªÉ c√≥ r·∫•t nhi·ªÅu ti·ªÅm ·∫©n z . Theo nh∆∞ ta c√≥ th·ªÉ hi·ªÉu ch√∫ng nhi·ªÅu nh∆∞ v√¢y.

![image.png](https://images.viblo.asia/62777ffc-7270-43c3-b991-903d8a8ab84c.png)

Ta c√≥ th·ªÉ hi·ªÉu x l√† ƒë·∫ßu v√†o v√† $z_{t}$ l√† bi·∫øm ti·ªÅn ·∫©n, $z_{t+1}$ l√† bi·∫øn ti·ªÅm ·∫©n ti·∫øp theo v√† $Z_{T}$ l√† ·∫£nh d·ª± ƒëo√°n t·ª´ b·ªô decoder.
Nh√¨n v√†o ·∫£nh ta c√≥ ƒëo√°n ra ngay **encoder** s·∫Ω ƒë∆∞·ª£c vi·∫øt l√†:
 $$q _ { \phi } ( z _ { 1 } | x )(q _ { \phi } ( z _ { 2 } | z_{1} )(q _ { \phi } ( z _ { 3 } | z_{2} )....(q _ { \phi } ( z _ { T } | z_{T-1} )$$
 n·∫øu b·∫°n ƒë·ªÉ √Ω ch√∫ng ch√≠nh l√† chu·ªói markovian v√† n·∫øu b·∫°n ƒë√£ quen thu·ªôc v·ªõi markovian th√¨ c√≥ th·ªÉ vi·∫øt l·∫°i th√†nh
 
 (22)
 
 $$q _ { \phi } ( z _ { 1 } | x ) \prod _ { t = 2 } ^ { T } q _ { \phi } ( z _ { t } | z _ { t - 1 } )$$
 Sau khi ƒë√£ xong encoder ch√∫ng ta s·∫Ω ti·∫øp t·ª•c v·ªõi **decoder**:
 

  $$p ( z _ { T } ) p _ { \theta } ( x | z _ { 1 } )p _ { \theta } ( z_{1} | z _ { 2 } )p _ { \theta } ( z_{2} | z _ { 3 } ).........(p _ { \theta } ( z _ { T-1 } | z_{T} )$$
  vi·∫øt l·∫°i ƒë∆°n gi·∫£n th√†nh.
  
  (23)
 
  $$p ( z _ { T } ) p _ { \theta } ( x | z _ { 1 } ) \prod _ { t = 2 } ^ { T } p _ { \theta } ( z _ { t - 1 } | z _ { t } )$$
  T·ª´ (22) v√† (23)  v√† √°p d·ª•ng ph∆∞∆°ng tr√¨nh s·ªë (8) ta c√≥:
  $$E _ { q _ { \phi } ( z _ { 1 } | x ) \prod _ { t = 2 } ^ { T } q _ { \phi } ( z _ { t } | z _ { t - 1 } ) } [ \log \frac { p ( z _ { T } ) p _ { \theta } ( x | z _ { 1 } ) \prod _ { t = 2 } ^ { T } p _ { \theta } ( z _ { t - 1 } | z _ { t } ) } { q _ { \phi } ( z _ { 1 } | x ) \prod _ { t = 2 } ^ { T} q _ { \phi } ( z _ { t } | z _ { t - 1 } ) } ]$$
 
## 2.4 K·∫øt lu·∫≠n
Qua series n√†y c√°c b·∫°n ƒë√£ hi·ªÉu chi ti·∫øt ƒë·∫±ng sau h√†m loss autoencoder v√† variable autoencoder ch√∫ng ta c√≥ 2 tham s·ªë c·∫ßn t·ªëi ∆∞u v·ªõi encoder l√† phi v√† v·ªõi decoder l√† theta . H√†m loss c√≥ 2 ƒëoan ch√≠nh ƒëo·∫°n 2 ch√≠nh l√† kho·∫£ng c√°ch ph√¢n ph·ªëi gi·ªØa ti·ªÅm ·∫©n t·∫°o ra v√† ti·ªÅm ·∫©n gaussian ti√™u chu·∫©n , ƒëo·∫°n 1 ch√≠nh l√† kh·∫£ nƒÉng t√°i t·∫°o c·ªßa ·∫£nh so v·ªõi ·∫£nh ban ƒë·∫ßu ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a b·∫±ng tham s·ªë theta hay c√≤n g·ªçi l√† ELBO.
M√¨nh s·∫Ω l√†m ti·∫øp series 2 v√† 3 ph·∫ßn series 3 s·∫Ω n√≥i nhi·ªÅu h∆°n v·ªÅ nhi·ªát ƒë·ªông l·ª±c h·ªçc , series 2 l√† diffussion model . v√† c√≤n r·∫•t nhi·ªÅu c√°c th·ªÉ lo·∫°i diffussion kh√°c nhau ch√∫ng ta s·∫Ω t√¨m hi·ªÉu th√™m v·ªÅ ch√∫ng n·ªØa . R·∫•t mong ƒë∆∞·ª£c c√°c b·∫°n ·ªßng h·ªô.

~~T√†i li·ªáu tham kh·∫£o ~~

https://arxiv.org/pdf/2208.11970v1.pdf

https://paperswithcode.com/paper/nvae-a-deep-hierarchical-variational

https://viblo.asia/p/tan-man-ve-generative-models-part-1-cac-mo-hinh-autoencoder-vaes-4P856rw35Y3
üòÑüòÑüòÑüòÑüòÑüòÑ