Trong bÃ i [Má»™t sá»‘ kiáº¿n thá»©c cÆ¡ báº£n vá» Text2Speech
](https://viblo.asia/p/mot-so-kien-thuc-co-ban-ve-text2speech-63vKjWLNZ2R), mÃ¬nh cÃ¹ng cÃ¡c báº¡n Ä‘Ã£ Ä‘iá»ƒm qua cÃ¡c kiáº¿n thá»©c cÆ¡ báº£n vá» Xá»­ lÃ½ giá»ng nÃ³i nhÆ° cÃ¡ch con ngÆ°á»i táº¡o ra Ã¢m thanh, cÃ¡c phÃ©p toÃ¡n biáº¿n Ä‘á»•i Fourier, ... HÃ´m nay, mÃ¬nh chia sáº» vá» má»™t kiáº¿n trÃºc Ä‘Ã£ tá»«ng lÃ m mÆ°a lÃ m giÃ³ má»™t thá»i trong lÄ©nh vá»±c Text2Speech - **Tacotron** trong bÃ i bÃ¡o [TACOTRON: TOWARDS END-TO-END SPEECH SYNTHESIS](https://arxiv.org/pdf/1703.10135.pdf)


## I. Tá»•ng quan
<p align="center">
    <img src="https://images.viblo.asia/a34e387a-47a7-4f90-bb3c-cc4f8cdde928.png" >
Source: A Survey on Neural Speech Synthesis
</p>                                                                     
                                                                             

CÃ¡c há»‡ thá»‘ng text-to-speech Ä‘Ã£ Ä‘Æ°á»£c xÃ¢y dá»±ng nghiÃªn cá»©u cÃ¡ch Ä‘Ã¢y ráº¥t lÃ¢u vá» trÆ°á»›c. VÃ­ dá»¥ nhÆ° mÃ´ hÃ¬nh [STATISTICAL PARAMETRIC SPEECH SYNTHESIS](https://www.cs.cmu.edu/~awb/papers/icassp2007/0401229.pdf) tuy nhiÃªn nhá»¯ng mÃ´ hÃ¬nh nÃ y Ä‘Ã²i há»i ngÆ°á»i phÃ¡t triá»ƒn cÃ³ nhá»¯ng kiáº¿n thá»©c chuyÃªn sÃ¢u vá» xá»­ lÃ½ giá»ng nÃ³i vÃ  ráº¥t máº¥t cÃ´ng Ä‘á»ƒ thiáº¿t káº¿. MÃ´ hÃ¬nh nÃ y gá»“m cÃ³ má»™t bá»™ pháº­n gá»i lÃ  **text frontend** trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng ngÃ´n ngá»¯, má»™t mÃ´ hÃ¬nh trÆ°á»ng Ä‘á»™, má»™t mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n Ä‘áº·c trÆ°ng Ã¢m thanh vÃ  má»™t mÃ´ hÃ¬nh sinh tÃ­n hiá»‡u táº¡o Ã¢m thanh. Má»—i mÃ´ hÃ¬nh nhá» trong Ä‘Ã¢y Ä‘Æ°á»£c huáº¥n luyá»‡n má»™t cÃ¡ch Ä‘á»™c láº­p nÃªn khÃ³ kiá»ƒm soÃ¡t lá»—i trÃªn toÃ n bá»™ há»‡ thá»‘ng. VÃ  Ä‘Ã³ lÃ  lÃ½ do cÃ¡c kiáº¿n trÃºc sau nÃ y nhÆ° **Tacotron** Ä‘Æ°á»£c sinh ra. 

## II. Kiáº¿n trÃºc mÃ´ hÃ¬nh
**Tacotron** nháº­n dá»¯ liá»‡u huáº¥n luyá»‡n bao gá»“m cÃ¡c cáº·p **<text, audio>** sinh ra Linear Spectrogram. Sau Ä‘Ã³ dÃ¹ng giáº£i thuáº­t [Griffin-Lim](https://paperswithcode.com/method/griffin-lim-algorithm) Ä‘Ã³ng vai trÃ² nhÆ° má»™t Vocoder sinh waveform tá»« Linear Spectrogram thu Ä‘Æ°á»£c tá»« á»Ÿ bÆ°á»›c trÆ°á»›c. 

![image.png](https://images.viblo.asia/685ee422-cadf-4113-b8a0-b36100fedd40.png)
Kiáº¿n trÃºc Tacotron cÃ³ dáº¡ng giá»‘ng nhÆ° kiáº¿n trÃºc seq2seq káº¿t há»£p vá»›i attention Ä‘Æ°á»£c sá»­ dá»¥ng nhiá»u trong cÃ¡c bÃ i toÃ¡n vá» OCR bao gá»“m 3 pháº§n: 

- Encoder
- Attention-based decoder
- Post-processing net

### 1. Highway Networks
**Highway Networks** láº¥y nguá»“n cáº£m há»©ng tá»« cÆ¡ cháº¿ Ä‘iá»u khiá»ƒn lÆ°á»£ng thÃ´ng tin vÃ o ra báº±ng cá»•ng trong bÃ i bÃ¡o [ Long Short Term Memory recurrent
neural networks](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43905.pdf) cho phÃ©p há»— trá»£ táº¡o ra cÃ¡c mÃ´ hÃ¬nh sÃ¢u hÆ¡n hÆ¡n báº±ng cÃ¡ch truyá»n thÃ´ng tin Ä‘i qua nhiá»u lá»›p nhÆ°ng khÃ´ng lÃ m giáº£m lÆ°á»£ng thÃ´ng tin truyá»n Ä‘i ban Ä‘áº§u. ÄÃ³ cÅ©ng lÃ  lÃ½ do tÃ¡c giáº£ Ä‘áº·t tÃªn cho kiáº¿n trÃºc lÃ  *highway-network*.



Giáº£ sá»­ bÃ¢y giá» ta cÃ³ má»™t plain feedforward neural network bao gá»“m L lá»›p nháº­n Ä‘áº§u vÃ o lÃ  $x_1$ vÃ  Ä‘áº§u ra lÃ  $y_L$. Lá»›p thá»© **l** cÃ³ sá»­ dá»¥ng má»™t biáº¿n Ä‘á»•i phi tuyáº¿n nháº­n Ä‘áº§u vÃ o lÃ  $x_l$ vÃ  Ä‘áº§u ra lÃ  lá»›p $y_l$.

$$y_l = H(x_l, W_H) \space (1)$$ 

Khi chuyá»ƒn Ä‘á»•i sang highway networks, cÃ´ng thá»©c (1) thÃ nh nhÆ° sau:

$$y = H ( x , W _ { H } ) \cdot T ( x , W _ { T } ) + x \cdot ( 1 - T ( x , W _ { T } ) )$$

trong Ä‘Ã³ T á»Ÿ Ä‘Ã¢y thÆ°á»ng lÃ  phÃ©p toÃ¡n **sigmoid** do Ä‘Ã³ giÃ¡ trá»‹ phÃ©p toÃ¡n T náº±m trong khoáº£ng [0, 1]. NhÆ° váº­y trong má»™t sá»‘ trÆ°á»ng há»£p Ä‘áº·c biá»‡t: 

![image.png](https://images.viblo.asia/1bae6ae4-861c-4d26-ac2a-f0e1315651b0.png)

CÃ¡ nhÃ¢n mÃ¬nh Ä‘Ã¡nh giÃ¡ cÆ¡ cháº¿ nÃ y khÃ¡ giá»‘ng vá»›i cÆ¡ cháº¿ cá»§a skip-connection Ä‘Æ°á»£c sá»­ dá»¥ng trong mÃ´ hÃ¬nh ResNet vá»›i chá»©c nÄƒng tÆ°Æ¡ng tá»±. KhÃ¡c nhau á»Ÿ Ä‘iá»ƒm lÆ°á»£ng thÃ´ng tin Ä‘Æ°á»£c mang tá»›i cÃ¡c lá»›p vá» sau linh hoáº¡t hÆ¡n nhÆ° hÃ m sigmoid.


### 2. CBHG module
<p align="center">
    <img src="https://images.viblo.asia/7c86bc3f-9681-4d90-b147-05c84d8efca4.png" >
CBHG module 
</p>

CBHG lÃ  module cÃ³ chá»©c nÄƒng trÃ­ch xuáº¥t biá»ƒu diá»…n tá»« má»™t chuá»—i bao gá»“m 1 táº­p cÃ¡c lá»›p 1-D convolution, highway networks vÃ  má»™t GRU 2 chiá»u. Chuá»—i Ä‘áº§u vÃ o trÆ°á»›c tiÃªn Ä‘Æ°á»£c nhÃ¢n tÃ­ch cháº­p vá»›i K táº­p há»£p cÃ¡c lá»›p convolution 1-D trong Ä‘Ã³ táº­p há»£p thá»© k chá»©a $C_k$ lá»›p vá»›i kÃ­ch thÆ°á»›c k (k = 1, 2, ..., K). CÃ¡c lá»›p convolution Ä‘Ã³ng vai trÃ² mÃ´ hÃ¬nh hÃ³a thÃ´ng tin ngá»¯ cáº£nh vÃ  Ä‘á»‹a phÆ°Æ¡ng. Káº¿t quáº£ Ä‘áº§u ra cÃ¡c lá»›p convolution nÃ y sau Ä‘Ã³ Ä‘Æ°á»£c ghÃ©p ná»‘i vá»›i nhau vÃ  cho qua lá»›p **Max-pool along time** Ä‘á»ƒ tÄƒng tÃ­nh local invariance (tá»« nÃ y mÃ¬nh khÃ´ng biáº¿t giáº£i nghÄ©a tiáº¿ng Viá»‡t lÃ  gÃ¬ ğŸ˜“).  Sau Ä‘Ã³ káº¿t quáº£ sau pooling Ä‘Æ°á»£c cho qua lá»›p conv 1-D vá»›i kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh.  ChÃº Ã½ tÃ¡c giáº£ dÃ¹ng stride báº±ng 1 á»Ÿ Ä‘Ã¢y nháº±m giá»¯ nguyÃªn Ä‘á»™ phÃ¢n giáº£i Ä‘áº§u vÃ o. TrÆ°á»›c khi Ä‘i vÃ o **highway network**, tÃ¡c giáº£ cÃ³ thá»±c hiá»‡n bá»• sung thÃ´n tin báº±ng cÃ¡ch cá»™ng thÃªm vÃ o Ä‘áº§u ra cá»§a lá»›p Conv1D vá»›i chuá»—i ban Ä‘áº§u. ÄÃ¢y chÃ­nh lÃ  **residual connection** Ä‘Æ°á»£c Ä‘á» cáº­p trong hÃ¬nh minh há»a CBHG module phÃ­a trÃªn.

### 3. Encoder

<p align="center">
    <img src="https://images.viblo.asia/36f3e7e6-e0e3-45f3-802e-510b0dfe004a.png" >
Encoder
</p>

NhÆ° mÃ¬nh Ä‘Ã£ Ä‘á» cáº­p á»Ÿ pháº§n trÃªn, **Encoder** lÃ  má»™t trong 3 module chÃ­nh trong kiáº¿n trÃºc seq2seq. Nhiá»‡m vá»¥ cá»§a encoder á»Ÿ Ä‘Ã¢y Ä‘á»ƒ trÃ­ch xuáº¥t biá»ƒu diá»…n thÃ´ng tin dÆ°á»›i dáº¡ng chuá»—i cá»§a text Ä‘áº§u vÃ o nhÆ° trong cÃ¡c bÃ i toÃ¡n OCR. Äáº§u vÃ o cá»§a encoder lÃ  chuá»—i cÃ¡c kÃ­ tá»± trong Ä‘Ã³ má»—i kÃ­ tá»± Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng one-hot vector vÃ  Ä‘Æ°á»£c embedded vá» dáº¡ng *continous vector.* Tiáº¿p theo, tÃ¡c giáº£ dÃ¹ng má»™t táº­p há»£p cÃ¡c biáº¿n Ä‘á»•i phi tuyáº¿n cho cÃ¡c **continous vector** gá»i lÃ  *pre-net* gá»“m cÃ³ cÃ¡c bottleneck layer vÃ  dropout. Theo nghiÃªn cá»©u viá»‡c sá»­ dá»¥ng *prenet* giÃºp mÃ´ hÃ¬nh há»™i tá»¥ nhanh hÆ¡n vÃ  tÄƒng tÃ­nh tá»•ng quÃ¡t.


### 4. Decoder

<p align="center">
    <img src="https://images.viblo.asia/1d3e9153-4d21-4ab6-a0e2-982d27c59faf.png" >
Attention based decoder
</p>

Trong kiáº¿n trÃºc Tacotron, tÃ¡c giáº£ sá»­ dá»¥ng content-based tanh attention decoder trong Ä‘Ã³ recurrent layer sinh ra cÃ¡c truy váº¥n attention tá»›i má»—i decoder step. Äáº§u vÃ o cá»§a decoder RNN bao gá»“m context vector vÃ  output cá»§a attention RNN. Trong cÃ¡c bÃ i toÃ¡n OCR mÃ  chÃºng ta Ä‘Ã£ gáº·p, cÅ©ng lÃ  kiáº¿n trÃºc seq2seq vá»›i attention tuy nhiÃªn target cá»§a decoder trá»±c tiáº¿p lÃ  cÃ¡c chuá»—i kÃ­ tá»± mong muá»‘n Ä‘áº§u ra. Tuy nhiÃªn vá»›i bÃ i toÃ¡n text2speech láº¡i khÃ¡ khÃ¡c nhau vÃ¬ Ä‘á»ƒ sinh ra audio waveform, lÆ°á»£ng thÃ´ng tin tá»« text lÃ  chÆ°a Ä‘á»§ (phase, ...) vÃ¬ tháº¿ chÃºng ta cáº§n má»™t biáº¿u diá»…n trung gian nhÆ° linear spectrogam, mel spetrogram, ... CÃ¡c báº¡n chÆ°a biáº¿t spetrogam lÃ  gÃ¬ thÃ¬ cÃ³ thá»ƒ xem láº¡i bÃ i [Má»™t sá»‘ kiáº¿n thá»©c cÆ¡ báº£n vá» Text2Speech
](https://viblo.asia/p/mot-so-kien-thuc-co-ban-ve-text2speech-63vKjWLNZ2R) cá»§a mÃ¬nh nhÃ©.

á» Ä‘Ã¢y tÃ¡c giáº£ báº­t mÃ­ cho chÃºng ta má»™t kÄ© thuáº­t Ä‘Ã³ lÃ  viá»‡c dá»± Ä‘oÃ¡n nhiá»u frame khÃ¡c nhau vÃ  táº¥t nhiÃªn khÃ´ng trÃ¹ng nhau á»Ÿ má»—i decoder step sáº½ giÃºp giáº£m kÃ­ch thÆ°á»›c model, thá»i gian huáº¥n luyá»‡n cÅ©ng nhÆ° thá»i gian dá»± Ä‘oÃ¡n. LÃ½ do á»Ÿ Ä‘Ã¢y lÃ  cÃ¡c frame gáº§n nhau thÆ°á»ng liÃªn quan Ä‘áº¿n nhau vÃ  má»™t tá»« Ä‘Æ°á»£c phÃ¡t Ã¢m ra tÆ°Æ¡ng á»©ng vá»›i nhiá»u frame.

### 5. Post-processing net vÃ  waveform synthesis.

á» trong bÃ i bÃ¡o nÃ y, tÃ¡c giáº£ sá»­ dá»¥ng **Griffin-Lim** nhÆ° má»™t synthesizer sinh Ã¢m thanh tá»« linear spectrogram Ä‘Æ°á»£c dá»± Ä‘oÃ¡n á»Ÿ decoder. Tuy nhiÃªn thuáº­t toÃ¡n nÃ y hiá»‡n nÃ y Ä‘Ã£ khÃ´ng cÃ²n hiá»‡u quáº£ so vá»›i cÃ¡c thuáº­t toÃ¡n nhÆ° Waveflow, WaveNet, .... MÃ¬nh sáº½ dÃ nh háº³n vÃ i bÃ i sáº¯p tá»›i Ä‘á»ƒ giá»›i thiá»‡u cho cÃ¡c báº¡n vá» cÃ¡c kiáº¿n trÃºc synthesizer nhÆ° nÃ y.


## III. Káº¿t qá»§a

![image.png](https://images.viblo.asia/4680c6dc-1537-4080-8b46-0a4a01e05e52.png)

Tacotron Ä‘áº¡t MOS 3.82 vÆ°á»£t trá»™i hÆ¡n cÃ¡c phÆ°Æ¡ng phÃ¡p trÆ°á»›c Ä‘Ã¢y nhÆ° Paramtric hay Concatnative trÃªn trong ngÃ´n ngá»¯ tiáº¿ng Anh. Äiá»u nÃ y Ä‘Ã£ khiáº¿n Tacotron trá»Ÿ thÃ nh phÆ°Æ¡ng phÃ¡p hiá»‡u quáº£ nháº¥t trong lÄ©nh vá»±c Text2Speech lÃºc báº¥y giá».

## TÃ i liá»‡u tham kháº£o

1. [TACOTRON: TOWARDS END-TO-END SPEECH SYNTHESIS](https://arxiv.org/pdf/1703.10135.pdf)
2. [Text To Speech â€” Foundational Knowledge (Part 2)
](https://towardsdatascience.com/text-to-speech-foundational-knowledge-part-2-4db2a3657335)