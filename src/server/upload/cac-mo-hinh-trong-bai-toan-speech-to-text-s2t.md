á» 2 bÃ i trÆ°á»›c, mÃ¬nh Ä‘Ã£ trÃ¬nh bÃ y vá» dá»¯ liá»‡u Ã¢m thanh. BÆ°á»›c tiáº¿p theo chÃºng ta sáº½ cÃ¹ng tÃ¬m hiá»ƒu vá» cÃ¡c mÃ´ hÃ¬nh trong bÃ i toÃ¡n speech to text.
# CÃ¡ch tiáº¿p cáº­n thá»‘ng kÃª trong bÃ i toÃ¡n S2T
- Má»¥c tiÃªu chÃ­nh cá»§a bÃ i toÃ¡n S2T lÃ  xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh thá»‘ng kÃª Ä‘á»ƒ dá»± Ä‘oÃ¡n cÃ¡c chuá»—i vÄƒn báº£n (W) dá»±a trÃªn cÃ¡c vector Ä‘áº·c trÆ°ng (X). <br>
- CÃ³ thá»ƒ giáº£i thÃ­ch mÃ´ hÃ¬nh thá»‘ng kÃª nhÆ° sau: tÃ¬m kiáº¿m táº¥t cáº£ cÃ¡c chuá»—i tá»« cÃ³ thá»ƒ cÃ³ (háº¡n cháº¿ Ä‘á»™ dÃ i tá»‘i Ä‘a) vÃ  tÃ¬m má»™t chuá»—i tá»« phÃ¹ há»£p nháº¥t vá»›i Ä‘áº·c Ä‘iá»ƒm Ã¢m thanh Ä‘áº§u vÃ o.
![yyyyyyyyy.png](https://images.viblo.asia/d6f2e8d4-a23f-4ff0-927e-9c2f36a70d90.png)<br>
- CÃ¡c bÆ°á»›c Ä‘Æ°á»£c trÃ¬nh bÃ y á»Ÿ hÃ¬nh sau:![eeeeeeee.png](https://images.viblo.asia/580d0f26-246f-4be5-a51c-5cf78abb44a9.png)<br>
## Acoustic Model (MÃ´ hÃ¬nh Ã¢m thanh)
MÃ´ hÃ¬nh Ã¢m thanh lÃ  má»™t mÃ´ hÃ¬nh phá»©c táº¡p, mÃ´ hÃ¬nh hÃ³a má»‘i quan há»‡ giá»¯a tÃ­n hiá»‡u Ã¢m thanh vÃ  cÃ¡c Ä‘Æ¡n vá»‹ ngá»¯ Ã¢m trong ngÃ´n ngá»¯.
![xxxxxxx.png](https://images.viblo.asia/e6c5a519-7ece-4b3e-bbb8-80b1a26793df.png)<br>
### HMM-GMM Acoustic model 
#### HMM (MÃ´ hÃ¬nh Markov áº©n)
MÃ´ hÃ¬nh Markov áº©n vá»›i ba tráº¡ng thÃ¡i:
![zzzzzzzz.png](https://images.viblo.asia/82ec2677-2c9b-4537-93f2-068d358b2382.png)<br>
***MÃ´ hiÌ€nh Markov áº©n (HMM)*** laÌ€ mÃ´ hiÌ€nh thÃ´Ìng kÃª mÃ¡y tráº¡ng thÃ¡i, cho phÃ©p chÃºng ta xem xÃ©t Ä‘áº¿n hai thÃ nh pháº§n lÃ  sá»± kiá»‡n quan sÃ¡t Ä‘Æ°á»£c vÃ  cÃ¡c sá»± kiá»‡n áº©n. <br>
VÃ­ dá»¥ trong nháº­n dáº¡ng giá»ng nÃ³i thÃ¬ sá»± kiá»‡n quan sÃ¡t Ä‘Æ°á»£c lÃ  cÃ¡c Ä‘áº·c trÆ°ng Ã¢m há»c cá»§a tiáº¿ng nÃ³i, cÃ²n sá»± kiá»‡n áº©n lÃ  cÃ¡c tá»«.
#####  HMM bao gá»“m cÃ¡c thÃ nh pháº§n chÃ­nh sau:
* *Q = q1, q2, â€¦, qN*: lÃ  táº­p cá»§a N tráº¡ng thÃ¡i. <br>
** A = a11, q12, â€¦, ann*: lÃ  ma tráº­n chuyá»ƒn tráº¡ng thÃ¡i (transition matrix) vá»›i aij lÃ  xÃ¡c suÃ¢Ìt Ä‘ÃªÌ‰ traÌ£ng thÃ¡i j xuÃ¢Ìt hiÃªÌ£n taÌ£i thÆ¡Ì€i Ä‘iÃªÌ‰m t+1 khi traÌ£ng thÃ¡i i Ä‘aÌƒ xuÃ¢Ìt hiÃªÌ£n taÌ£i thÆ¡Ì€i Ä‘iÃªÌ‰m t. <br>
* *O = o1, o2, â€¦, oT*: lÃ  má»™t chuá»—i T cÃ¡c quan sÃ¡t táº¡i cÃ¡c thá»i Ä‘iá»ƒm t khÃ¡c nhau. <br>
TÆ°Æ¡ng á»©ng vá»›i má»—i tráº¡ng thÃ¡i táº¡i thá»i Ä‘iá»ƒm t sáº½ cÃ³ má»™t táº­p V = {o1, o2, â€¦, om} lÃ  táº­p táº¥t cáº£ cÃ¡c quan sÃ¡t cÃ³ thá»ƒ Ä‘Æ°á»£c quan sÃ¡t tháº¥y trong má»—i tráº¡ng thÃ¡i. 
* ğµ = {ğ‘ğ‘— (ğ‘£ğ‘˜ )}: B lÃ  phÃ¢n bá»‘ xÃ¡c suáº¥t quan sÃ¡t Ä‘Æ°á»£c cÃ¡c quan sÃ¡t o trong tráº¡ng thÃ¡i qj.<br>
* *Î  = {Ï€1, Ï€2, â€¦, Ï€N}*: tÃ¢Ì£p caÌc phÃ¢n bÃ´Ì xaÌc suÃ¢Ìt cho traÌ£ng thaÌi khÆ¡Ì‰i Ä‘Ã¢Ì€u, Ï€i laÌ€ xaÌc suÃ¢Ìt Ä‘ÃªÌ‰ traÌ£ng thaÌi i Ä‘Æ°Æ¡Ì£c choÌ£n taÌ£i thÆ¡Ì€i Ä‘iÃªÌ‰m khÆ¡Ì‰i Ä‘Ã¢Ì€u t = 1 (cÃ³ thá»ƒ hiá»ƒu nhÆ° khi chÃºng ta khá»Ÿi táº¡o tham sá»‘ cho cÃ¡c mÃ´ hÃ¬nh Deep Learning).<br>
=> á» hÃ¬nh trÃªn biá»ƒu diá»…n má»™t vÃ­ dá»¥ cá»§a HMM vá»›i 3 tráº¡ng thÃ¡i Q = q1, q2, q3. Táº¡i má»—i tráº¡ng thÃ¡i q, cÃ¡c sá»± kiá»‡n quan sÃ¡t Ä‘Æ°á»£c lÃ  V = (v1, v2, v3, v4) vÃ  B = (b1, b2, b3, b4) lÃ  phÃ¢n bá»‘ xÃ¡c suáº¥t quan sÃ¡t Ä‘Æ°á»£c sá»± kiá»‡n vá»›i bj(k) lÃ  xÃ¡c suáº¥t quan sÃ¡t Ä‘Æ°á»£c sá»± kiá»‡n vk trong tráº¡ng thÃ¡i qj. 
##### Äá»‘i vá»›i HMM, cÃ³ 3 bÃ i toÃ¡n chÃ­nh:
* *BÃ i toÃ¡n 1: Computing likelihood*<br>
Cho biáº¿t trÆ°á»›c mÃ´ hÃ¬nh HMM Î»(Ï€, A, B) vÃ  chuá»—i quan sÃ¡t O=O1, O2, â€¦, OT. XÃ¡c Ä‘á»‹nh likelihood P(O|Î»).
VÃ­ dá»¥ trong nháº­n dáº¡ng tiáº¿ng nÃ³i, ta cÃ³ quan sÃ¡t O lÃ  tÃ­n hiá»‡u tiáº¿ng nÃ³i vÃ  Î» lÃ  mÃ´ hÃ¬nh, váº­y bÃ i toÃ¡n cáº§n giáº£i lÃ  tÃ­nh likelihood P Ä‘á»ƒ mÃ´ hÃ¬nh Î» quan sÃ¡t Ä‘Æ°á»£c O.
* *BÃ i toÃ¡n 2: Decoding*<br>
Cho má»™t chuá»—i quan sÃ¡t O vÃ  mÃ´ hÃ¬nh HMM Î»(A,B,Ï€), xÃ¡c Ä‘á»‹nh chuá»—i Q tá»‘t nháº¥t. 
Trong nháº­n dáº¡ng tiáº¿ng nÃ³i thÃ¬ Ä‘Ã¢y chÃ­nh lÃ  bÃ i toÃ¡n nháº­n dáº¡ng, khi quan sÃ¡t O lÃ  tÃ­n hiá»‡u tiáº¿ng nÃ³i thÃ¬ bÃ i toÃ¡n lÃ  tÃ¬m chuá»—i Ã¢m vá»‹ Q tÆ°Æ¡ng á»©ng vá»›i tÃ­n hiá»‡u nÃ y.
* *BÃ i toÃ¡n 3: Learning*<br>
Co má»™t chuá»—i quan sÃ¡t O vÃ  táº­p cÃ¡c tráº¡ng thÃ¡i cá»§a HMM, Ä‘iá»u chá»‰nh cÃ¡c tham sá»‘ Î» = {A, B, Ï€} cá»§a HMM Ä‘á»ƒ P(O| Î») lá»›n nháº¥t.<br>
ÄÃ¢y chÃ­nh lÃ  bÃ i toÃ¡n huáº¥n luyá»‡n mÃ´ hÃ¬nh HMM. <br>
CÃ³ thá»ƒ giáº£i quyáº¿t 3 bÃ i toÃ¡n trÃªn báº±ng 3 thuáº­t toÃ¡n sau: ***Forward, Viterbi, Baum Welch***. CÃ¡c báº¡n cÃ³ thá»ƒ tÃ¬m hiá»ƒu thÃªm vá» cÃ¡c thuáº­t toÃ¡n nÃ y táº¡i [Ä‘Ã¢y](https://jonathan-hui.medium.com/speech-recognition-gmm-hmm-8bb5eff8b196). 
##### Trong HMM, 1 Ã¢m vá»‹ thÆ°á»ng Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng HMM tuyáº¿n tÃ­nh 3 hoáº·c 5 tráº¡ng thÃ¡i
![jjjjjjj.png](https://images.viblo.asia/bf358b64-d465-439b-900a-53517343f00b.png)<br>
CÃ³ 1 cÃ¢u há»i Ä‘áº·t ra lÃ : CÃ¡c quan sÃ¡t Ä‘Æ°á»£c táº¡o ra báº±ng cÃ¡ch nÃ o? <br>
CÃ¢u tráº£ lá»i lÃ  sá»­ dá»¥ng *GMM (Gaussian Mixture Model)*. GMM lÃ  má»™t mÃ´ hÃ¬nh phÃ¢n phá»‘i Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng cÃ¡c quan sÃ¡t Ä‘Æ°á»£c táº¡o ra. 
Viá»‡c Ä‘Ã o táº¡o HMM-GMM Ä‘Æ°á»£c giáº£i quyáº¿t báº±ng Tá»‘i Ä‘a hÃ³a ká»³ vá»ng (Expectation Maximization - EM). CÃ¡c báº¡n cÃ³ thá»ƒ tÃ¬m hiá»ƒu rÃµ hÆ¡n vá» GMM vÃ  EM qua bÃ i viáº¿t [nÃ y](https://towardsdatascience.com/expectation-maximization-for-gmms-explained-5636161577ca).
### HMM-DNN Acoustic model
Kiáº¿n trÃºc HMM-DNN tiáº¿p cáº­n mÃ´ hÃ¬nh Ã¢m thanh theo má»™t cÃ¡ch khÃ¡c. Thay vÃ¬ Ä‘i tÃ¬m kiáº¿m cÃ¢u tráº£ lá»i cho P(X|W), thÃ¬ HMM-DNN trá»±c tiáº¿p tráº£ lá»i cho P(W|X). DNN dá»± Ä‘oÃ¡n xÃ¡c suáº¥t tráº¡ng thÃ¡i cá»§a má»™t khung thoáº¡i, trong khi HMM káº¿t há»£p cÃ¡c dá»± Ä‘oÃ¡n cá»§a DNN Ä‘á»ƒ dá»± Ä‘oÃ¡n tráº¡ng thÃ¡i tiáº¿p theo.

![ggggggg.png](https://images.viblo.asia/64c61b3b-5e23-4ecb-8b01-5ca10ca680ff.png)<br>
## Language Modeling (MÃ´ hÃ¬nh ngÃ´n ngá»¯)
MÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng P(W). MÃ´ hÃ¬nh ngÃ´n ngá»¯ thá»‘ng kÃª lÃ  loáº¡i mÃ´ hÃ¬nh gÃ¡n xÃ¡c suáº¥t cho cÃ¡c chuá»—i tá»«. 
### N-gram language model
**CÃ´ng thá»©c:**
                **P(w|h)**, tÃ­nh xÃ¡c suáº¥t cá»§a tá»« **w** khi biáº¿t trÆ°á»›c cÃ¡c tá»« trÆ°á»›c nÃ³ **h**<br>
**VÃ­ dá»¥:**
	P(**yÃªu**|**TÃ´i lÃ  má»™t cÃ´ gÃ¡i Ä‘Ã¡ng**)<br>
    á» Ä‘Ã¢y, w = yÃªu,
             h = TÃ´i lÃ  má»™t cÃ´ gÃ¡i Ä‘Ã¡ng .
     
 TÃ­nh xÃ¡c suáº¥t trÃªn báº±ng phÆ°Æ¡ng phÃ¡p Ä‘áº¿m táº§n suáº¥t tÆ°Æ¡ng Ä‘á»‘i, trong Ä‘Ã³ chÃºng ta cáº§n sá»­ dá»¥ng má»™t kho ngá»¯ liá»‡u (corpus) lá»›n. Tá»« kho ngá»¯ liá»‡u nÃ y, Ä‘áº¿m sá»‘ láº§n xuáº¥t hiá»‡n cá»§a â€œ**TÃ´i lÃ  má»™t cÃ´ gÃ¡i Ä‘Ã¡ng**â€, sau Ä‘Ã³ Ä‘áº¿m sá»‘ láº§n xuáº¥t hiá»‡n cá»§a â€œ**yÃªu**" sau nÃ³.
* *P(yÃªu|TÃ´i lÃ  má»™t cÃ´ gÃ¡i Ä‘Ã¡ng) = C(TÃ´i lÃ  má»™t cÃ´ gÃ¡i Ä‘Ã¡ng yÃªu)/C(TÃ´i lÃ  má»™t cÃ´ gÃ¡i Ä‘Ã¡ng)*<br>

Thá»­ tÆ°á»£ng tÆ°á»Ÿng, náº¿u corpus báº¡n lÃªn Ä‘áº¿n hÃ ng triá»‡u, hÃ ng trÄƒm nghÃ¬n tá»« thÃ¬ tÃ­nh toÃ¡n nÃ y cÃ³ kháº£ thi khÃ´ng? ***MÃ´ hÃ¬nh N-gram*** cÃ³ thá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y, thay vÃ¬ tÃ­nh toÃ¡n xÃ¡c suáº¥t báº±ng cÃ¡ch sá»­ dá»¥ng toÃ n bá»™ kho dá»¯ liá»‡u, thÃ¬ sáº½ Æ°á»›c tÃ­nh nÃ³ chá»‰ báº±ng má»™t vÃ i tá»« (N) Ä‘Ã£ xuáº¥t hiá»‡n trÆ°á»›c Ä‘Ã³. 
![ccccccccccc.png](https://images.viblo.asia/bfc2c59b-24d4-4de2-880d-55d6b69760ac.png)Trong Ä‘Ã³ n cÃ³ thá»ƒ lÃ  1(unigram), 2(bigram), 3(trigram)<br>
* CÃ³ thá»ƒ tháº¥y nhÆ°á»£c Ä‘iá»ƒm cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ thá»‘ng kÃª lÃ  Ä‘Æ°á»£c Ä‘Ã o táº¡o dá»±a trÃªn 1 kho ngá»¯ liá»‡u cá»‘ Ä‘á»‹nh. Náº¿u dá»¯ liá»‡u á»Ÿ ngoÃ i táº­p ngá»¯ liá»‡u nÃ y, sáº½ dáº«n Ä‘áº¿n xÃ¡c suáº¥t báº±ng 0. NgoÃ i ra cÃ²n thiáº¿u tÃ­nh tá»•ng quÃ¡t khi tÃ¹y vÃ o tá»«ng thá»ƒ loáº¡i, tá»«ng chá»§ Ä‘á» thÃ¬ sáº½ cÃ³ cÃ¡c cÃ¡ch káº¿t há»£p cÃ¢u, tá»« khÃ¡c nhau. 

* Äá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y, chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ há»c sÃ¢u. Gáº§n Ä‘Ã¢y, trong lÄ©nh vá»±c NLP, cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ dá»±a trÃªn máº¡ng nÆ¡ ron ngÃ y cÃ ng trá»Ÿ nÃªn phá»• biáº¿n hÆ¡n.

# Káº¿t luáº­n
MÃ¬nh sáº½ káº¿t thÃºc bÃ i nÃ y táº¡i Ä‘Ã¢y. Qua bÃ i nÃ y chÃºng ta Ä‘Ã£ hiá»ƒu rÃµ pháº§n nÃ o vá» kiáº¿n trÃºc bÃ i toÃ¡n S2T. MÃ¬nh sáº½ viáº¿t thÃªm vá» cÃ¡ch huáº¥n luyá»‡n cÅ©ng nhÆ° sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh deep learning thay vÃ¬ mÃ´ hÃ¬nh thá»‘ng kÃª trong cÃ¡c bÃ i sau. CÃ¡c báº¡n cÃ¹ng Ä‘Ã³n Ä‘á»c nhÃ©.
# TÃ i liá»‡u tham kháº£o
https://www.aiourlife.com/2020/04/tong-hop-tieng-noi-su-dung-mo-hinh.html?showComment=1598613008903<br>
https://jonathan-hui.medium.com/speech-recognition-gmm-hmm-8bb5eff8b196<br>
https://maelfabien.github.io/machinelearning/speech_reco/#1-hmm-gmm-acoustic-model<br>
https://towardsdatascience.com/introduction-to-language-models-n-gram-e323081503d9<br>