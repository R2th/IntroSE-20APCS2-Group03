Chào các bạn! Với những kiến thức trong bài viết trước ta đã biết nếu muốn đánh giá được hệ thống **Machine Learning** ta cần phải chia tập data của mình thành những phần khác nhau (**Training set**, **Dev set**, **Test set**). Vấn đề đặt ra ở đây là ta nên chia chúng như thế nào ? Liệu có phải cứ chia đều hay theo một tỉ lệ nào đó cố định ?

## 1. Tập dữ liệu nào là quan trọng ? 
Như chúng ta đã biết **Training set** - **Dev set** - **Test set** tương tự như "**giáo trình**" - "**bộ đề thi thử**" - "**bộ đề thi thật**", vậy theo các bạn kiến thức trong các tập dữ liệu này, ở đâu là nhiều nhất. Tôi không thể nghe các bạn trả lời, nhưng hi vọng rằng câu trả lời là "giáo trình". Nếu các bạn chọn phải bộ giáo trình thiếu hụt nhiều kiến thức tới nỗi đi thi gặp bài nào cũng lạ hoắc thì tỉ lệ về quê chăn trâu cao như mấy tòa nhà bên **Dubai** luôn ! Đối với các tập dữ liệu cũng vậy, nơi quan trọng bậc nhất là những dữ liệu các bạn cho máy học trực tiếp. Dù cho thi cử là quan trọng nhưng giáo trình càng chứa nhiều kiến thức càng tốt. Chính vì vậy tập dữ liệu quan trọng nhất và nên "to" nhất chính là **Training set**. Nên đừng dại gì mà chia dataset của các bạn thành các phần mà trong đó **Training set** nhỏ xíu như tô hủ tíu, các bạn sẽ thất bại ngay từ vòng gửi xe.
![](https://images.viblo.asia/3f0254f3-5c47-40d4-8691-6dbbdd738215.png)

## 2. Data set "nhỏ"
Thuở xa xưa khi internet còn chậm như còn rùa hay thậm chí máy tính chỉ xuất hiện ở những gia đình có điều kiện, tài liệu ôn thi của con nhà mình thường be bé xinh xinh chứ không được dồi dào như con nhà người ta. Nói vậy thôi, thời nay để gom được mớ dữ liệu mà dạy cho thằng "máy" nó học cho bằng anh bằng em vẫn vô cùng gian nan và vất vả, chưa kể những chuyên ngành khó còn vô cùng đắt đỏ nữa. Vậy nên ta vẫn thường xuyên gặp những tập data "**nhỏ**", nhiều lúc hẩm hiu chỉ có vài trăm bản ghi, hay đôi lúc sung túc thì được tầm trăm ngàn (So với dữ liệu của các bác đầu cơ như **Google**, **Facebook** thì thật chẳng khác gì kiến và voi). Nếu các bạn quá yêu chiều **Training set**, giao cho chúng nó tất cả những cuộc đời trao tặng cho bạn, thì sẽ chẳng có gì mà đánh giá, mô hình tốt xấu phụ thuộc vào ý trời. Vậy nên thông thường chúng ta vẫn chừa lại xíu xíu cho **Dev set** và **Test set**, một thời tỉ lệ vàng của các tập dữ liệu này 70% - 15% - 15% hay 60%-20%-20%. Những tỉ lệ này đều phản ánh cho ta thấy phần lớn vẫn là **Training set**, phần còn lại được chia đều cho **Dev set** và **Test set**. **Dev set** và **Test set** tuy nhỏ hơn **Training set** nhưng về tỉ lệ cũng đã = **1/3** hay **1/4** so với **Training set**. Vì lượng dữ liệu của ta nhỏ nên nếu sử dụng quá nhiều cho **Training set**, có thể trong quá trình phát triển mô hình, vô hình chung ta sẽ bị overfitting **Dev set**. Dù có **Test set** giúp phát hiện điều đó nhưng việc phân chia lại sẽ khiến các bạn bắt đầu lại từ đầu.
![](https://images.viblo.asia/ea6694f9-b89c-43c8-88c5-56e996708c48.png)

## 3. Data set "lớn", thậm chí ... "rất lớn"
"**Mạnh vì gạo, bạo vì tiền**" - Nếu có hồng phúc tề thiên, các bạn vớ phải dự án có nguồn dữ liệu dồi dào, được góp nhặt cẩn thận qua năm tháng thì chuỗi ngày mấy anh em **Training set** - **Dev set** - **Test set** chia nhau củ khoai đã không còn, lịch sử đã sang trang mới, chúng ta trở thành những gia đình có điều kiện. Với tập dữ liệu lên tới hàng triệu hay thậm chí hàng trăm triệu, hàng tỉ thì việc chia ngọt sẽ bùi giữa các tập dữ liệu không cần tỉ lệ vàng ở trên nữa.Chỉ với 1% cả tập dữ liệu các bạn đã có tới hàng trăm ngàn hay hàng triệu dữ liệu, với lượng dữ liệu này các bạn có thể khá tự tin rằng mô hình khó có thể bị overfitting **Dev set**. Vì vậy với những tập dữ liệu lớn, ta có thể dành 98% hay thậm chí 99% để chăm chút cho con lợn xề **Training set**, với phần còn lại chia đều cho Dev set và Test set. Giờ vấn đề duy nhất của các bạn là thằng "máy" kia có nhét nổi đống "kiến thức" này vào đầu hay không ! 
![](https://images.viblo.asia/4d3ffc73-d6ee-497e-b1c8-289af3dec0f9.png)

## 4. Liệu ta có nên thay đổi tỉ lệ chia các tập dữ liệu trong quá trình phát triển ?
Các bạn đã biết chia tập dữ liệu như thế nào, nhưng như mình đã nhắc tới ở trên. Dù ta chia dữ liệu ra sao, vẫn có khả năng ta bị overfitting **Dev set**. Khi đó, đáng buồn là các bạn phải thay đổi việc chia dữ liệu giữa các tập. Việc cần làm là mở rộng **Dev set**, các bạn có thể lấy từ **Test set** hay **Training set**, dù là cách nào cũng khiến **Dev set** lớn hơn. Nếu lấy từ **Test set**, các bạn sẽ vẫn giữ được lượng dữ liệu dồi dào để training, nhưng có thể khiến **Dev set** không mở rộng được nhiều và vẫn bị overfitting. Còn nếu  như lấy từ **Training set**, khả năng mở rộng **Dev set** khá là thoải mái, tuy nhiên có thể ảnh hưởng tới lượng dữ liệu training đôi chút.
![](https://images.viblo.asia/08acc381-35a0-43fe-9c77-d006a5d90454.png)

## 5. Dữ liệu trong Training set, Dev set, Test set có cần "giống" nhau ?
Trước khi kết thúc bài viết, ta hãy nói một chút về vấn đề "giống nhau" giữa các tập dữ liệu. Chẳng hạn với bài toán phân loại ảnh, giả dụ như bạn đang phân loại ảnh chó và mèo, dữ liệu ban đầu của ta đến từ camera điện thoại, sau khi phân chia dữ liệu thành 3 phần như trên ta có thêm 1 cục dữ liệu nữa từ nhà hảo tâm Google nhưng ảnh toàn là ảnh chó mèo trong phim hoạt hình. Vậy ta có nên ném hết chúng vào trong **Training set** để có thêm nhiều dữ liệu training. Nhưng rõ ràng việc làm đó sẽ khiến tấm bia của chúng ta bị sai lệch, điểm quan trọng trong việc phân chia data vào các tập dữ liệu là ta phải đảm bảo chúng đều có phân phối hay nguồn tương tự nhau. Hẹn gặp lại các bạn trong bài viết tiếp theo.