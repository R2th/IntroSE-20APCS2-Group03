# Má»Ÿ bÃ i
Trong táº¥t cáº£ cÃ¡c loáº¡i Neural Network, em thÃ­ch nháº¥t lÃ  Convolutional Neural Network. VÃ¬ váº­y hÃ´m nay em sáº½ lÃ m má»™t bÃ i vÄƒn miÃªu táº£ vá» Receptive field lÃ  gÃ¬, táº¡i sao chÃºng ta cáº§n pháº£i hiá»ƒu nÃ³ náº¿u muá»‘n hiá»ƒu rÃµ cÃ¡ch CNN hoáº¡t Ä‘á»™ng. ğŸ˜‚

NhÆ° chÃºng ta Ä‘Ã£ biáº¿t NN Ä‘Æ°á»£c láº¥y cáº£m há»©ng tá»« há»‡ tháº§n kinh nÃ£o bá»™ cá»§a con ngÆ°á»i vá»›i receptive field cÅ©ng khÃ´ng ngoáº¡i lá»‡, váº­y nÃªn mÃ¬nh sáº½ láº¥y má»™t vÃ­ dá»¥ vá» há»‡ thá»‘ng thá»‹ giÃ¡c cá»§a con ngÆ°á»i cho má»i ngÆ°á»i dá»… hÃ¬nh dung. Khi mÃ  báº¡n táº­p trung nhÃ¬n vÃ o má»™t váº­t thá»ƒ á»Ÿ trÆ°á»›c máº·t thÃ¬ khu vá»±c nhÃ¬n tháº¥y cá»§a máº¯t ngÆ°á»i sáº½ Ä‘Æ°á»£c gá»i lÃ  receptive field (field of view). Há»‡ thá»‘ng thá»‹ giÃ¡c cá»§a chÃºng ta cÃ³ hÃ ng triá»‡u táº¿ bÃ o tháº§n kinh vÃ¬ váº­y vá»›i má»—i táº¿ bÃ o tháº§n kinh nÃ³ sáº½ phá»¥ trÃ¡ch receptive field má»™t pháº§n hoáº·c má»™t khu vá»±c nhá» trÃªn tá»•ng tháº¿ reptive field nhÃ¬n tháº¥y (total field of view). Hay nÃ³i cÃ¡ch khÃ¡c thÃ¬ má»—i neuron tháº§n kinh sáº½ Ä‘Æ°á»£c phÃ©p truy cáº­p vÃ o má»™t khu vá»±c vÃ  khu vá»±c nÃ y Ä‘Æ°á»£c gá»i lÃ  trÆ°á»ng tiáº¿p nháº­n cá»§a táº¿ bÃ o (**cell's receptive field**). Má»i ngÆ°á»i cÃ³ thá»ƒ hÃ¬nh dung rÃµ hÆ¡n vá»›i hÃ¬nh minh há»a phÃ­a dÆ°á»›i.
![](https://images.viblo.asia/48f6674c-985e-483b-8359-a736a815ed98.png)

Oke. Sau khi má»i ngÆ°á»i Ä‘Ã£ mÆ°á»ng tÆ°á»£ng ra receptive field nÃ³ nÃ  cÃ¡i dÃ¬ dá»“i thÃ¬ chÃºng ta cÃ¹ng Ä‘i vÃ o chi tiáº¿t xem nÃ³ cÃ³ tÃ¡c dá»¥ng gÃ¬ Ä‘á»‘i vá»›i CNN. **GÃ©t gÃ´...**
# ThÃ¢n bÃ i
### Receptive field
* **KhÃ¡i niá»‡m:**

Receptive field trong deep learning Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  kÃ­ch thÆ°á»›c cá»§a má»™t vÃ¹ng (region) trong khÃ´ng gian Ä‘áº§u vÃ o (input space) Ä‘Æ°á»£c nhÃ¬n tháº¥y bá»Ÿi pixel output qua má»™t kernel/filter. KhÃ´ng giá»‘ng vá»›i máº¡ng fully connected network khi mÃ  má»—i node trong layer phá»¥ thuá»™c vÃ o toÃ n bá»™ input Ä‘áº§u vÃ o cá»§a máº¡ng, thÃ¬ Ä‘á»‘i vá»›i CNN nÃ³ chá»‰ phá»¥ thuá»™c vÃ o má»™t vÃ¹ng cá»§a input. VÃ¹ng nÃ y trong input Ä‘Æ°á»£c gá»i lÃ  ***receptive field***.  

* **Táº¡i sao láº¡i cáº§n receptive field:**

Oke. Äá»ƒ dá»… hÃ¬nh dung mÃ¬nh sáº½ láº¥y má»™t vÃ­ dá»¥ cá»¥ thá»ƒ, nhÆ° chÃºng ta Ä‘Ã£ biáº¿t trong bÃ i toÃ¡n image segmentation nhiá»‡m vá»¥ lÃ  Ä‘i dá»± Ä‘oÃ¡n tá»«ng pixel tÆ°Æ¡ng á»©ng á»Ÿ input xem nÃ³ Ä‘ang thuá»™c class tÆ°Æ¡ng á»©ng nÃ o. Váº­y Ä‘iá»u chÃºng ta mong muá»‘n nháº¥t á»Ÿ Ä‘Ã¢y sáº½ lÃ  lÃ m sao cho viá»‡c dá»± Ä‘oÃ¡n pixel Ä‘Ã³ thuá»™c true class lÃ  cao nháº¥t. MÃ  Ä‘iá»u kiá»‡n lÃ½ tÆ°á»Ÿng nháº¥t cho Ä‘iá»u nÃ y lÃ  táº¡i má»—i output pixel nÃ³ cÃ³ má»™t receptive field tháº­t lá»›n. Äiá»u nÃ y giÃºp cho viá»‡c model khÃ´ng bá»‹ bá» qua nhá»¯ng chi tiáº¿t quan trá»ng trong quÃ¡ trÃ¬nh dá»± Ä‘oÃ¡n. NhÆ° báº¡n tháº¥y á»Ÿ hÃ¬nh bÃªn dÆ°á»›i, vá»›i ouput pixel báº¡n muá»‘n dá»± Ä‘oÃ¡n thuá»™c khu vá»±c chiáº¿c Ã´ tÃ´ thÃ¬ báº¡n muá»‘n receptive field lÃ  mÃ u cam hay mÃ u xanh? Options nÃ o sáº½ mang láº¡i nhiá»u thÃ´ng tin cho output hÆ¡n?
![](https://images.viblo.asia/aef340d2-b102-4260-b047-f89678714d8e.png)

* **TÃ­nh toÃ¡n nÃ³ nhÆ° nÃ o:**

á» Ä‘Ã¢y mÃ¬nh sáº½ láº¥y má»™t vÃ­ dá»¥ nhÆ° hÃ¬nh bÃªn dÆ°á»›i:
![](https://images.viblo.asia/2722e024-b88b-4d3a-b72f-67e61274d212.png)
Vá»›i feature map Ä‘Æ°á»£c táº¡o ra bá»Ÿi layer Ä‘áº§u tiÃªn (mÃ u xanh lá»¥c) Ä‘Æ°á»£c táº¡o ra bá»Ÿi kernel size = 3x3 vá»›i padding = 1 vÃ  stride = 2 thÃ¬ cÃ³ thá»ƒ tháº¥y ta sáº½ thu Ä‘Æ°á»£c vÃ¹ng receptive field 3x3 tÆ°Æ¡ng á»©ng báº±ng vá»›i kÃ­ch thÆ°á»›c cá»§a kernel size (táº¡i má»—i vÃ¹ng kernel trÆ°á»£t qua). Tiáº¿p Ä‘áº¿n, ta sáº½ xem xÃ©t Ä‘á»‘i vá»›i feature map (mÃ u cam) cá»§a layer thá»© 2 Ä‘Æ°á»£c táº¡o ra vá»›i thÃ´ng sá»‘ S, P vÃ  kernel tÆ°Æ¡ng tá»±, lÃºc nÃ y Ä‘á»‘i vá»›i má»—i pixel cá»§a feature map má»›i ta thu Ä‘Æ°á»£c má»™t vÃ¹ng receptive field 7x7 tÆ°Æ¡ng á»©ng.

Oke. Äá»ƒ cho dá»… hÃ¬nh dung vá» viá»‡c tá»«ng pixel trong feature map nÃ³ sáº½ nhÃ¬n tháº¥y má»™t vÃ¹ng receptive field lÃ  bao nhiÃªu ta sáº½ nhÃ¬n qua 2 hÃ¬nh nhá» phÃ­a bÃªn pháº£i. Vá»›i viá»‡c feature map Ä‘Æ°á»£c thay Ä‘á»•i kÃ­ch thÆ°á»›c báº±ng vá»›i kÃ­ch thÆ°á»›c cá»§a input. VÃ¹ng mÃ u vÃ ng nháº¡t vÃ  vÃ¹ng mÃ u xanh dÆ°Æ¡ng nháº¡t biá»ƒu thá»‹ cho vÃ¹ng receptive field tÆ°Æ¡ng á»©ng cá»§a tá»«ng pixel trÃªn feature map layer 1 vÃ  layer 2. NhÃ¬n vÃ o hÃ¬nh minh há»a kia chÃºng ta cÃ³ thá»ƒ Ä‘oÃ¡n ráº±ng, khi máº¡ng cÃ ng sÃ¢u thÃ¬ vÃ¹ng receptive field cÃ ng lá»›n chÄƒng?

Giá» cÃ¹ng Ä‘i vÃ o má»™t tÃ­ tÃ­nh toÃ¡n cho Ä‘á»¡ nhÃ m chÃ¡n nÃ o.ğŸ˜—

Ta cÃ³ receptive field táº¡i layer k Ä‘Æ°á»£c kÃ½ hiá»‡u $R_k  \times  R_k$. Gá»i $F_j$ lÃ  kÃ­ch thÆ°á»›c cá»§a kernel cá»§a layer thá»© *j* vÃ  $S_i$ lÃ  giÃ¡ trá»‹ cá»§a stride cá»§a layer thá»© *I*, ta sáº½ táº¡m Ä‘á»ƒ $S_0$ = 1. Tá»« Ä‘Ã³ kÃ­ch thÆ°á»›c receptive field táº¡i layer *k* Ä‘Æ°á»£c tÃ­nh báº±ng cÃ´ng thá»©c:

![](https://images.viblo.asia/003d35e4-9447-4da8-b591-bb4178dc39d2.png)

á» vÃ­ dá»¥ phÃ­a dÆ°á»›i chÃºng ta cÃ³, $F_1 = F_2 = 3$ vÃ  $S_1 = S_2 = 1$, nÃªn cho ra Ä‘Æ°á»£c $R_2 = 1 + 2 . 1 + 2 . 1 = 5$.

![](https://images.viblo.asia/e0f68905-e2ed-458e-9ca0-3808b4837800.gif)

**Note:** ChÃº Ã½ ráº±ng viá»‡c tÃ­nh toÃ¡n bÃªn trÃªn chá»‰ lÃ  vÃ¹ng theoretical receptive field vÃ¬ trong thá»±c táº¿ khÃ´ng pháº£i toÃ n bá»™ receptive field map Ä‘á»u cÃ³ Ä‘Ã³ng gÃ³p vÃ o output lÃ  nhÆ° nhau. Báº¡n sáº½ Ä‘Æ°á»£c tÃ¬m hiá»ƒu vá» khÃ¡i niá»‡m effective receptive field á»Ÿ pháº§n tiáº¿p theo.

* **Má»™t sá»‘ cÃ¡ch tÄƒng receptive field:**

1. *Add thÃªm nhiá»u layers hÆ¡n:*  Má»™t cÃ¡ch Ä‘Æ¡n giáº£n nháº¥t lÃ  add thÃªm nhiá»u layers hÆ¡n táº¡o cho máº¡ng sÃ¢u hÆ¡n. Viá»‡c nÃ y tÄƒng kÃ­ch thÆ°á»›c cá»§a receptive field lÃªn theo chiá»u tuyáº¿n tÃ­nh. NhÆ° á»Ÿ nhá»¯ng vÃ­ dá»¥ bÃªn trÃªn mÃ¬nh Ä‘Ã£ Ä‘Æ°a ra thÃ¬ cháº¯c cÃ³ láº½ má»i ngÆ°á»i cÅ©ng sáº½ hÃ¬nh dung ra. Tuy nhiÃªn cÃ¡ch nÃ y cÃ³ má»™t váº¥n Ä‘á» xáº£y ra, khi mÃ  kÃ­ch thÆ°á»›c Ä‘Æ°á»£c tÄƒng sáº½ lÃ  kÃ­ch thÆ°á»›c theoretical receptive field trong khi kÃ­ch thÆ°á»›c effective receptive field láº¡i bá»‹ giáº£m xuá»‘ng.

![](https://images.viblo.asia/dd682038-e8dc-4f4a-b004-4f807cea9196.png)

2. *Sub-sampling and diated convolutions:*  ÄÃ¢y lÃ  má»™t cÃ¡ch khÃ¡c giÃºp tÄƒng receptive field lÃªn nhiá»u láº§n. Cá»¥ thá»ƒ hÆ¡n Ä‘Ã¢y lÃ  má»™t ká»¹ thuáº­t má»Ÿ rá»™ng kernel báº±ng cÃ¡ch chÃ¨n cÃ¡c há»‘ (holes) vÃ o giá»¯a cÃ¡c pháº§n tá»­ cá»§a kernel. NÃ³i cÃ¡ch khÃ¡c nÃ³ giá»‘ng nhÆ° viá»‡c tÃ­nh convolutions nhÆ°ng bá» qua pixel (kiá»ƒu nháº£y cÃ³c =)) ) giÃºp cho viá»‡c má»Ÿ rá»™ng input ra má»™t vÃ¹ng lá»›n hÆ¡n.

![](https://images.viblo.asia/e4d46e03-a337-4853-b717-d4681da66741.gif)

### Effective receptive field
* **Váº¥n Ä‘á» cá»§a theoretical receptive field:**

NhÆ° tÃ¡c giáº£ á»Ÿ paper [nÃ y](https://arxiv.org/pdf/1701.04128.pdf) Ä‘Ã£ phÃ¢n tÃ­ch vÃ  chá»‰ ra ráº±ng khu vá»±c effective náº±m trong receptive field cÃ³ tÃ¡c Ä‘á»™ng lá»›n Ä‘áº¿n output cá»§a layer (khu vá»±c nÃ y Ä‘Æ°á»£c gá»i lÃ  effective receptive field) chá»‰ chiáº¿m má»™t pháº§n nhá» trÃªn toÃ n bá»™ theoretical receptive field. VÃ  Ä‘áº·c biá»‡t nÃ³ cÃ²n suy giáº£m nhanh chÃ³ng tá»« tÃ¢m theo phÃ¢n phá»‘i Gaussian.

Váº­y nÃªn tiáº¿p theo chÃºng ta sáº½ cÃ¹ng Ä‘i tÃ¬m cÃ¡ch Ä‘á»ƒ tÃ­nh toÃ¡n xem liá»‡u nhá»¯ng pixel nÃ o náº±m trong receptive field cÃ³ tÃ¡c Ä‘á»™ng lá»›n Ä‘áº¿n output cá»§a layer.

Äá»ƒ tÃ­nh toÃ¡n thÃ­ nghiá»‡m tÃ¡c giáº£ chá»‰ láº¥y duy nháº¥t má»™t Ä‘iá»ƒm $y_{0,0}$ lÃ  pixel trung tÃ¢m táº¡i feature map vÃ  sau Ä‘Ã³ tÃ­nh toÃ¡n tÃ¡c Ä‘á»™ng cá»§a cÃ¡c Ä‘iá»ƒm $x_{i,j}$ lÃªn nÃ³. Oke báº¯t Ä‘áº§u nÃ oâ€¦

Cho má»—i pixel trÃªn má»—i layer cÃ³ index lÃ  $(i, j)$, vÆ¡i tÃ¢m cá»§a chÃºng lÃ  $(0, 0)$. Biá»ƒu thá»‹ pixel thá»© $(i, j)$ cá»§a layer thá»© *p* lÃ  ${x_{i,j}^p}$ vá»›i ${x_{i,j}^0}$ lÃ  pixel input cá»§a máº¡ng, vÃ  $y_{i,j} = {x_{i,j}^n}$ lÃ  output cá»§a layer thá»© n. Nhiá»‡m vá»¥ cá»§a chÃºng ta lÃ  sáº½ Ä‘o lÆ°á»ng xem má»—i giÃ¡ trá»‹ cá»§a ${x_{i,j}^0}$ sáº½ Ä‘Ã³ng gÃ³p bao nhiÃªu vÃ o $y_{0,0}$

Äá»ƒ tÃ­nh Ä‘Æ°á»£c cÃ¡i nÃ y chÃºng ta sáº½ sá»­ dá»¥ng Ä‘áº¡o hÃ m riÃªng $\frac{\partial y_{0,0}}{\partial x_{i,j}^0}$ vÃ  Ä‘Æ°á»£c tÃ­nh toÃ¡n qua back-propagation.  Vá»›i viá»‡c back-propagation sáº½ lan truyá»n ngÆ°á»£c lá»—i Ä‘áº¡o hÃ m(sai sá»‘ giá»¯a giÃ¡ trá»‹ output vÃ  labels) vá»›i hÃ m sá»‘ loss nháº¥t Ä‘á»‹nh. á» Ä‘Ã¢y, giáº£ sá»­ chÃºng ta cÃ³ hÃ m sá»‘ loss $l$ khi Ä‘Ã³ sá»­ dá»¥ng chain rule Ä‘á»ƒ tÃ­nh Ä‘áº¡o hÃ m chÃºng ta sáº½ cÃ³ $\frac{\partial l}{\partial x_{i,j}^0} =  \sum\nolimits_{i',j'}  \frac{\partial l}{\partial y_{i',j'}} .  \frac{\partial y_{i',j'}}{\partial x_{i,j}^0}$

Äá»ƒ láº¥y Ä‘Æ°á»£c $\frac{\partial y_{0,0}}{\partial x_{i,j}^0}$, chÃºng ta chá»‰ cáº§n set $\frac{\partial l}{\partial y_{0,0}} = 1$ vÃ  $\frac{\partial l}{\partial y_{i,j}} = 0$ cho táº¥t cáº£ nhá»¯ng vá»‹ trÃ­ $i \neq 0$ vÃ  $j \neq 0$. Sau Ä‘Ã³ thÃ¬ viá»‡c lan chuyá»n ngÆ°á»£c cá»§a máº¡ng nhÆ° bÃ¬nh thÆ°á»ng ta sáº½ Ä‘Æ°á»£c káº¿t quáº£ $\frac{\partial l}{\partial x_{i,j}^0}$ báº±ng vá»›i $\frac{\partial y_{0,0}}{\partial x_{i,j}^0}$
* **Váº­y cÃ¡i gÃ¬ sáº½ tÃ¡c Ä‘á»™ng Ä‘áº¿n sá»± thay Ä‘á»•i cá»§a ERF?**

1. *Dropout:*
Äá»‘i vá»›i dropout sáº½ khÃ´ng lÃ m thay Ä‘á»•i kÃ­ch thÆ°á»›c cá»§a ERF. Äiá»u nÃ y Ä‘Æ°á»£c xÃ¡c thá»±c trong [paper](https://arxiv.org/pdf/1701.04128.pdf)

2. *Sub-sampling & Diated convolutions:* 
NhÆ° ta cÃ³ thá»ƒ tháº¥y viá»‡c sub-sample vÃ  dialted tÃ¡c Ä‘á»™ng lÃªn ERF lÃ  ráº¥t lá»›n khi so sÃ¡nh vá»›i viá»‡c chá»‰ sá»­ dá»¥ng Conv Ä‘Æ¡n thuáº§n
![](https://images.viblo.asia/44b7040e-813c-472b-8718-753dfd31e996.png)

3. *Activation:* 
NhÆ° á»Ÿ hÃ¬nh bÃªn dÆ°á»›i cÃ³ thá»ƒ tháº¥y viá»‡c add ReLU activation lÃ m cho ERF giáº£m thiá»ƒu hiá»‡n tÆ°á»£ng Gaussian xuá»‘ng má»™t chÃºt
![](https://images.viblo.asia/b5718505-7f25-4fe1-b9bf-94ea3f59658f.png)

5. *Trong quÃ¡ trÃ¬nh training:* 
á» Ä‘Ã¢y tÃ¡c giáº£ cÃ³ sá»­ dá»¥ng 2 task, má»™t lÃ  classification vÃ  segmentation Ä‘á»ƒ lÃ m thÃ­ nghiá»‡m. NhÆ° ta cÃ³ thá»ƒ tháº¥y thÃ¬ trÆ°á»›c vÃ  sau khi training ERF cÃ³ tháº¥y Ä‘á»•i ráº¥t lá»›n. Äiá»u nÃ y cÃ³ thá»ƒ dá»± Ä‘oÃ¡n ráº±ng sau khi training model Ä‘Ã£ learn tá»‘t hÆ¡n vÃ  biáº¿t cÃ¡ch sá»­ dá»¥ng nhiá»u thuá»™c tÃ­nh á»Ÿ trÃªn input hÆ¡n.
![](https://images.viblo.asia/b3915870-2c37-4f87-a208-9429c30b36ff.png)

* **Má»™t sá»‘ chiáº¿n lÆ°á»£c giÃºp tÄƒng quy mÃ´ cá»§a ERF:**

NhÆ° Ä‘Ã£ nÃ³i ERF lÃ  má»™t dáº¡ng Gaussian distribution, vÃ¬ váº­y nÃ³ sáº½ bá»‹ suy giáº£m nhanh chÃ³ng tá»« tÃ¢m. Äiá»u nÃ y lÃ  khÃ´ng mong muá»‘n. Váº­y lÃ m sao Ä‘á»ƒ giáº£m thiá»ƒu tá»•n tháº¥t do Gaussian gÃ¢y lÃªn?

**New Initialization:** Khá»Ÿi táº¡o má»™t bá»™ trá»ng sá»‘ ngáº«u nhiÃªn sao cho trá»ng sá»‘ á»Ÿ trung tÃ¢m cá»§a kernel cÃ³ tá»‰ lá»‡ nhá» hÆ¡n trá»ng sá»‘ á»Ÿ bÃªn ngoÃ i, Ä‘iá»u nÃ y lÃ m cho viá»‡c khuáº¿ch tÃ¡n trá»ng sá»‘ á»Ÿ trung tÃ¢m ra ngoáº¡i vi. Trong thá»±c táº¿, chÃºng ta cÃ³ thá»ƒ lÃ m Ä‘iá»u nÃ y báº±ng cÃ¡ch khá»Ÿi táº¡o trá»ng sá»‘ nhÆ° thÃ´ng thÆ°á»ng, sau Ä‘Ã³ chá»‰ cáº§n chia tá»‰ lá»‡ trá»ng sá»‘ theo má»™t phÃ¢n phá»‘i vá»›i tá»‰ lá»‡ á»Ÿ trung tÃ¢m tháº¥p hÆ¡n tá»‰ lá»‡ bÃªn ngoÃ i.

CÃ³ má»™t lÆ°u Ã½ ráº±ng cho dÃ¹ chÃºng ta cÃ³ thay Ä‘á»•i W nhÆ° nÃ o Ä‘i ná»¯a thÃ¬ ERF váº«n cÃ³ phÃ¢n phá»‘i theo Gaussian, phÆ°Æ¡ng phÃ¡p trÃªn chá»‰ cÃ³ thá»ƒ lÃ m giáº£m thiá»ƒu Ä‘Æ°á»£c váº¥n Ä‘á» nÃ y.

**Architectural changes:** ÄÃ¢y cÃ³ láº½ lÃ  cÃ¡ch Ä‘Æ¡n giáº£n hÆ¡n cÃ¡ch trÃªn. Viá»‡c thay Ä‘á»•i kiáº¿n trÃºc cá»§a máº¡ng sáº½ giÃºp chÃºng ta thay Ä‘á»•i Ä‘Æ°á»£c ERF má»™t cÃ¡ch cÆ¡ báº£n nháº¥t. á» Ä‘Ã¢y vÃ­ dá»¥ chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng Sub-sampling hay dialted convolution.
# Káº¿t bÃ i
KhÃ´ng pháº£i lÃ  yáº¿u tá»‘ duy nháº¥t quyáº¿t Ä‘á»‹nh hiá»‡u suáº¥t cá»§a cá»§a model deep learning. NhÆ°ng khÃ´ng thá»ƒ phá»§ nháº­n Ä‘Æ°á»£c viá»‡c receptive field cÃ³ tÃ¡c Ä‘á»™ng ráº¥t lá»›n Ä‘áº¿n output cá»§a máº¡ng. Náº¿u chÃºng ta hiá»ƒu Ä‘Æ°á»£c táº§m quan trá»ng cá»§a nÃ³ vÃ  sá»­ dá»¥ng má»™t sá»‘ phÆ°Æ¡ng phÃ¡p giÃºp tÄƒng Ä‘Æ°á»£c kÃ­ch thÆ°á»›c cá»§a receptive field lÃªn sáº½ giÃºp cho model tÄƒng hiá»‡u suáº¥t Ä‘Ã¡ng ká»ƒ.

CÃ²n ná»¯a, náº¿u tháº¥y bÃ i viáº¿t há»¯u Ã­ch má»i ngÆ°á»i hÃ£y upvote cho mÃ¬nh nhÃ© hoáº·c má»i ngÆ°á»i cÃ³ báº¥t ká»³ tháº¯c máº¯c nÃ o hÃ£y comment phÃ­a bÃªn dÆ°á»›i áº¡.
# References:
1. [Understanding the effective receptive field in semantic image segmentation](https://link.springer.com/article/10.1007/s11042-018-5704-3)
2. [Understanding the Effective Receptive Field in Deep Convolutional Neural Networks](https://arxiv.org/pdf/1701.04128.pdf)
3. [A Guide to Receptive Field Arithmetic for Convolutional Neural Networks](https://syncedreview.com/2017/05/11/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks/)
4. [Máº¡ng neural tÃ­ch cháº­p cheatsheet](https://stanford.edu/~shervine/l/vi/teaching/cs-230/cheatsheet-convolutional-neural-networks#hyperparameters)