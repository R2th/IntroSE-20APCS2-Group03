Tiáº¿p tá»¥c series Paper Explain Ä‘ang dang dá»Ÿ vá» topic Action Recognition, trong bÃ i viáº¿t nÃ y, mÃ¬nh muá»‘n bÃ n má»™t chÃºt vá» data: **Data Augmentation**. 

Cháº¯c má»i ngÆ°á»i cÅ©ng Ä‘Ã£ biáº¿t rá»“i, bÃªn cáº¡nh má»™t model tá»‘t, thá»© áº£nh hÆ°á»Ÿng trá»±c tiáº¿p Ä‘áº¿n káº¿t quáº£ Ä‘áº§u ra, Ä‘Ã³ lÃ  cháº¥t lÆ°á»£ng cá»§a dá»¯ liá»‡u. Viá»‡c xÃ¢y dá»±ng Ä‘Æ°á»£c má»™t bá»™ dá»¯ liá»‡u sáº¡ch, sá»‘ lÆ°á»£ng lá»›n, tÃ­nh tá»•ng quÃ¡t cao Ä‘Ã´i khi improve cÃ²n tá»‘t hÆ¡n viá»‡c sá»­ dá»¥ng nhá»¯ng model háº§m há»‘ trÃªn nhá»¯ng bá»™ dá»¯ liá»‡u kÃ©m. Vá»›i nhá»¯ng bá»™ dá»¯ liá»‡u nhá», data augmentation chÃ­nh lÃ  keyword cáº§n pháº£i quan tÃ¢m.

Náº¿u nhÆ° cÃ¡c bÃ i toÃ¡n image classification hay object detection vá»‘n Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng ráº¥t nhiá»u phÆ°Æ¡ng phÃ¡p augment khÃ¡c nhau, action recognition láº¡i ráº¥t Ã­t nghiÃªn cá»©u bÃ n vá» váº¥n Ä‘á» nÃ y. Paper mÃ¬nh muá»‘n phÃ¢n tÃ­ch hÃ´m nay lÃ  má»™t sá»‘ Ã­t hiáº¿m hoi Ä‘á» cáº­p Ä‘áº¿n viá»‡c augment cho video, Ä‘áº·c biá»‡t lÃ  vá» temporal augmentation (máº·c dÃ¹ hÆ¡i outdate - tá»« 2020). 

***Note: BÃ i nÃ y sáº½ nhiá»u code vÃ  hÃ¬nh minh há»a thay vÃ¬ nhiá»u lÃ­ thuyáº¿t + cÃ´ng thá»©c nhÆ° bÃ i phÃ¢n tÃ­ch trÆ°á»›c.***

![imgur](https://i.imgur.com/qfXANBg.png)
# 1. Tá»•ng quan
Äáº§u tiÃªn, Ä‘á»ƒ láº¡i thÃ´ng tin liÃªn quan trÆ°á»›c:
- paper: Learning Temporally Invariant and Localizable Features via Data Augmentation for Video Recognition
- link: https://arxiv.org/pdf/2008.05721.pdf (ECCV Workshop 2020)
- github: https://github.com/taeoh-kim/temporal_data_augmentation

Äá»ƒ má»i ngÆ°á»i dá»… theo dÃµi, mÃ¬nh sáº½ tÃ³m táº¯t láº¡i má»™t lÆ°á»£t vá» cÃ¡c kÄ© thuáº­t augmentation thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c bÃ i toÃ¡n Computer Vison thÃ´ng thÆ°á»ng. 
- **In-network Augmentation**: ÄÃ¢y lÃ  cÃ¡c kÄ© thuáº­t táº­p trung vÃ o thiáº¿t káº¿ cÃ¡c kiáº¿n trÃºc máº¡ng, Ä‘á»ƒ Ã¡p dá»¥ng augmentation á»Ÿ má»©c feature trong quÃ¡ trÃ¬nh training. Viá»‡c nÃ y lÃ m giáº£m predictive variance, Ä‘á»“ng thá»i giÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c nhá»¯ng high-level augmented thay vÃ¬ nhá»¯ng low-level augmentation. Nhá»¯ng kÄ© thuáº­t nÃ y cÃ²n Ä‘Æ°á»£c biáº¿t Ä‘áº¿n lÃ  kÄ© thuáº­t regularization.
    - Dropout
    - DropBlock
    - DropBlock
    - Shake-Shake
    - ShakeDrop
    - Random Mean Scaling
- **Data-level Augmentation**: ÄÃ¢y lÃ  cÃ¡c kÄ© thuáº­t táº­p trung vÃ o viá»‡c biáº¿n Ä‘á»‘i data Ä‘áº§u vÃ o (á»Ÿ Ä‘Ã¢y lÃ  image), lÃ m tÄƒng Ä‘á»™ Ä‘a dáº¡ng vÃ  tá»•ng quÃ¡t cá»§a dá»¯ liá»‡u, tá»« Ä‘Ã³ giÃºp mÃ´ hÃ¬nh táº­p trung vÃ o cÃ¡c feature báº¥t biáº¿n trong dá»¯ liá»‡u (invariant features). Ta cÃ³ thá»ƒ tiáº¿p tá»¥c chia nhá» cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y tiáº¿p thÃ nh 3 nhÃ³m nhá» hÆ¡n: 
    - Geometric Transformation: cropping, flipping, rotating, shearing, translating, ...
    - Photometric Transformation: brightness, contrast, color, ...
    -  Localizable features Augmentation: (thÆ°á»ng Ã¡p dá»¥ng cÃ¡c task liÃªn quan Ä‘áº¿n localization cá»§a Ä‘á»‘i tÆ°á»£ng, vÃ­ dá»¥ nhÆ° object detection): CutOut, Hide-and-Seek, ...

    NgoÃ i ra, nhá»¯ng phÆ°Æ¡ng phÃ¡p káº¿t há»£p nhiá»u kÄ© thuáº­t augment khÃ¡c nhau, vá»›i má»™t há»‡ sá»‘ ngáº«u nhiÃªn cÅ©ng Ä‘em láº¡i nhá»¯ng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ: RandAugment, AugMix, ...
- **Data-level Mixing**: CÃ¹ng vá»›i augmentation trÃªn 1 sample, cÃ¡c chiáº¿n lÆ°á»£c augment sá»­ dá»¥ng nhiá»u sample hÆ¡n cÅ©ng Ä‘Æ°á»£c nghiÃªn cá»©u vÃ  Ã¡p dá»¥ng, phá»• biáº¿n nháº¥t lÃ  trÃªn cÃ¡c tÃ¡c vá»¥ object detection. 
    - MixUp: tiáº¿n hÃ nh blend 2 hÃ¬nh áº£nh báº¥t kÃ¬ Ä‘á»ƒ táº¡o ra 1 áº£nh má»›i, vá»›i label má»›i Ä‘Æ°á»£c ná»™i suy tá»« label cá»§a 2 áº£nh
    - CutMix: Káº¿t há»£p Ã½ tÆ°á»Ÿng cá»§a CutOut vÃ  MixUp, tiáº¿n hÃ nh thay tháº¿ vÃ¹ng bá»‹ xÃ³a trong hÃ¬nh áº£nh cá»§a CutOut báº±ng 1 báº£n vÃ¡ tá»« hÃ¬nh áº£nh khÃ¡c.
    - CutBlur: Láº¥y cáº£m há»©ng tá»« CutMix, tiáº¿n hÃ nh cut-and-paste giá»¯a áº£nh cÃ³ Ä‘á»™ phÃ¢n giáº£i tháº¥p vÃ  áº£nh cÃ³ Ä‘á»™ phÃ¢n giáº£i cao.
    - CutMixUp: Káº¿t há»£p tá»« CutMix vÃ  MixUp
    - Attribute Mix
    - Attentive CutMix
    - Smoothmix

Máº·c dÃ¹ nhiá»u phÆ°Æ¡ng phÃ¡p augment dá»¯ liá»‡u, bao gá»“m deleting, blending, cut-and-pasting, ... Ä‘Ã£ tÄƒng cÆ°á»ng thÃ nh cÃ´ng nhiá»u táº­p dá»¯ liá»‡u hÃ¬nh áº£nh, viá»‡c Ã¡p dá»¥ng nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ y cho action recognition chÆ°a tháº­t sá»± hiá»‡u quáº£. NhÃ³m tÃ¡c giáº£ paper nháº­n Ä‘á»‹nh, Ä‘á»ƒ Ã¡p dá»¥ng tá»‘t trÃªn video, cÃ¡c phÆ°Æ¡ng phÃ¡p augment cáº§n cÃ³ kháº£ nÄƒng mÃ´ hÃ¬nh hÃ³a Ä‘Æ°á»£c **temporally invariant** vÃ  **temporal localizable features**. 

Tá»« Ä‘Ã¢y, paper Ä‘á» xuáº¥t cÃ¡c phiÃªn báº£n cáº£i tiáº¿n cá»§a nhá»¯ng phÆ°Æ¡ng phÃ¡p augment hiá»‡n táº¡i, táº­p trung hÆ¡n vÃ o yáº¿u tá»‘ thá»i gian, cÃ¡i mÃ  chÃºng ta sáº½ bÃ n sÃ¢u hÆ¡n trong pháº§n sau cá»§a bÃ i viáº¿t.
# 2. Temporal Data Augmentations
Äá» xuáº¥t Ä‘áº§u tiÃªn cá»§a paper lÃ  RandAugment-T (má»™t phiÃªn báº£n cáº£i tiáº¿n cá»§a RandAugment)

Khi Ã¡p dá»¥ng vÃ o video, RandAugment thÆ°á»ng Ã¡p dá»¥ng cÃ¡c augment giá»‘ng nhau cho má»i khung hÃ¬nh cá»§a video, tuy nhiÃªn, Ä‘iá»u nÃ y háº¡n cháº¿ kháº£ nÄƒng mÃ´ hÃ¬nh hÃ³a temporal perturbation. RandAugment-T, cáº£i tiáº¿n hÆ¡n, tiáº¿n hÃ nh ná»™i suy tuyáº¿n tÃ­nh giá»¯a má»©c Ä‘á»™ augment tá»« khung hÃ¬nh Ä‘áº§u tiÃªn Ä‘áº¿n khung hÃ¬nh cuá»‘i cÃ¹ng, tá»« Ä‘Ã³ táº¡o sá»± biáº¿n Ä‘á»•i trong suá»‘t video. 

DÆ°á»›i Ä‘Ã¢y lÃ  mÃ£ giáº£ cá»§a RandAugment-T
```python
def randaugment_T(X, N, M1, M2):
    """Generate a set of distortions.
    Args:
    X: Input video (T x H x W)
    N: Number of augmentation transformations
    to apply sequentially.
    M1, M2: Magnitudes for both temporal ends.
    """
    ops = np.random.choice(transforms, N)
    M = np.linspace(M1, M2, T)
    return [[op(X, M[t]) for t in range(T)]
    for op in ops]
```
Trong Ä‘Ã³, **transform** á»Ÿ Ä‘Ã¢y bao gá»“m 1 list cÃ¡c data-level augmentation bao gá»“m cáº£ Geometric Transformation vÃ  Photometric Transformation. Äá»ƒ dá»… hÃ¬nh dung nháº¥t, mÃ¬nh sáº½ implement láº¡i code + cÃ³ visualization cá»¥ thá»ƒ cho tá»«ng phÆ°Æ¡ng phÃ¡p.
```python
# Äáº§u tiÃªn, import nhá»¯ng thÆ° viá»‡n cáº§n thiáº¿t
import cv2
import copy
import random
import numpy as np
from PIL import Image, ImageOps, ImageEnhance
```
ChÃºng ta sáº½ báº¯t Ä‘áº§u vá»›i 1 video sample trong táº­p dataset cá»§a BKAI-NAVER Challenge lÃ m vÃ­ dá»¥. 

![](https://images.viblo.asia/5982127e-787d-4777-8df1-bb6999fc0fb8.gif)

```python
def temporal_interpolate(v_list, t, n):
    if len(v_list) == 1:
        return v_list[0]
    elif len(v_list) == 2:
        return v_list[0] + (v_list[1] - v_list[0]) * t / n
    else:
        NotImplementedError('Invalid degree')
```
- Geometric Transformation
    - **Shear X**

        ```python
        def shear_x(imgs, v_list=[-0.3, 0.3]):
            for v in v_list:
                assert -0.3 <= v <= 0.3
            if random.random() > 0.5:
                v_list = [-v for v in v_list]

            out = [img.transform(img.size, Image.AFFINE, (1, temporal_interpolate(v_list, t, len(imgs) - 1), 0, 0, 1, 0)) for t, img in enumerate(imgs)]
            return out
        ```

        ![](https://images.viblo.asia/b7b77a37-6b90-4d5a-b4dd-8780bc17acb1.gif)

    - **Shear Y**

        ```python
        def shear_y(imgs, v_list=[-0.3, 0.3]):
            for v in v_list:
                assert -0.3 <= v <= 0.3
            if random.random() > 0.5:
                v_list = [-v for v in v_list]

            out = [img.transform(img.size, Image.AFFINE, (1, 0, 0, temporal_interpolate(v_list, t, len(imgs) - 1), 1, 0)) for t, img in enumerate(imgs)]
            return out
        ```

        ![](https://images.viblo.asia/8a3c55c3-2b30-4054-bba2-3f716f045329.gif)

    - **Translate X**

        ```python
        def translate_x(imgs, v_list=[-80, 80]):  # [-150, 150] => percentage: [-0.45, 0.45]
            for v in v_list:
                assert -150 <= v <=150
            if random.random() > 0.5:
                v_list = [-v for v in v_list]

            out = [img.transform(img.size, Image.AFFINE, (1, 0, temporal_interpolate(v_list, t, len(imgs) - 1), 0, 1, 0)) for t, img in enumerate(imgs)]
            return out
        ```

        ![](https://images.viblo.asia/72f29358-80b4-44d8-ab90-ad70ddbfe674.gif)

    - **Translate Y**

        ```python
        def translate_y(imgs, v_list=[-50, 50]):  # [-150, 150] => percentage: [-0.45, 0.45]
                for v in v_list:
                    assert -150 <= v <=150
                if random.random() > 0.5:
                    v_list = [-v for v in v_list]

                out = [img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, temporal_interpolate(v_list, t, len(imgs) - 1))) for t, img in enumerate(imgs)]
                return out
        ```

        ![](https://images.viblo.asia/79517a17-c900-4a1f-8c91-8c565731374b.gif)

    - **Rotate**

```python
def rotate(imgs, v_list=[-30, 30]):  # [-30, 30]
    for v in v_list:
        assert -30 <= v <= 30
    if random.random() > 0.5:
        v_list = [-v for v in v_list]

    out = [img.rotate(temporal_interpolate(v_list, t, len(imgs) - 1)) for t, img in enumerate(imgs)]
    return out
```

![](https://images.viblo.asia/2bd1d754-8d73-4126-bc55-33063e5c8d1f.gif)

- Photometric Transformation
    - **Solarize**

        ```python
        def solarize(imgs, v_list=[128, 256]):  # [0, 256]
            for v in v_list:
                assert 0 <= v <= 256

            out = [ImageOps.solarize(img, temporal_interpolate(v_list, t, len(imgs) - 1)) for t, img in enumerate(imgs)]
            return out
        ```

        ![](https://images.viblo.asia/777f3353-85f8-4c3d-9a24-d7c6af375fe8.gif)

    - **Color**

        ```python
        def color(imgs, v_list=[0.1,1.9]):  # [0.1,1.9]
            for v in v_list:
                assert 0.1 <= v <= 1.9

            out = [ImageEnhance.Color(img).enhance(temporal_interpolate(v_list, t, len(imgs) - 1)) for t, img in enumerate(imgs)]
            return out
        ```

        ![](https://images.viblo.asia/19207309-764d-46ee-835d-a1e3795295fb.gif)

    - **Posterize**

        ```python
        def posterize(imgs, v_list=[4, 8]):  # [4, 8]
            v_list = [max(1, int(v)) for v in v_list]

            out = [ImageOps.posterize(img, int(temporal_interpolate(v_list, t, len(imgs) - 1))) for t, img in enumerate(imgs)]
            return out
        ```

        ![](https://images.viblo.asia/b027d5d9-09e2-4109-a721-fb0390575e23.gif)

    - **Contrast** 

        ```python
        def contrast(imgs, v_list=[0.1,1.9]):  # [0.1,1.9]
            for v in v_list:
                assert 0.1 <= v <= 1.9

            out = [ImageEnhance.Contrast(img).enhance(temporal_interpolate(v_list, t, len(imgs) - 1)) for t, img in enumerate(imgs)]
            return out
        ```

        ![](https://images.viblo.asia/99cd1999-6210-4f69-9bdd-548959f7b34d.gif)

    - **Brightness** 

        ```python
        def brightness(imgs, v_list=[0.1,1.9]):  # [0.1,1.9]
            for v in v_list:
                assert 0.1 <= v <= 1.9

            out = [ImageEnhance.Brightness(img).enhance(temporal_interpolate(v_list, t, len(imgs) - 1)) for t, img in enumerate(imgs)]
            return out
        ```

        ![](https://images.viblo.asia/cc50ad3a-c783-4c45-9706-4fa5195b8ef2.gif)

    - **Sharpness**

        ```python
        def sharpness(imgs, v_list=[0.1,1.9]):  # [0.1,1.9]
            for v in v_list:
                assert 0.1 <= v <= 1.9

            out = [ImageEnhance.Sharpness(img).enhance(temporal_interpolate(v_list, t, len(imgs) - 1)) for t, img in enumerate(imgs)]
            return out
        ```

        ![](https://images.viblo.asia/7917384f-8ebd-42ac-be55-129963de369f.gif)

# 3. Temporal Deleting, Blending, Cut-and-Pasting
Paper cÅ©ng Ä‘á»“ng thá»i Ä‘á» xuáº¥t cÃ¡c biáº¿n thá»ƒ cá»§a data-level Mixing, táº­p trung vÃ o temporal localizable features, chá»§ yáº¿u liÃªn quan Ä‘áº¿n viá»‡c transform giá»¯a cÃ¡c frame. 

Do data-level Mixing tiáº¿n hÃ nh augment dá»±a trÃªn nhiá»u sample, á»Ÿ Ä‘Ã¢y, mÃ¬nh sáº½ dÃ¹ng thÃªm 1 video ná»¯a Ä‘á»ƒ láº¥y vÃ­ dá»¥ minh há»a: 

![](https://images.viblo.asia/ce06781b-72a4-4971-9457-0a9f4bdc0982.gif)

```python
def rand_bbox(imgs, lam, type):
    T = len(imgs)
    H, W = imgs[0].size

    if type in ['cutmix', 'cutmixup']:
        cut_rat = np.sqrt(1. - lam)
        cut_w = np.int32(W * cut_rat)
        cut_h = np.int32(H * cut_rat)

        cx = np.random.randint(W)
        cy = np.random.randint(H)

        bbt1 = 0
        bbx1 = np.clip(cx - cut_w // 2, 0, W)
        bby1 = np.clip(cy - cut_h // 2, 0, H)
        bbt2 = T
        bbx2 = np.clip(cx + cut_w // 2, 0, W)
        bby2 = np.clip(cy + cut_h // 2, 0, H)
    elif type in ['framemix', 'framemixup']:
        cut_rat = 1. - lam
        cut_t = np.int32(T * cut_rat)

        ct = np.random.randint(T)

        bbt1 = np.clip(ct - cut_t // 2, 0, T)
        bbx1 = 0
        bby1 = 0
        bbt2 = np.clip(ct + cut_t // 2, 0, T)
        bbx2 = W
        bby2 = H
    else: # spatio-temporal, cubemix
        cut_rat = np.power(1. - lam, 1./3.)
        cut_t = np.int32(T * cut_rat)
        cut_w = np.int32(W * cut_rat)
        cut_h = np.int32(H * cut_rat)

        ct = np.random.randint(T)
        cx = np.random.randint(W)
        cy = np.random.randint(H)

        bbt1 = np.clip(ct - cut_t // 2, 0, T)
        bbx1 = np.clip(cx - cut_w // 2, 0, W)
        bby1 = np.clip(cy - cut_h // 2, 0, H)
        bbt2 = np.clip(ct + cut_t // 2, 0, T)
        bbx2 = np.clip(cx + cut_w // 2, 0, W)
        bby2 = np.clip(cy + cut_h // 2, 0, H)

    return bbt1, bbx1, bby1, bbt2, bbx2, bby2
```

(á» Ä‘Ã¢y do code CutOut vÃ  CutMix lÃ  tÆ°Æ¡ng tá»± nhau, nÃªn chÃºng ta sáº½ bá» qua cÃ¡c pháº§n liÃªn quan Ä‘áº¿n CutOut)
- **CutMix**

    ```python
    def cut_mix(imgs, replace_imgs, beta=1.0):
        new_imgs = copy.deepcopy(imgs)
        lam = np.random.beta(beta, beta)
        bbt1, bbx1, bby1, bbt2, bbx2, bby2 = rand_bbox(imgs, lam, type='cutmix')
        for t in range(bbt1, bbt2):
            img = np.array(imgs[t])
            replace_img = np.array(replace_imgs[t])
            img[bby1:bby2, bbx1:bbx2, :] = replace_img[bby1:bby2, bbx1:bbx2, :]
            new_imgs[t] = Image.fromarray(img)
        return new_imgs
    ```

    ![](https://images.viblo.asia/83d6ea3e-7725-4eb3-bc2d-945bcfb7f915.gif)

- **FrameMix**

    ```python
    def frame_mix(imgs, replace_imgs, beta=1.0):
        new_imgs = copy.deepcopy(imgs)
        lam = np.random.beta(beta, beta)
        bbt1, bbx1, bby1, bbt2, bbx2, bby2 = rand_bbox(imgs, lam, type='framemix')
        for t in range(bbt1, bbt2):
            img = np.array(imgs[t])
            replace_img = np.array(replace_imgs[t])
            img[bby1:bby2, bbx1:bbx2, :] = replace_img[bby1:bby2, bbx1:bbx2, :]
            new_imgs[t] = Image.fromarray(img)
        return new_imgs
    ```

    ![](https://images.viblo.asia/0f5f4470-df6f-498a-8dca-3c2fc55cd357.gif)

- **CubeMix**

    ```python
    def cube_mix(imgs, replace_imgs, beta=1.0):
        new_imgs = copy.deepcopy(imgs)
        lam = np.random.beta(beta, beta)
        bbt1, bbx1, bby1, bbt2, bbx2, bby2 = rand_bbox(imgs, lam, type='cubemix')
        for t in range(bbt1, bbt2):
            img = np.array(imgs[t])
            replace_img = np.array(replace_imgs[t])
            img[bby1:bby2, bbx1:bbx2, :] = replace_img[bby1:bby2, bbx1:bbx2, :]
            new_imgs[t] = Image.fromarray(img)
        return new_imgs
    ```

    ![](https://images.viblo.asia/9dc19a93-beac-41d4-be34-91ec5acc24b9.gif)

- **MixUp**

    ```python
    def mixup(imgs, replace_imgs, beta=1.0):
        new_imgs = copy.deepcopy(imgs)
        lam = np.random.beta(beta, beta)
        for t in range(len(imgs)):
            img = np.array(imgs[t])
            replace_img = np.array(replace_imgs[t])
            new_img = img * lam + replace_img * (1. - lam)
            new_imgs[t] = Image.fromarray(new_img.astype(np.uint8))
        return new_imgs
    ```

    ![](https://images.viblo.asia/af08cc96-8abe-4a7b-af0b-4303b65e0f3c.gif)

- **FrameMixUp**

    ```python
    def frame_mixup(imgs, replace_imgs, beta=1.0):
        new_imgs = copy.deepcopy(imgs)
        # Sample Mixing Coordinates
        lam = np.random.beta(beta, beta)
        bbt1, bbx1, bby1, bbt2, bbx2, bby2 = rand_bbox(imgs, lam, type='framemixup')
        # adjust lambda to exactly match pixel ratio
        T = len(imgs)
        H, W = imgs[0].size
        lam = 1 - ((bbt2 - bbt1) * (bbx2 - bbx1) * (bby2 - bby1) / (T * H * W))
        lamt = np.random.beta(2.0, 2.0)
        for t in range(len(imgs)):
            img = np.array(imgs[t])
            replace_img = np.array(replace_imgs[t])
            new_img = img * lamt + replace_img * (1. - lamt)
            fr = np.random.rand(1)
            if fr < 0.5:  # Basic MixUp, 0.5 Prob FrameMixUp
                if lamt >= 0.5:
                    if bbt1 <= t < bbt2:
                        new_img[bby1:bby2, bbx1:bbx2, :] = replace_img[bby1:bby2, bbx1:bbx2, :]
                    lam = lamt * lam
                else:
                    if bbt1 <= t < bbt2:
                        new_img[bby1:bby2, bbx1:bbx2, :] = img[bby1:bby2, bbx1:bbx2, :]
                    lam = lamt * lam + (1 - lam)
            new_imgs[t] = Image.fromarray(new_img.astype(np.uint8))
        return new_imgs
    ```

    ![](https://images.viblo.asia/021e4476-3a69-42a2-902c-63a345d93213.gif)

- **CubeMixUp**

    ```python
    def cube_mixup(imgs, replace_imgs, beta=1.0):
        new_imgs = copy.deepcopy(imgs)
        # Sample Mixing Coordinates
        lam = np.random.beta(beta, beta)
        bbt1, bbx1, bby1, bbt2, bbx2, bby2 = rand_bbox(imgs, lam, type='cubemixup')
        # adjust lambda to exactly match pixel ratio
        T = len(imgs)
        H, W = imgs[0].size
        lam = 1 - ((bbt2 - bbt1) * (bbx2 - bbx1) * (bby2 - bby1) / (T * H * W))
        lamt = np.random.beta(2.0, 2.0)
        for t in range(len(imgs)):
            img = np.array(imgs[t])
            replace_img = np.array(replace_imgs[t])
            new_img = img * lamt + replace_img * (1. - lamt)
            fr = np.random.rand(1)
            if fr < 0.5:  # Basic MixUp, 0.5 Prob FrameMixUp
                if lamt >= 0.5:
                    if bbt1 <= t < bbt2:
                        new_img[bby1:bby2, bbx1:bbx2, :] = replace_img[bby1:bby2, bbx1:bbx2, :]
                    lam = lamt * lam
                else:
                    if bbt1 <= t < bbt2:
                        new_img[bby1:bby2, bbx1:bbx2, :] = img[bby1:bby2, bbx1:bbx2, :]
                    lam = lamt * lam + (1 - lam)
            new_imgs[t] = Image.fromarray(new_img.astype(np.uint8))
        return new_imgs
    ```

    ![](https://images.viblo.asia/1a81b960-be56-43ef-9d08-11868942e65a.gif)

- **CutMixUp**

    ```python
    def cut_mixup(imgs, replace_imgs, beta=1.0):
        new_imgs = copy.deepcopy(imgs)
        # Sample Mixing Coordinates
        lam = np.random.beta(beta, beta)
        bbt1, bbx1, bby1, bbt2, bbx2, bby2 = rand_bbox(imgs, lam, type='cutmixup')
        # adjust lambda to exactly match pixel ratio
        T = len(imgs)
        H, W = imgs[0].size
        lam = 1 - ((bbt2 - bbt1) * (bbx2 - bbx1) * (bby2 - bby1) / (T * H * W))
        lamt = np.random.beta(2.0, 2.0)
        for t in range(len(imgs)):
            img = np.array(imgs[t])
            replace_img = np.array(replace_imgs[t])
            new_img = img * lamt + replace_img * (1. - lamt)
            fr = np.random.rand(1)
            if fr < 0.5:  # Basic MixUp, 0.5 Prob FrameMixUp
                if lamt >= 0.5:
                    if bbt1 <= t < bbt2:
                        new_img[bby1:bby2, bbx1:bbx2, :] = replace_img[bby1:bby2, bbx1:bbx2, :]
                    lam = lamt * lam
                else:
                    if bbt1 <= t < bbt2:
                        new_img[bby1:bby2, bbx1:bbx2, :] = img[bby1:bby2, bbx1:bbx2, :]
                    lam = lamt * lam + (1 - lam)
            new_imgs[t] = Image.fromarray(new_img.astype(np.uint8))
        return new_imgs
    ```

    ![](https://images.viblo.asia/55780c86-be5e-4e73-954f-ee5a0b40752a.gif)

- **FadeMixUp**

```python
def fade_mixup(imgs, replace_imgs, beta=1.0):
    new_imgs = copy.deepcopy(imgs)
    lam = np.random.beta(beta, beta)
    adj = np.random.choice([-1, 1]) * np.random.uniform(0, min(lam, 1.0 - lam))
    fade = np.linspace(lam - adj, lam + adj, num=len(imgs))
    for t in range(len(imgs)):
        img = np.array(imgs[t])
        replace_img = np.array(replace_imgs[t])
        new_img = img * fade[t] + replace_img * (1. - fade[t])
        new_imgs[t] = Image.fromarray(new_img.astype(np.uint8))
    return new_imgs
```

![](https://images.viblo.asia/271de9a6-156e-4c5d-9e7d-3cf364a37032.gif)

# 4. Káº¿t luáº­n
CÃ¡ nhÃ¢n mÃ¬nh thÃ¬ mÃ¬nh tháº¥y bÃ i viáº¿t nÃ y khÃ´ng mang Ä‘Ãºng tÃ­nh cháº¥t cá»§a "Explain Paper" láº¯m :D CÆ¡ mÃ  khÃ´ng sao, vá»›i dá»¯ liá»‡u, cÃ¡ch mÃ´ táº£ dá»… hiá»ƒu nháº¥t lÃ  visualize, Ä‘áº·c biá»‡t trong trÆ°á»ng há»£p cá»§a paper nÃ y - giá»›i thiá»‡u cÃ¡c phÆ°Æ¡ng phÃ¡p augment data. Hi vá»ng cÃ¡ch tiáº¿p cáº­n nÃ y sáº½ giÃºp cÃ¡c báº¡n cÃ³ há»©ng thÃº hÆ¡n vá»›i ná»™i dung paper (vÃ¬ tháº­t sá»± Ã½ tÆ°á»Ÿng cá»§a paper cÅ©ng khÃ¡ Ä‘Æ¡n giáº£n). 

Náº¿u tháº¥y hay, Ä‘á»«ng quÃªn upvote + share bÃ i viáº¿t Ä‘á»ƒ tiáº¿p thÃªm Ä‘á»™ng lá»±c cho mÃ¬nh. ChÃºc má»i ngÆ°á»i má»™t ngÃ y lÃ m viá»‡c vÃ  há»c táº­p hiá»‡u quáº£. Seeya ğŸ‘‹