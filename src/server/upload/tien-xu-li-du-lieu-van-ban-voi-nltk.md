# Giá»›i thiá»‡u
Tiá»n xá»­ lÃ­ dá»¯ liá»‡u lÃ  giai Ä‘oáº¡n ráº¥t quan trá»ng, hay nÃ³i cÃ¡ch khÃ¡c Ä‘Ã¢y lÃ  cÃ´ng Ä‘oáº¡n lÃ m sáº¡ch vÄƒn báº£n. Viá»‡c vÄƒn báº£n Ä‘Æ°á»£c lÃ m sáº¡ch giÃºp cÃ¡ch thuáº­t toÃ¡n cÃ³ thá»ƒ trÃ­ch xuáº¥t Ä‘Æ°á»£c nhá»¯ng Ä‘áº·c trÆ°ng tá»‘t nháº¥t tá»« Ä‘Ã³ nÃ¢ng cao hiá»‡u quáº£, cháº¥t lÆ°á»£ng cá»§a cÃ¡c mÃ´ hÃ¬nh, thuáº­t toÃ¡n. 

## ThÆ° viá»‡n NLTK
ThÆ° viá»‡n [NLTK](https://www.nltk.org/) - Natural Language Toolkit lÃ  má»™t trong nhá»¯ng thÆ° viá»‡n open-source xá»­ lÃ­ ngÃ´n ngá»¯ tá»± nhiÃªn. ÄÆ°á»£c viáº¿t báº±ng Python vÃ  vá»›i Æ°u Ä‘iá»ƒm lÃ  dá»… dÃ ng sá»­ dá»¥ng nÃªn thÆ° viá»‡n nÃ y ngÃ y cÃ ng trá»Ÿ nÃªn phá»• biáº¿n vÃ  cÃ³ Ä‘Æ°á»£c má»™t cá»™ng Ä‘á»“ng lá»›n máº¡nh. ThÆ° viá»‡n cung cáº¥p hÆ¡n 50 kho dá»¯ liá»‡u vÄƒn báº£n khÃ¡c nhau (corpora) vÃ  nhiá»u chá»©c nÄƒng Ä‘á»ƒ xá»­ lÃ­ dá»¯ liá»‡u vÄƒn báº£n Ä‘á»ƒ phá»¥c vá»¥ cho nhiá»u má»¥c Ä‘Ã­ch khÃ¡c nhau. CÃ i thÆ° viá»‡n NLTK vá»›i pip `pip install nltk`.
# Tiá»n xá»­ lÃ­ dá»¯ liá»‡u vÄƒn báº£n
Äá»ƒ trá»±c quan mÃ¬nh sáº½ tiá»n xá»­ lÃ­ ná»™i dung cá»§a quyá»ƒn The War of the Worlds cá»§a tÃ¡c giáº£ H. G. Wells Ä‘Æ°á»£c táº£i tá»« trang [Gutenberg](https://www.gutenberg.org/). Ta táº£i sÃ¡ch vÃ  Ä‘á»c ná»™i dung quyá»ƒn sÃ¡ch nhÆ° sau:
```
wget https://www.gutenberg.org/files/36/36-0.txt
with open("/content/36-0.txt", encoding='utf-8-sig') as f:
    raw_text = f.read()
```
Sau khi quan sÃ¡t ná»™i dung quyá»ƒn sÃ¡ch thÃ¬ trÆ°á»›c tiÃªn ta cáº§n loáº¡i bá» cÃ¡c kÃ­ tá»± xuá»‘ng dÃ²ng `\n`:
```
raw_text = raw_text.replace("\n", " ")
```
## Biáº¿n Ä‘á»•i vá» chá»¯ thÆ°á»ng
NhÆ° tÃªn thÃ¬ Ä‘Æ¡n giáº£n lÃ  ta chuyá»ƒn táº¥t cáº£ cÃ¡c chá»¯ in hoa vá» chá»¯ thÆ°á»ng. ÄÃ¢y lÃ  cÃ¡ch Ä‘Æ¡n giáº£n nhÆ°ng cÅ©ng ráº¥t hiá»‡u quáº£ trong viá»‡c tiá»n xá»­ lÃ­ dá»¯ liá»‡u vÄƒn báº£n, Ä‘áº·c biá»‡t lÃ  Ä‘á»‘i vá»›i nhá»¯ng bá»™ dá»¯ liá»‡u nhá». 
```
raw_text = raw_text.lower()
```
Sau khi quan sÃ¡t Ä‘oáº¡n vÄƒn báº£n thÃ¬ trÆ°á»›c tiÃªn ta pháº£i loáº¡i bá» cÃ¡c kÃ­ tá»±
## TÃ¡ch cÃ¡c cÃ¢u
Tá»« má»™t Ä‘oáº¡n vÄƒn báº£n gá»“m nhiá»u cÃ¢u thÃ¬ thÃ´ng qua bÆ°á»›c nÃ y ta thu Ä‘Æ°á»£c cÃ¡c cÃ¢u thÃ nh pháº§n. Äá»ƒ nháº­n biáº¿t má»™t cÃ¢u Ä‘Æ¡n giáº£n nháº¥t lÃ  khi gáº·p dáº¥u "." káº¿t thÃºc cÃ¢u, chÃºng ta hoÃ n toÃ n cÃ³ thá»ƒ sá»­ dá»¥ng hÃ m split() trong python vÃ  tÃ¡ch cÃ¢u má»—i khi gáº·p dáº¥u ".". Tuy nhiÃªn, khÃ´ng pháº£i lÃºc nÃ o dáº¥u "." cÅ©ng lÃ  káº¿t thÃºc cÃ¢u, vÃ­ dá»¥ trong tiáº¿ng anh, tá»« "Mr. Smith" thÃ¬ náº¿u ta dÃ¹ng cÃ¡ch trÃªn Ä‘á»ƒ bÃ³c tÃ¡ch cÃ¡c cÃ¢u thÃ¬ sáº½ sai. Äá»ƒ cÃ³ thá»ƒ tÃ¡ch cÃ¡c cÃ¢u chÃ­nh xÃ¡c thÃ¬ viá»‡c sá»­ dá»¥ng cÃ¡c thÆ° viá»‡n há»— trá»£ lÃ  biá»‡n phÃ¡p Ä‘Æ¡n giáº£n nháº¥t cá»¥ thá»ƒ lÃ  sá»­ dá»¥ng hÃ m `nltk.sent_tokenize`.
```
sentence_list = nltk.sent_tokenize(raw_text)
# Print some sentences
for i in range(100, 110):
  print(sentence_list[i])
  print("-----")
print("---------------------------------------")
print(f"Number of sentences: {len(sentence_list)}")
```
Output:
```
i might not have heard of the eruption at all had i not met ogilvy, the well-known astronomer, at ottershaw.
-----
he was immensely excited at the news, and in the excess of his feelings invited me up to take a turn with him that night in a scrutiny of the red planet.
......
```
BÃªn cáº¡nh hÃ m Ä‘á»ƒ tÃ¡ch cÃ¡c cÃ¢u thÃ¬ thÆ° viá»‡n NLTK cÅ©ng cung cáº¥p hÃ m Ä‘á»ƒ tÃ¡ch cÃ¡c tá»« `nltk.word_tokenize`.
## Loáº¡i bá» cÃ¡c kÃ­ tá»± Ä‘áº·c biá»‡t (dáº¥u cÃ¢u)
Trong cÃ¡c cÃ¢u trong vÄƒn báº£n sáº½ tá»“n táº¡i nhiá»u dáº¥u cÃ¢u nhÆ° *?, !, ", ;, ...* trÆ°á»›c khi xÃ¢y dá»±ng bá»™ tá»« vá»±ng thÃ¬ cÃ¡c kÃ­ tá»± nÃ y cÅ©ng cáº§n Ä‘Æ°á»£c loáº¡i bá». Python Ä‘Ã£ Ä‘á»‹nh nghÄ©a cÃ¡c dáº¥u cÃ¢u trong `string.punctuation` tuy vÃ o bÃ i toÃ¡n ta cÃ³ thá»ƒ thÃªm hoáº·c bá»›t cÃ¡c dáº¥u nÃ y cho phÃ¹ há»£p.
```
import string
print("Punctuations: " + string.punctuation + "\n")
sentence_list = [sentence.translate(str.maketrans('', '', string.punctuation)) for sentence in sentence_list]

for i in range(100, 110):
  print(sentence_list[i])
  print("-----")
```
Output
```
Punctuations: !"#$%&'()*+,-./:;<=>?@[\]^_`{|}~

i might not have heard of the eruption at all had i not met ogilvy the wellknown astronomer at ottershaw
-----
he was immensely excited at the news and in the excess of his feelings invited me up to take a turn with him that night in a scrutiny of the red planet
```
KhÃ´ng chá»‰ dáº¥u "," vÃ  "." trong cÃ¢u Ä‘Ã£ Ä‘Æ°á»£c loáº¡i bá» thÃ¬ cÃ¡c dáº¥u Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong `string.punctuation` cÅ©ng Ä‘Æ°á»£c bá» Ä‘i. NgoÃ i ra ta cÃ³ thá»ƒ thÃªm bá»›t cÃ¡c dáº¥u tÃ¹y theo má»¥c Ä‘Ã­ch.
## Loáº¡i bá» stop-word
Stop words thÆ°á»ng lÃ  cÃ¡c tá»« xuáº¥t hiá»‡n nhiá»u láº§n vÃ  khÃ´ng Ä‘Ã³ng gÃ³p nhiá»u vÃ o Ã½ nghÄ©a cá»§a cÃ¢u, chÃºng sáº½ Ä‘Ã³ng vai trÃ² nhÆ° nhiá»…u, trong tiáº¿ng Anh cÃ¡c tá»« nÃ y cÃ³ thá»ƒ ká»ƒ Ä‘áº¿n nhÆ° *the, is, at, on, which, in, some, many* hay trong tiáº¿ng Viá»‡t lÃ  cÃ¡c tá»« *cÃ¡i, cÃ¡c, cáº£,...*. CÃ¡c tá»« nÃ y thÆ°á»ng sáº½ Ä‘Æ°á»£c loáº¡i bá» Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c cá»§a bá»™ tá»« vá»±ng. Trong thÆ° viá»‡n NLTK cÃ³ Ä‘á»‹nh nghÄ©a cÃ¡c stop words phá»• biáº¿n trong tiáº¿ng Anh, tuy nhiÃªn tÃ¹y thuá»™c vÃ o má»¥c Ä‘Ã­ch, bÃ i toÃ n mÃ  ta sáº½ thÃªm bá»›t cÃ¡c stop word cho phÃ¹ há»£p. Äá»ƒ sá»­ dá»¥ng stop words cá»§a NLTK, trÆ°á»›c tiÃªn ta cáº§n download bá»™ stop words `nltk.download('stopwords')`.
```
nltk.download('stopwords')
from nltk.corpus import stopwords

stop_word_list = set(stopwords.words('english'))
print(stop_word_list, "\n")
for i in range(len(sentence_list)):
  sentence_list[i] = " ".join([word for word in sentence_list[i].split() if word not in stop_word_list])

for i in range(100, 110):
  print(sentence_list[i])
  print("-----")
```
Output
```
Stop words:  {'against', 'don', 'between', 'whom', 'any', 'theirs', 'both', 'until', 'same', 'the', "weren't", 'only', 'y', "isn't", 'an', 'she', 'mightn', 'before', "should've", "you've", 'were', 'how', 'myself', 'yourself', 'who', 'too', 'other', "wouldn't", 'did', 'about', 'i', 'very', 'ain', 'won', 'had', 'my', 'while', 'those', 'her', 'to', 'will', 'this', 'm', 'in', 'under', 'shouldn', 'why', 'which', 'been', "you're", 'can', 'o', 'aren', 'them', 'below', 'than', 'we', 'be', 'but', 'here', 'for', "mightn't", 'through', 'was', "you'd", "hadn't", 'and', "needn't", 'having', 't', "that'll", 'me', 'doesn', 'ma', 'have', 'are', 'on', "she's", 'after', 'ours', 'a', 'not', 'out', 'at', "won't", 'above', 'few', 'herself', 'weren', 'is', 'up', "didn't", "don't", 'from', 'should', 'their', 'his', 'himself', 'they', 'him', 'do', 'just', 'or', 'you', "doesn't", 'if', 'each', 'wouldn', "haven't", 'isn', 'it', 've', 're', 'when', 'so', 'down', 'its', 'over', 'most', 'further', 'your', "it's", "shan't", 'that', 'hers', 'itself', 'no', 's', 'doing', "aren't", 'such', 'wasn', 'into', 'yours', 'yourselves', 'during', "shouldn't", 'mustn', 'our', 'll', 'own', 'themselves', 'where', 'more', 'd', 'then', 'being', 'has', 'by', 'hasn', 'once', 'haven', 'of', 'ourselves', 'as', 'these', 'all', 'now', 'couldn', "mustn't", 'some', 'again', 'hadn', 'needn', 'does', "wasn't", 'because', 'with', 'he', 'what', "couldn't", 'off', 'am', 'didn', 'nor', 'there', "you'll", "hasn't", 'shan'} 

might heard eruption met ogilvy wellknown astronomer ottershaw
-----
immensely excited news excess feelings invited take turn night scrutiny red planet
```
## Loáº¡i bá» cÃ¡c tá»« hiáº¿m gáº·p
BÃªn cáº¡nh stop words thÃ¬ trong nhiá»u bÃ i toÃ¡n ta cÅ©ng cáº§n pháº£i loáº¡i bá» cÃ¡c tá»« hiáº¿m gáº·p, Ä‘áº·c biá»‡t khi bá»™ dá»¯ liá»‡u lá»›n. ÄÃ¢y cÅ©ng lÃ  kÄ© thuáº­t mÃ  ta cáº§n cÃ¢n nháº¯c trÆ°á»›c khi sá»­ dá»¥ng bá»Ÿi loáº¡i bá» cÃ¡c tá»« nÃ y cÃ³ thá»ƒ gÃ¢y ra sá»± máº¥t mÃ¡t vá» ngá»¯ nghÄ©a cá»§a cÃ¢u, Ä‘áº·c biá»‡t lÃ  vá»›i cÃ¡c bá»™ dá»¯ liá»‡u trung bÃ¬nh, nhá». Äá»ƒ loáº¡i bá» cÃ¡c tá»« hiáº¿m ta sáº½ dÃ¹ng `Counter` Ä‘á»ƒ Ä‘áº¿m sá»‘ láº§n xuáº¥t hiá»‡n cá»§a cÃ¡c tá»« vÃ  tÃ¬m ra cÃ¡c tá»« Ã­t xuáº¥t hiá»‡n nháº¥t, sau Ä‘Ã³ loáº¡i bá» cÃ¡c tá»« nÃ y trong cÃ¢u nhÆ° Ä‘á»‘i vá»›i stop words.
```
from collections import Counter
# get word list
word_list =list()
for sentence in sentence_list:
  for word in sentence.split():
    word_list.append(word)
word_counter = Counter(word_list)

# for example, remove 10 rare words
rare_word_list = set([word for (word, word_count) in word_counter.most_common()[:-10-1:-1]])
print(rare_word_list)
for i in range(len(sentence_list)):
  sentence_list[i] = " ".join([word for word in sentence_list[i].split() if word not in rare_word_list])
```
## Stemming & Lemmatization
**Stemming** lÃ  quÃ¡ trÃ¬nh biáº¿n Ä‘á»•i cÃ¡c tá»« vá» dáº¡ng gá»‘c cá»§a nÃ³ (vÃ­ dá»¥: connected, connection khi stemming thu Ä‘Æ°á»£c connect hay moved, move khi stemming thu Ä‘Æ°á»£c mov), lÆ°u Ã½ lÃ  stemming Ä‘Æ¡n giáº£n lÃ  loáº¡i bá» pháº§n cuá»‘i cá»§a tá»« tuy nhiÃªn dáº¡ng cá»§a tá»« thu Ä‘Æ°á»£c chÆ°a cháº¯c Ä‘Ã£ tá»“n táº¡i trong tiáº¿ng Anh (nhÆ° tá»« mov) (khÃ¡ tá»‡!!). ThÃ´ng thÆ°á»ng kÄ© thuáº­t nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ chuáº©n hÃ³a bá»™ tá»« vá»±ng vÃ  ta cÅ©ng cáº§n cÃ¢n nháº¯c sá»­ dá»¥ng theo bÃ i toÃ¡n Ä‘áº·t ra. Trong thÆ° viá»‡n NLTK cÅ©ng cÃ³ há»— trá»£ thuáº­t toÃ¡n Porter Ä‘á»ƒ thá»±c hiá»‡n nhiá»‡m vá»¥ nÃ y.
```
from nltk.stem.porter import PorterStemmer

stemmer = PorterStemmer()
stemmed_sentence_list = []
for i in range(len(sentence_list)):
  stemmed_sentence_list.append(" ".join([stemmer.stem(word) for word in sentence_list[i].split()]))

for i in range(100, 110):
  print(stemmed_sentence_list[i])
  print("-----")
```
Khi quan sÃ¡t output, ta tháº¥y má»™t sá»‘ tá»« nhÆ°  eruption -> erupt, astronomer -> astronom....
```
might heard erupt met ogilvi wellknown astronom ottershaw
-----
immens excit news excess feel invit take turn night scrutini red planet
```
**Lemmatization** vá» cÆ¡ báº£n lÃ  giá»‘ng vá»›i stemming khi nÃ³ loáº¡i bá» pháº§n Ä‘uÃ´i cá»§a tá»« Ä‘á»ƒ thu Ä‘Æ°á»£c gá»‘c tá»«, tuy nhiÃªn cÃ¡c gá»‘c tá»« á»Ÿ Ä‘Ã¢y Ä‘á»u thá»±c sá»± tá»‘n táº¡i chá»© khÃ´ng nhÆ° stemming (nhÆ° vÃ­ dá»¥ trÃªn thÃ¬ tá»« moved sau khi lemmatize sáº½ thu Ä‘Æ°á»£c move). Trong thÆ° viá»‡n NLTK sáº½ sá»­ dá»¥ng tá»« Ä‘iá»ƒn Wordnet Ä‘á»ƒ map theo cÃ¡c quy táº¯c (theo tÃ­nh cháº¥t cá»§a tá»«, tá»« lÃ  danh tá»«, Ä‘á»™ng tá»«, tráº¡ng tá»« hay tÃ­nh tá»«). Sá»­ dá»¥ng *part-of-speech tagging* (`nltk.pos_tag`) Ä‘á»ƒ thu Ä‘Æ°á»£c cÃ¡c tÃ­nh cháº¥t cá»§a tá»«.
```
from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet

wordnet_map = {"N":wordnet.NOUN, "V":wordnet.VERB, "J":wordnet.ADJ, "R":wordnet.ADV}
lemmatizer = WordNetLemmatizer()
lemmatized_sentence_list = []
for i in range(len(sentence_list)):
  pos_tagged_sentence = nltk.pos_tag(sentence_list[i].split())
  lemmatized_sentence_list.append(" ".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_sentence]))

for i in range(100, 110):
  print(lemmatized_sentence_list[i])
  print("-----")
```
CÃ³ thá»ƒ tháº¥y tá»« excited -> excite vÃ  invited -> invite.
```
might hear eruption meet ogilvy wellknown astronomer ottershaw
-----
immensely excite news excess feeling invite take turn night scrutiny red planet
```
Tuy nhiÃªn, 2 kÄ© thuáº­t nÃ y thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong tiáº¿ng Anh (hoáº·c ngÃ´n ngá»¯ nÃ o mÃ  má»™t gá»‘c tá»« cÃ³ thá»ƒ biáº¿n Ä‘á»•i thÃ nh nhiá»u dáº¡ng khÃ¡c nhau), cÃ²n trong tiáº¿ng Viá»‡t thÃ¬ ta khÃ´ng dÃ¹ng vÃ¬ má»™t tá»« khÃ´ng cÃ³ cÃ¡c biáº¿n thá»ƒ khÃ¡c nhau.
## Loáº¡i bá» cÃ¡c emoji
Äá»‘i vá»›i má»™t sá»‘ bÃ i toÃ¡n sá»­ dá»¥ng dá»¯ liá»‡u lÃ  cÃ¡c vÄƒn báº£n tá»« nhá»¯ng trang máº¡ng xÃ£ há»™i nhÆ° Twitter, Facebook,... thÃ¬ viá»‡c loáº¡i bá» cÃ¡c biá»ƒu tÆ°á»£ng cáº£m xÃºc - emoji lÃ  vÃ´ cÃ¹ng cáº§n thiáº¿t. Äá»ƒ loáº¡i bá» emoji ta sáº½ sá»­ dá»¥ng regex, pattern láº¥y tá»« [repo nÃ y](https://github.com/NeelShah18/emot/blob/master/emot/emo_unicode.py) khÃ¡ Ä‘áº§y Ä‘á»§ vÃ  hoáº¡t Ä‘á»™ng tá»‘t.
```
emoji_pattern = re.compile("["
                            u"\U0001F600-\U0001F64F"  # emoticons
                            u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                            u"\U0001F680-\U0001F6FF"  # transport & map symbols
                            u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                            u"\U00002500-\U00002BEF"  # chinese char
                            u"\U00002702-\U000027B0"
                            u"\U00002702-\U000027B0"
                            u"\U000024C2-\U0001F251"
                            u"\U0001f926-\U0001f937"
                            u"\U00010000-\U0010ffff"
                            u"\u2640-\u2642"
                            u"\u2600-\u2B55"
                            u"\u200d"
                            u"\u23cf"
                            u"\u23e9"
                            u"\u231a"
                            u"\ufe0f"  # dingbats
                            u"\u3030"
                            "]+", flags=re.UNICODE)
emoji_example = "ğŸ˜… ğŸ‘  ğŸ˜† Without you by my side, ğŸ’“ ğŸ˜‰ I am not complete. You have given me the best of love, ğŸˆ and I want to be by your side forever. Thank you for giving my life that direction it needed. ğŸ’‹â€ Thank you for loving me unconditional. ğŸ’"
print(emoji_pattern.sub(r'', emoji_example))
```
Thu Ä‘Æ°á»£c cÃ¢u Ä‘Ã£ loáº¡i bá» Ä‘i cÃ¡c biá»ƒu tÆ°á»£ng cáº£m xÃºc!
```
   Without you by my side,   I am not complete. You have given me the best of love,  and I want to be by your side forever. Thank you for giving my life that direction it needed.  Thank you for loving me unconditional. 
```
## Loáº¡i bá» URL
Khi crawl dá»¯ liá»‡u tá»« nhiá»u nguá»“n thÃ¬ khÃ´ng thá»ƒ trÃ¡nh khá»i viá»‡c cÃ¡c dá»¯ liá»‡u nÃ y sáº½ dÃ­nh cÃ¡c Ä‘Æ°á»ng dáº«n URL khÃ¡c nhau. Sá»­ dá»¥ng regex Ä‘á»ƒ loáº¡i bá» cÃ¡c URL Ä‘Æ¡n giáº£n nhÆ° sau.
```
url_example = "You can read more about AI at https://viblo.asia/"
url_pattern = re.compile(r'http\S+')
print(url_pattern.sub(r'', url_example))
```
Output
```
You can read more about AI at 
```
# Káº¿t luáº­n
TrÃªn Ä‘Ã¢y lÃ  má»™t vÃ i kÄ© thuáº­t cÆ¡ báº£n Ä‘á»ƒ tiá»n xá»­ lÃ­ dá»¯ liá»‡u vÄƒn báº£n trÆ°á»›c khi sá»­ dá»¥ng cho báº¥t kÃ¬ bÃ i toÃ¡n NLP nÃ o. Tuy nhiÃªn, khÃ´ng pháº£i lÃºc nÃ o ta cÅ©ng cáº§n thá»±c hiá»‡n táº¥t cáº£. Ta cáº§n cÃ¢n nháº¯c dá»± vÃ o tá»«ng má»¥c tiÃªu, bÃ i toÃ¡n cá»¥ thá»ƒ, tháº­m chÃ­ lÃ  cáº§n cÃ³ nhá»¯ng Ä‘Ã¡nh giÃ¡ ráº±ng cÃ³ nÃªn sá»­ dá»¥ng kÄ© thuáº­t Ä‘áº¥y khÃ´ng. ThÃ´ng thÆ°á»ng cÃ¡c kÄ© thuáº­t tiá»n xá»­ lÃ­ nÃ y sáº½ mang láº¡i hiá»‡u quáº£ cao cho cÃ¡c bÃ i toÃ n sá»­ dá»¥ng bá»™ dá»¯ liá»‡u trÃªn domain nhá».
# References
https://realpython.com/nltk-nlp-python/

https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing/