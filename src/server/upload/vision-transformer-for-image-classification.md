# 1. Introduction
<div align="justify">
    
Xin chÃ o cÃ¡c báº¡n, dáº¡o gáº§n Ä‘Ã¢y tÃ´i cÃ³ Ä‘i tÃ¬m hiá»ƒu vá» cÃ¡c mÃ´ hÃ¬nh sequence to sequence káº¿t há»£p vá»›i cÆ¡ cháº¿ attention Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u dáº¡ng chuá»—i (sequence). CÃ¡c dá»¯ liá»‡u dáº¡ng chuá»—i cÃ¡c báº¡n cÃ³ thá»ƒ gáº·p nhÆ°: dá»¯ liá»‡u text, dá»¯ liá»‡u vá» Ã¢m thanh... CÃ¡c bÃ i toÃ¡n tiÃªu biá»ƒu xá»­ lÃ½ dá»¯ liá»‡u chuá»—i cÃ³ thá»ƒ ká»ƒ Ä‘áº¿n nhÆ° Machine Translation (dá»‹ch chuá»—i vÄƒn báº£n tá»« ngÃ´n ngá»¯ A sang ngÃ´n ngá»¯ B), Text to Speech (chuyá»ƒn chuá»—i vÄƒn báº£n Ä‘áº§u vÃ o thÃ nh chuá»—i Ã¢m thanh tÆ°Æ¡ng á»©ng), NLP (Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn), ...

CÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y, há»c sÃ¢u Ä‘ang Ä‘Æ°á»£c cáº£i thiá»‡n vÃ  phÃ¡t triá»ƒn liÃªn tá»¥c theo thá»i gian vá» cáº£ Ä‘á»™ chÃ­nh xÃ¡c vÃ  tá»‘c Ä‘á»™ xá»­ lÃ½. Äá»‘i vá»›i bÃ i toÃ¡n sequence to sequence cÅ©ng váº­y. CÃ¡c mÃ´ hÃ¬nh xá»­ lÃ½ cho bÃ i toÃ¡n nÃ y tá»« thuá»Ÿ ban Ä‘áº§u lÃ  RNN ( Recurrent Neural Network). Tuy nhiÃªn náº¿u báº¡n nÃ o Ä‘Ã£ tÃ¬m hiá»ƒu vá» RNN cÃ³ thá»ƒ biáº¿t nÃ³ cÃ³ ráº¥t nhiá»u cÃ¡c háº¡n cháº¿ khi pháº£i xá»­ lÃ½ cÃ¡c chuá»—i Ä‘áº§u vÃ o cÃ³ kÃ­ch thÆ°á»›c quÃ¡ dÃ i do khÃ´ng lÆ°u trá»¯ Ä‘c thÃ´ng tin cá»§a chuá»—i á»Ÿ khoáº£ng cÃ¡ch xa vÃ  sá»± máº¥t mÃ¡t Ä‘áº¡o hÃ m khiáº¿n mÃ´ hÃ¬nh khÃ´ng thá»ƒ há»c Ä‘Æ°á»£c. VÃ  cá»© cÃ³ nhÆ°á»£c Ä‘iá»ƒm nhÆ° váº­y thÃ¬ cÃ¡c mÃ´ hÃ¬nh sau má»›i Ä‘Æ°á»£c nghiÃªn cá»©u ra. Äiá»ƒn hÃ¬nh lÃ  LSTM ra Ä‘á»i nháº±m kháº¯c phá»¥c pháº§n nÃ o váº¥n Ä‘á» khi xá»­ lÃ½ cÃ¡c chuá»—i Ä‘áº§u vÃ o cÃ³ kÃ­ch thÆ°á»›c dÃ i cá»§a RNN. Vá» sau nÃ y vá»›i sá»± ra Ä‘á»i cá»§a cÆ¡ cháº¿ Attention thÃ¬ cÃ¡c mÃ´ hÃ¬nh RNN vÃ  LSTM cÅ©ng Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u quáº£ hÆ¡n rÃµ rá»‡t khi xá»­ lÃ½ cÃ¡c chuá»—i Ä‘áº§u vÃ o. Tiáº¿p ná»‘i sau Ä‘Ã³ thÃ¬ mÃ´ hÃ¬nh Transformer ra Ä‘á»i nhÆ° lÃ  má»™t sá»± bá»©t phÃ¡ trong cÃ¡c bÃ i toÃ¡n sequence to sequence, mÃ´ hÃ¬nh nÃ y vá»«a táº­n dá»¥ng Ä‘Æ°á»£c sá»©c máº¡nh cá»§a cÆ¡ cháº¿ attention vá»«a táº­n dá»¥ng Ä‘Æ°á»£c kháº£ nÄƒng tÃ­nh toÃ¡n song song cá»§a GPU vÃ¬ mÃ´ hÃ¬nh nÃ y cÃ³ thá»ƒ xá»­ lÃ½ song song chuá»—i Ä‘áº§u vÃ o thay vÃ¬ xá»­ lÃ½ tuáº§n tá»± nhÆ° cÃ¡c mÃ´ hÃ¬nh RNN hay LTSM trÆ°á»›c Ä‘Ã³.

Vá»›i tÃ´i, tÃ´i láº¡i thÃ­ch xá»­ lÃ½ cÃ¡c bÃ i toÃ¡n liÃªn quan Ä‘áº¿n dá»¯ liá»‡u áº£nh hÆ¡n, vÃ¬ thá»‰nh thoáº£ng cÃ³ thá»ƒ Ä‘Æ°a má»™t sá»‘ áº£nh cá»§a ngÆ°á»i mÃ¬nh thÃ­ch hoáº·c lÃ  idol cá»§a mÃ¬nh vÃ o model Ä‘á»ƒ thá»­ nghiá»‡m cho vui :joy::joy::joy:. ChÃ­nh vÃ¬ váº­y tÃ´i tá»± há»i ráº±ng cÃ³ sá»± giao thoa nÃ o giá»¯a 2 bÃ i toÃ¡n xá»­ lÃ½ dá»¯ liá»‡u vÃ o lÃ  áº£nh vÃ  xá»­ lÃ½ dá»¯ liá»‡u vÃ o lÃ  chuá»—i khÃ´ng thÃ¬  bÃ¹m :boom::boom::boom:     **Vision Transformer** lÃ  cÃ¢u tráº£ lá»i.
    
Láº¥y Ã½ tÆ°á»Ÿng xá»­ lÃ½ áº£nh Ä‘áº§u vÃ o nhÆ° má»™t chuá»—i, Vision Transformer lÃ  sá»± káº¿t há»£p cá»§a 1 pháº§n kiáº¿n trÃºc cá»§a Transformer vÃ  cÃ¡c khá»‘i MLP (Multilayer Perceptron). MÃ´ hÃ¬nh nÃ y nháº±m giáº£i quyáº¿t bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh (Image classification). BÃ i viáº¿t nÃ y lÃ  nhá»¯ng kiáº¿n thá»©c Ä‘Æ°á»£c tÃ´i note láº¡i trong quÃ¡ trÃ¬nh tÃ¬m hiá»ƒu, má»¥c Ä‘Ã­ch lÃ  cÃ³ nÆ¡i lÆ°u láº¡i kiáº¿n thá»©c Ä‘á»ƒ sau nÃ y quÃªn thÃ¬ cÃ³ chá»— Ä‘á»c láº¡i, hoáº·c cÃ³ thá»ƒ chia sáº» Ä‘Æ°á»£c chÃºt Ã­t ná»™i dung cho cÃ¡c báº¡n Ä‘á»c.
    
ThÃ´i khÃ´ng linh tinh luyÃªn thuyÃªn ná»¯a, cÃ¡c báº¡n cÃ¹ng tÃ´i tÃ¬m hiá»ƒu kiáº¿n trÃºc cá»§a mÃ´ hÃ¬nh nÃ y nhÃ© :grinning:    
    
</div>    



# 2. Vision Transformer
DÆ°á»›i Ä‘Ã¢y lÃ  kiáº¿n trÃºc cá»§a mÃ´ hÃ¬nh Vision Transformer cho bÃ i toÃ¡n Image Classification.
![](https://1.bp.blogspot.com/-_mnVfmzvJWc/X8gMzhZ7SkI/AAAAAAAAG24/8gW2AHEoqUQrBwOqjhYB37A7OOjNyKuNgCLcBGAsYHQ/s1600/image1.gif)

<div align="center">
    
  [Source  Google AI Blog](https://ai.googleblog.com/2020/12/transformers-for-image-recognition-at.html)
    
</div>   

Kiáº¿n trÃºc cá»§a mÃ´ hÃ¬nh gá»“m 3 thÃ nh pháº§n chÃ­nh:
* Linear Projection of Flattened Patches
* Transformer encoder.
* Classification head.

Sau Ä‘Ã¢y tÃ´i sáº½ Ä‘i trÃ¬nh bÃ y vá» tá»«ng thÃ nh pháº§n cá»§a ViT:



## 2.1. Linear Projection and Flattend Patches
### 2.1.1. Patch Embedding
Vá»›i cÃ¡c mÃ´ hÃ¬nh CNN cho bÃ i toÃ¡n image classification, áº£nh input Ä‘áº§u vÃ o cho mÃ´ hÃ¬nh CNN Ä‘Ã³ lÃ  toÃ n bá»™ áº£nh vá»›i kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh. Tuy nhiÃªn ViT cÃ³ má»™t cÃ¡ch xá»­ lÃ½ khÃ¡c.

Vá»›i má»—i áº£nh Ä‘áº§u vÃ o, ViT xá»­ lÃ½ báº±ng cÃ¡ch chia áº£nh ra thÃ nh cÃ¡c pháº§n cÃ³ kÃ­ch thÆ°á»›c báº±ng nhau (patch)
![](https://i.imgur.com/OJw9XpG.gif)

VÃ­ dá»¥ vá»›i hÃ¬nh trÃªn, áº£nh gá»‘c cÃ³ kÃ­ch thÆ°á»›c lÃ  48x48, ViT sáº½ chia áº£nh gá»‘c nÃ y ra thÃ nh cÃ¡c patch cÃ³ kÃ­ch thÆ°á»›c 16x16 ( ÄÃ¢y lÃ  lÃ½ do mÃ  paper cÃ³ tÃªn **An image is worth 16x16 words transformers for image recognition at scale** :smile:). Sau khi chia nhá» áº£nh Ä‘áº§u vÃ o ra ta sáº½ cÃ³ 9 patches táº¥t cáº£.

BÆ°á»›c tiáº¿p theo, Ä‘Æ°a cÃ¡c patches nÃ y vá» dáº¡ng vector báº±ng cÃ¡ch flattend cÃ¡c patches nÃ y ra.
![](https://i.imgur.com/A0Ip0ww.png)
HÃ¬nh trÃªn mÃ´ táº£ pháº§n Linear Projection.
Thá»±c cháº¥t Linear Projection lÃ  má»™t lá»›p Dense vá»›i Ä‘áº§u vÃ o lÃ  flattend vector cá»§a cÃ¡c patches, Ä‘áº§u ra sáº½ lÃ  embeeding vector tÆ°Æ¡ng á»©ng vá»›i tá»«ng patch.

$z_{i}=W*x_i +b$

Trong Ä‘Ã³:
* $x_i$ lÃ  flattend vector cá»§a patch thá»© $i$.
* $z_i$ lÃ  output tÆ°Æ¡ng á»©ng cá»§a $x_i$ khi qua Linear Projection.
* $W$ Ä‘Æ°á»£c gá»i lÃ  ma tráº­n embeeding .

### 2.1.2. Positional Embeeding
Ã tÆ°á»Ÿng tÆ°Æ¡ng tá»± vá»›i mÃ´ hÃ¬nh Transformer gá»‘c. Positional embeeding trong mÃ´ hÃ¬nh ViT sáº½ chá»©a thÃ´ng tin vá» vá»‹ trÃ­ cá»§a patch trong áº£nh (spatial information). Váº­y táº¡i sao vá»›i dá»¯ liá»‡u lÃ  áº£nh mÃ  ta váº«n cáº§n spatial information.
VÃ­ dá»¥ nhÆ° hÃ¬nh dÆ°á»›i Ä‘Ã¢y:
![](https://i.imgur.com/070STJQ.png)

Náº¿u nhÆ° ta chá»‰ Embeeding cÃ¡c patch vÃ  Ä‘Æ°a vÃ o mÃ´ hÃ¬nh Transformer thÃ¬ vá»›i 2 áº£nh á»Ÿ bÃªn trÃªn sáº½ hoÃ n toÃ n khÃ´ng cÃ³ sá»± khÃ¡c biá»‡t. Do Ä‘Ã³ ta cáº§n thÃªm thÃ´ng tin vá» vá»‹ trÃ­ cho má»—i patch.


Sau khi cÃ³ vector positional embeeding cho má»—i patch ta sáº½ cá»™ng cÃ¡c vector nÃ y tÆ°Æ¡ng á»©ng vá»›i embeeding vector cá»§a tá»«ng patch Ä‘Ã£ tÃ­nh á»Ÿ trÃªn vÃ  thu Ä‘Æ°á»£c cÃ¡c vector embeeding vá»«a chá»©a thÃ´ng tin cá»§a vÃ¹ng áº£nh vá»«a chá»©a thÃ´ng tin vá» vá»‹ trÃ­ cá»§a nÃ³ trong áº£nh.

### 2.1.3. Class Embeeding
Pháº§n nÃ y tÃ´i Ä‘Ã£ tÃ¬m hiá»ƒu trong paper tuy nhiÃªn cÅ©ng chÆ°a hiá»ƒu rÃµ cho láº¯m. Náº¿u báº¡n nÃ o hiá»ƒu  pháº§n nÃ y cÃ³ thá»ƒ Ä‘á»ƒ láº¡i 1 comment giÃºp tÃ´i nhÃ©! Thanks :sweat_smile::sweat_smile::sweat_smile:
## 2.2. Transformer Encoder
TrÆ°á»›c khi vÃ o tÃ¬m hiá»ƒu pháº§n nÃ y, tÃ´i gá»£i Ã½ cÃ¡c báº¡n nÃªn Ä‘á»c cÃ¡c bÃ i viáº¿t sau Ä‘Ã¢y Ä‘á»ƒ cÃ³ cÃ¡i nhÃ¬n cá»¥ thá»ƒ hÆ¡n vá» cÆ¡ cháº¿ Attention vÃ  mÃ´ hÃ¬nh Transformer, Ä‘Ã¢y lÃ  nhá»¯ng bÃ i viáº¿t ráº¥t hay cá»§a cÃ¡c "tay to" trong team AI cá»§a tÃ´i:
1. [[Machine Learning] Attention, Attention, Attention, ...!](https://viblo.asia/p/machine-learning-attention-attention-attention-eW65GPJYKDO) - TÃ¡c giáº£ [Phan Huy HoÃ ng](https://viblo.asia/u/phanhoang)
2. [Táº£n máº¡n vá» self Attention](https://viblo.asia/p/tan-man-ve-self-attention-07LKXoq85V4) - TÃ¡c giáº£ [BÃ¹i Quang Máº¡nh](https://viblo.asia/u/buiquangmanh)
3. [Transformers - "NgÆ°á»i mÃ¡y biáº¿n hÃ¬nh" biáº¿n Ä‘á»•i tháº¿ giá»›i NLP](https://viblo.asia/p/transformers-nguoi-may-bien-hinh-bien-doi-the-gioi-nlp-924lJPOXKPM#_transformers-2) - TÃ¡c giáº£ [Nguyá»…n Viá»‡t Anh](https://viblo.asia/u/anhdnv-0902)


Kiáº¿n trÃºc cá»§a Transformer Encoder.
![](https://i.imgur.com/OEfuWC4.png)
### 2.2.1. Self Attention layer
Self attention layer lÃ  thÃ nh pháº§n chÃ­nh Ä‘á»ƒ táº¡o nÃªn má»™t block trong Transformer Encoder.

![](https://i.imgur.com/55jI9Cx.png)

Äáº§u vÃ o cá»§a Self attention layer lÃ  má»™t chuá»—i $X=[x_1, x_2, x_3, ..., x_m]$

Äáº§u ra cá»§a Self Attention layer lÃ  má»™t context vector $C$ chá»©a nhá»¯ng  thÃ´ng tin quan trá»ng nháº¥t  cá»§a chuá»—i Ä‘áº§u vÃ o  $C=[c_1, c_2, c_3, ..., c_m]$

CÃ¡c parameters cá»§a layer nÃ y bao gá»“m $W_Q, W_K, W_V$.


DÆ°á»›i Ä‘Ã¢y lÃ  hÃ¬nh thá»ƒ hiá»‡n cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Self attention layer:
![](https://i.imgur.com/RBKZD3G.gif)
TÃ´i sáº½ Ä‘i nÃ³i qua vá» chi tiáº¿t tá»«ng bÆ°á»›c:
* **BÆ°á»›c 1:** á»¨ng vá»›i má»—i $x_i$ cá»§a chuá»—i Ä‘áº§u vÃ o $X$ tÃ­nh toÃ¡n cÃ¡c gÃ­a trá»‹ $q_i, k_i, v_i$ tÆ°Æ¡ng á»©ng theo cÃ´ng thá»©c $q_i=W_Qx_i$, $k_i=W_Kx_i$, $v_i=W_Vx_i$
* **BÆ°á»›c 2:** TÃ­nh *alignment score* tÆ°Æ¡ng á»©ng vá»›i $x_i$ theo cÃ´ng thá»©c: $\alpha_i=Softmax(K^Tq_i)$
* **BÆ°á»›c 3:** TÃ­nh *context vector* $C$ tÆ°Æ¡ng á»©ng vá»›i $x_i$ theo cÃ´ng thá»©c $c_i = \alpha_{11}v_1 + \alpha_{21}v_2 + ... + \alpha_{m1}v_m = V\alpha_1$

### 2.2.2. Multi-head Attention
BÃªn trÃªn tÃ´i Ä‘Ã£ trÃ¬nh bÃ y vá» cáº¥u trÃºc cÅ©ng nhÆ° cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a self attention layer. 

Multi-head Attention Ä‘Æ¡n giáº£n lÃ  sá»± xáº¿p chá»“ng cÃ¡c lá»›p self attention. VÃ­ dá»¥ 1 lá»›p Multi-head Attention cÃ³ $l$ lá»›p self attention. Äáº§u ra cá»§a má»—i lá»›p self attention cÃ³ kÃ­ch thÆ°á»›c $d$ x $m$ thÃ¬ Ä‘áº§u ra cá»§a multi-head attention sáº½ lÃ  $(ld)$ x $m$
![](https://i.imgur.com/exEqejD.png)




-----

NgoÃ i thÃ nh pháº§n chÃ­nh lÃ  Multi-head Attention thÃ¬ Transformer Encoder cÃ²n Ä‘Æ°á»£c táº¡o bá»Ÿi cÃ¡c lá»›p khÃ¡c nhÆ° Add & Norm, Feed Forward, Add & Norm. 
## 2.3. Classification Head
Pháº§n nÃ y Ä‘Æ¡n giáº£n lÃ  má»™t khá»‘i MLP (Multilayer perceptron) nháº­n Ä‘áº§u vÃ o lÃ  context vector $c$ tráº£ vá» tá»« Transformer Encoder vÃ  Ä‘Æ°a ra káº¿t quáº£ cuá»‘i cÃ¹ng lÃ  xÃ¡c suáº¥t tÆ°Æ¡ng á»©ng vá»›i cÃ¡c class.


![](https://i.imgur.com/pMJhZU3.png)

## 3. Results
### 3.1. Training strategies
![](https://i.imgur.com/Ft6WasV.gif)
Äá»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cao, quÃ¡ trÃ¬nh training ViT gá»“m cÃ³ 3 bÆ°á»›c:
* **Pre-Training**: Khá»Ÿi táº¡o model vÃ  training trÃªn táº­p Dataset A, Dataset A thÆ°á»ng lÃ  má»™t táº­p dataset vá»›i kÃ­ch thÆ°á»›c lá»›n. 
* **Fine-tuned**: Sá»­ dá»¥ng pretrained model á»Ÿ bÆ°á»›c 1, fine tune trÃªn táº­p dataset B. Dataset B lÃ  táº­p dataset má»¥c tiÃªu mÃ  ta cáº§n model há»c tá»‘t trÃªn nÃ³.
* **Testing**: Sau khi model Ä‘Æ°á»£c fine tune trÃªn táº­p training cá»§a  dataset B nÃ³ sáº½ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn táº­p Test cá»§a dataset B. CÃ¡c thÃ´ng sá»‘ Ä‘Ã¡nh giÃ¡ á»Ÿ bÆ°á»›c nÃ y sáº½ thá»ƒ hiá»‡n performance cá»§a model. 

ÄÆ°á»£c Ä‘á» cáº­p trong paper. CÃ¡c tÃ¡c giáº£ sá»­ dá»¥ng 3 táº­p dá»¯ liá»‡u cho viá»‡c huáº¥n luyá»‡n mÃ´ hÃ¬nh ViT. Chi tiáº¿t cÃ¡c táº­p dá»¯ liá»‡u nhÆ° á»Ÿ báº£ng dÆ°á»›i Ä‘Ã¢y.

<div align='center'>
    
  | Dataset | Sá»‘ lÆ°á»£ng samples | Sá»‘ lÆ°á»£ng class |
| - | - | - |
| ImageNet (Small) | 1.3 M |1K|
|ImageNet-21K (Medium) | 14 M | 21K |
| JFT (Big) | 300 M |18K|  
    
</div>    
   
   ### 3.2. Classification accuracies
   Vá»›i chiáº¿n lÆ°á»£c training nhÆ° trÃªn thÃ¬ ViT khi so sÃ¡nh vá»›i ResNet Ä‘áº¡t káº¿t quáº£ nhÆ° sau:
   ![](https://i.imgur.com/2BeJx4T.png)
*    Pretrained on ImageNet (small), káº¿t quáº£ kÃ©m hÆ¡n ResNet
*    Pretrained on ImageNet - 21K (medium), Ä‘á»™ chÃ­nh xÃ¡c cá»§a ViT Ä‘áº¡t xáº¥p xá»‰ báº±ng ResNet
*    Pretrained on JFT (large), ViT Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c vÆ°á»£t trá»™i hÆ¡n so vá»›i ResNet

    
   


# 4. Conclusions
NhÆ° váº­y phÃ­a trÃªn tÃ´i Ä‘Ã£ trÃ¬nh bÃ y qua vá» kiáº¿n trÃºc cÅ©ng nhÆ° cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Vision Transformer cho bÃ i toÃ¡n image classification. BÃ i viáº¿t cÃ²n nhiá»u thiáº¿u sÃ³t, cÅ©ng nhÆ° cÃ²n 1 sá»‘ pháº§n tÃ´i trÃ¬nh bÃ y theo Ã½ hiá»ƒu cá»§a mÃ¬nh nÃªn cÅ©ng cÃ³ thá»ƒ chÆ°a Ä‘Æ°á»£c chÃ­nh xÃ¡c hoÃ n toÃ n. Ráº¥t mong cÃ¡c báº¡n nÃ o Ä‘Ã£ Ä‘á»c bÃ i viáº¿t náº¿u tháº¥y chá»— nÃ o chÆ°a há»£p lÃ½ cÃ³ thá»ƒ Ä‘á»ƒ láº¡i cho tÃ´i 1 comment Ä‘á»ƒ giÃºp bÃ i viáº¿t hoÃ n chá»‰nh hÆ¡n. Náº¿u báº¡n nÃ o muá»‘n tÃ¬m hiá»ƒu vá» code thÃ¬ cÃ³ thá»ƒ tham kháº£o táº¡i [Ä‘Ã¢y](https://github.com/google-research/vision_transformer).

VÃ  má»™t láº§n ná»¯a náº¿u báº¡n nÃ o cÃ³ Ã½ Ä‘á»‹nh tÃ¬m hiá»ƒu sÃ¢u hÆ¡n thÃ¬ tÃ´i highly recommend xem qua cÃ¡c silde á»Ÿ [Ä‘Ã¢y](https://github.com/wangshusen/DeepLearning/tree/master/Slides). CÃ¹ng vá»›i list video [nÃ y](https://www.youtube.com/playlist?list=PLgtf4d9zHHO8p_zDKstvqvtkv80jhHxoE).

Náº¿u cÃ¡c báº¡n tháº¥y bÃ i viáº¿t nÃ y giÃºp cho cÃ¡c báº¡n má»™t chÃºt gÃ¬ Ä‘Ã³ cho báº¡n thÃ¬Ä‘á»«ng quÃªn cho tÃ´i xin 1 upvote nhÃ© ğŸ˜. Cáº£m Æ¡n cÃ¡c báº¡n ğŸ¤—ğŸ¤—
# References
* Paper [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/pdf/2010.11929.pdf)
* Slide [Vision Transformer](https://github.com/wangshusen/DeepLearning/blob/master/Slides/10_ViT.pdf)