## Gi·ªõi thi·ªáu
Ch√†o c√°c b·∫°n t·ªõi v·ªõi series v·ªÅ kubernetes. ƒê√¢y l√† b√†i th·ª© 19 trong series c·ªßa m√¨nh, ·ªü b√†i tr∆∞·ªõc ch√∫ng ta ƒë√£ n√≥i v·ªÅ [Advanced scheduling](https://viblo.asia/p/kubernetes-series-bai-18-advanced-scheduling-node-affinity-and-pod-affinity-gAm5y7jqZdb), ·ªü b√†i n√†y m√¨nh s·∫Ω n√≥i c√°ch l√†m sao ƒë·ªÉ ta c√≥ th·ªÉ t·ª± t·∫°o m·ªôt custom resource trong kubernetes.

B√™n c·∫°nh nh·ªØng resource m·∫∑c ƒë·ªãnh nh∆∞ Pod, ReplicaSet, Deployment, StatefulSet, ... Th√¨ kubernetes cho ph√©p ch√∫ng ta t·∫°o th√™m nh·ªØng custom resource ƒë·ªÉ ƒë√°p ·ª©ng ƒë√∫ng nhu c·∫ßu c·ªßa ch√∫ng ta trong d·ª± √°n, t·ª´ng custom resource s·∫Ω ph·ª•c v·ª• cho m·ªôt m·ª•c ƒë√≠ch c·ª• th·ªÉ n√†o ƒë√≥ trong d·ª± √°n c·ªßa ch√∫ng ta. V√≠ d·ª•, ƒë·ªÉ t·∫°o postgres database trong kubernetes, th√¨ ƒë·∫ßu ti√™n ta s·∫Ω ƒë·ªãnh nghƒ©a m·ªôt StatefulSet, sau ƒë√≥ t·∫°o m·ªôt Service cho StatefulSet n√†y ƒë·ªÉ client c√≥ th·ªÉ k·∫øt n·ªëi ƒë∆∞·ª£c t·ªõi n√≥. Ta c√≥ th·ªÉ gi·∫£m c√¥ng ƒëo·∫°n ph·∫£i t·∫°o nhi·ªÅu th·ª© li√™n quan nh∆∞ v·∫≠y b·∫±ng c√°ch ƒë·ªãnh nghƒ©a m·ªôt custom resource t√™n l√† Postgres, m·ªói l·∫ßn ta c·∫ßn postgres database th√¨ ta ch·ªâ c·∫ßn t·∫°o m·ªôt Postgres custom resource l√† ƒë∆∞·ª£c, v√≠ d·ª• nh∆∞ sau:

```yaml
...
kind: Postgres
metadata:
  name: test-db
storage: 50GB
```

## Custom Controller
Tr∆∞·ªõc khi n√≥i v·ªÅ ph·∫ßn custom resource, ta s·∫Ω n√≥i qua v·ªÅ c√°ch t·∫°o custome controller tr∆∞·ªõc. ·ªû b√†i [Kubernetes internals architecture](https://viblo.asia/p/kubernetes-series-bai-11-kubernetes-internals-architecture-L4x5xPjb5BM), ta t√¨m hi·ªÉu v·ªÅ c·∫•u tr√∫c b√™n trong kubernetes, n√≥ g·ªìm c√≥ 4 th√†nh ph·∫ßn ch√≠nh l√† etcd, API server, Controller Manager, Scheduler. Controller Manager c√≥ nhi·ªám v·ª• theo d√µi API server v√† t·∫°o ra c√°c resource li√™n quan t·ªõi n√≥, v√≠ d·ª• nh∆∞ Deployment Controller s·∫Ω c√≥ nhi·ªám v·ª• theo d√µi Deployment resource ·ªü tr√™n API server v√† t·∫°o ra nh·ªØng resource li√™n quan. Th√¨ b√™n c·∫°nh nh·ªØng Controller Manager c√≥ s·∫µn b√™n trong kubernetes, ta c√≥ th·ªÉ t·∫°o th√™m custom controller ƒë·ªÉ ph·ª•c v·ª• cho m·ªôt m·ª•c ƒë√≠ch kh√°c n√†o ƒë√≥.

Trong kubernetes, b·∫°n s·∫Ω ƒë·ªÉ √Ω m·ªôt ƒëi·ªÅu l√† khi ta t·∫°o m·ªôt ConfigMap v√† g√°n n√≥ cho Pod, l√∫c ta c·∫≠p nh·∫≠t l·∫°i ConfigMap ƒë√≥ v·ªõi gi√° tr·ªã m·ªõi, th√¨ Pod s·ª≠ d·ª•ng ConfigMap c·ªßa ch√∫ng ta v·∫´n gi·ªØ gi√° tr·ªã c≈©, n·∫øu ta mu·ªën Pod n√≥ s·ª≠ d·ª•ng gi√° tr·ªã ConfigMap m·ªõi th√¨ ta ph·∫£i x√≥a Pod ƒë√≥ ƒëi cho n√≥ t·∫°o l·∫°i th√¨ n√≥ m·ªõi c·∫≠p nh·∫≠t ƒë∆∞·ª£c gi√° tr·ªã m·ªõi. C√¥ng vi·ªác n√†y h∆°i m·∫•t c√¥ng, ta c√≥ th·ªÉ t·∫°o m·ªôt custom controller ƒë·ªÉ th·ª±c hi·ªán c√¥ng vi·ªác n√†y t·ª± ƒë·ªông, customer controller c·ªßa ta s·∫Ω theo d√µi resource ConfigMap ·ªü tr√™n API server, v√† n·∫øu n√≥ ph√°t hi·ªán ConfigMap thay ƒë·ªïi, n√≥ s·∫Ω t·ª± ƒë·ªông x√≥a th·∫±ng Pod ƒë√≥ v√† n·∫øu Pod ƒë∆∞·ª£c t·∫°o b·∫±ng c√°c resource nh∆∞ ReplicaSet, Deployment th√¨ n√≥ s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông t·∫°o l·∫°i, l√∫c n√†y Pod m·ªõi c·ªßa ta s·∫Ω s·ª≠ d·ª•ng gi√° tr·ªã m·ªõi c·ªßa ConfigMap.

ƒê·ªÉ t·∫°o m·ªôt custom controller, ƒë·∫ßu ti√™n ta s·∫Ω vi·∫øt code m√† s·∫Ω theo d√µi API server v·ªõi resource ta mu·ªën, sau ƒë√≥ ta build th√†nh image, sau ƒë√≥ ta s·∫Ω t·∫°o m·ªôt Deployment m√† s·ª≠ d·ª•ng image ta v·ª´a t·∫°o v√† deploy n√≥ l√™n kubernetes. Th·ª±c ch·∫•t th√¨ m·ªôt th·∫±ng customer controller ch·ªâ l√† m·ªôt th·∫±ng Deployment b√¨nh th∆∞·ªùng m√† th√¥i, kh√°c ·ªü ch·ªó l√† ta s·∫Ω t·ª± vi·∫øt code ƒë·ªÉ t∆∞∆°ng t√°c v·ªõi API server.

### T·∫°o m·ªôt customer controller
B√¢y gi·ªù ta s·∫Ω t·∫°o m·ªôt customer controller c√≥ t√™n l√† config-watcher-controller, n√≥ s·∫Ω theo d√µi ConfigMap v√† n·∫øu Pod n√†o c√≥ x√†i ConfigMap li√™n quan, khi ConfigMap thay ƒë·ªïi th√¨ gi√° tr·ªã ConfigMap m·ªõi n√†y c≈©ng s·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t l·∫°i cho Pod m·ªôt c√°ch t·ª± ƒë·ªông. N√≥ s·∫Ω l√†m vi·ªác n√†y b·∫±ng c√°ch x√≥a Pod c≈© ƒëi ƒë·ªÉ Pod t·ª± ƒë∆∞·ª£c t·∫°o l·∫°i. Minh h·ªça c·ªßa config-watcher-controller nh∆∞ sau:

![image.png](https://images.viblo.asia/a77efd47-91c3-4d8f-8930-1b857bc04e89.png)

Gi·ªù ta s·∫Ω ti·∫øn h√†nh vi·∫øt code v√† build image cho config-watcher container, t·∫°o m·ªôt file config-watcher-controller.sh v·ªõi code nh∆∞ sau:

```bash
#!/bin/bash

# Controller script which watches configmaps and evaluates annotation
# on the ConfigMap for pods to restart

# Namespace to watch (or 'default' if not given)
namespace=${WATCH_NAMESPACE:-default}

# API URL setup. Requires an ambassador API proxy running side-by-side on localhost
base=http://localhost:8001
ns=namespaces/$namespace

# Main event loop
start_event_loop() {
  # Watch the K8s API on events on service objects
  echo "::: Starting to wait for events"

  # Event loop listening for changes in config maps
  curl -N -s $base/api/v1/${ns}/configmaps?watch=true | while read -r event
  do
    # Sanitize new lines
    event=$(echo "$event" | tr '\r\n' ' ')

    # Event type & name
    local type=$(echo "$event" | jq -r .type)
    local config_map=$(echo "$event" | jq -r .object.metadata.name)

    # Fetch annotations of ConfigMap and extract our trigger annotation if any
    # The extracted pod selector is expected to have
    # the format "label1=value1,label2=value2,.."
    local annotations=$(echo "$event" | jq -r '.object.metadata.annotations')
    if [ "$annotations" != "null" ]; then
      local pod_selector=$(echo $annotations | jq -r 'to_entries | .[] | select(.key == "k8spatterns.io/podDeleteSelector") | .value | @uri')
    fi
    echo "::: $type -- $config_map -- $pod_selector"

    # Act only when configmap is modified and an annotation has been given
    if [ $type = "MODIFIED" ] && [ -n "$pod_selector" ]; then
      delete_pods_with_selector "$pod_selector"
    fi
  done
}

# Delete all pods that match a selector
delete_pods_with_selector() {
  local selector=${1}

  echo "::::: Deleting pods with $selector"

  # Pick up all pod names which match the given selector
  local pods=$(curl -s $base/api/v1/${ns}/pods?labelSelector=$selector | \
               jq -r .items[].metadata.name)

  # Delete all pods that matched
  for pod in $pods; do
    # Delete but also check exit code
    exit_code=$(curl -s -X DELETE -o /dev/null -w "%{http_code}" $base/api/v1/${ns}/pods/$pod)
    if [ $exit_code -eq 200 ]; then
      echo "::::: Deleted pod $pod"
    else
      echo "::::: Error deleting pod $pod: $exit_code"
    fi
  done
}

# ==============================================
# Fire up
start_event_loop
```

Ta kh√¥ng c·∫ßn ph·∫£i hi·ªÉu code chi ti·∫øt l√†m g√¨, ƒëo·∫°n code tr√™n s·∫Ω c√≥ nhi·ªám v·ª• l√† theo d√µi ConfigMap tr√™n API server b·∫±ng b·∫±ng c√¢u l·ªánh `curl -N -s $base/api/v1/${ns}/configmaps?watch=true | while read -r event`, n·∫øu ConfigMap c√≥ thay ƒë·ªïi g√¨ th√¨ n√≥ s·∫Ω ch·∫°y xu·ªëng ƒëo·∫°n code ph√≠a d∆∞·ªõi, v√† ph√°t hi·ªán n·∫øu c√≥ ConfigMap n√†o thay ƒë·ªïi m√† c√≥ Pod s·ª≠ d·ª•ng n√≥ th√¨ n√≥ s·∫Ω x√≥a Pod ƒë√≥ b·∫±ng ƒëo·∫°n code:

```bash
if [ $type = "MODIFIED" ] && [ -n "$pod_selector" ]; then
  delete_pods_with_selector "$pod_selector"
fi
```

Ta ch·ªâ c·∫ßn hi·ªÉu h√†nh ƒë·ªông c·ªßa ƒëo·∫°n code tr√™n nh∆∞ v·∫≠y l√† ƒë∆∞·ª£c. Ti·∫øp theo, ta t·∫°o Dockerfile:

```dockerfile
FROM alpine
WORKDIR /watcher
RUN apk add --update curl jq && rm -rf /var/cache/apk/*
COPY config-watcher-controller.sh .
ENTRYPOINT ["curl"]
```

Ti·∫øp theo l√† build v√† push image l√™n **docker hub c·ªßa b·∫°n** n·∫øu b·∫°n kh√¥ng mu·ªën s·ª≠ d·ª•ng image **080196/configmap-watcher**:

```
$ docker build . -t 080196/configmap-watcher
$ docker push 080196/configmap-watcher
```

Sau khi xong th√¨ ta t·∫°o m·ªôt file t√™n l√† config-watcher-controller.yaml v·ªõi config nh∆∞ sau:

```yaml
# Service account required for watching to resources
apiVersion: v1
kind: ServiceAccount
metadata:
  name: config-watcher-controller
---

# Bind to 'edit' role to allow for watching resources and restarting pods
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: config-watcher-controller
subjects:
- kind: ServiceAccount
  name: config-watcher-controller
roleRef:
  name: edit
  kind: ClusterRole
  apiGroup: rbac.authorization.k8s.io
---

# Controller with kubeapi-proxy sidecar for easy access to the API server
apiVersion: apps/v1
kind: Deployment
metadata:
  name: config-watcher-controller
spec:
  replicas: 1
  selector:
    matchLabels:
      app: config-watcher-controller
  template:
    metadata:
      labels:
        app: config-watcher-controller
    spec:
      # A serviceaccount is needed to watch events
      # and to allow for restarting pods. For now its
      # associated with the 'edit' role
      serviceAccountName: config-watcher-controller
      containers:
      - name: proxy
        image: 080196/kubeapi-proxy
      - name: config-watcher
        image: 080196/configmap-watcher
        env:
         # The operator watches the namespace in which the controller
         # itself is installed (by using the Downward API)
         - name: WATCH_NAMESPACE
           valueFrom:
             fieldRef:
               fieldPath: metadata.namespace
        command:
        - "sh"
        - "/watcher/config-watcher-controller.sh"
```

·ªû file tr√™n, ta s·∫Ω t·∫°o m·ªôt ServiceAccount ri√™ng ƒë·ªÉ s·ª≠ d·ª•ng cho config-watcher-controller c·ªßa ta thay v√¨ s·ª≠ d·ª•ng ServiceAccount m·∫∑c ƒë·ªãnh, sau ƒë√≥ ta s·∫Ω d√πng RoleBinding ƒë·ªÉ bind edit role t·ªõi ServiceAccount n√†y ƒë·ªÉ cho ph√©p n√≥ c√≥ quy·ªÅn edit c√°c resource trong m·ªôt namespace. Trong Deployment config, ta s·∫Ω khai b√°o ServiceAccount tr√™n t·ªõi Pod template, ƒë·ªÉ ·ª©ng d·ª•ng container trong Pod c√≥ th·ªÉ edit c√°c resource c·ªßa kubernetes ƒë∆∞·ª£c, c√°c b·∫°n c√≥ th·ªÉ xem l·∫°i [b√†i 13](https://viblo.asia/p/kubernetes-series-bai-13-serviceaccount-and-role-based-access-control-security-kubernetes-api-server-07LKXQD4ZV4) ƒë·ªÉ hi·ªÉu h∆°n v·ªÅ ServiceAccount. ƒê·ªÉ controller n√†y bi·∫øt n√≥ ƒëang theo d√µi namespace n√†o, ta d√πng [Downward API](https://viblo.asia/p/kubernetes-series-bai-10-downward-api-truy-cap-pod-metadata-m68Z0eGdlkG) ƒë√£ n√≥i ·ªü b√†i 11.

Ta t·∫°o controller tr√™n:

```
$ kubectl apply -f config-watcher-controller.yaml
serviceaccount/config-watcher-controller created
rolebinding.rbac.authorization.k8s.io/config-watcher-controller created
deployment.apps/config-watcher-controller created
```

### S·ª≠ d·ª•ng custom controller

Ok, v·∫≠y l√† ta ƒë√£ t·∫°o ƒë∆∞·ª£c custom controller, ti·∫øp theo ta s·∫Ω t·∫°o m·ªôt resource n√†o ƒë√≥ v√† test th·ª≠, ƒë·ªÉ s·ª≠ d·ª•ng config-watcher-controller, th√¨ khi ta khai b√°o ConfigMap, ta s·∫Ω th√™m v√†o tr∆∞·ªùng annotations v·ªõi gi√° tr·ªã `k8spatterns.io/podDeleteSelector: "<key>=<value>"`
, v·ªõi key value l√† label c·ªßa Pod m√† ta mu·ªën c·∫≠p nh·∫≠t l·∫°i gi√° tr·ªã ConfigMap cho n√≥ khi ConfigMap c·ªßa ta thay ƒë·ªïi. T·∫°o m·ªôt file t√™n l√† confimap-watch.yaml:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: webapp-config
  annotations:
    k8spatterns.io/podDeleteSelector: "app=webapp"
data:
  message: "Hello configmap watch one"
```

```
$ kubectl apply -f confimap-watch.yaml
configmap/webapp-config created
```

T·∫°o m·ªôt file t√™n l√† deploy-use-configmap-watcher.yaml:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      containers:
        - name: webapp
          image: alpine
          command: ["/bin/sleep", "999999"]
          envFrom:
            - configMapRef:
                name: webapp-config
```

Gi√° tr·ªã label c·ªßa Pod l√† gi√° tr·ªã m√† ta khai b√°o ·ªü th·∫±ng ConfiMap ·ªü tr√™n. Ta t·∫°o Deployment v√† truy c·∫≠p v√†o n√≥ ƒë·ªÉ xem gi√° tr·ªã ConfigMap tr∆∞·ªõc ƒë√≥, sau ƒë√≥ ta s·∫Ω c·∫≠p nh·∫≠t l·∫°i gi√° tr·ªã ConfigMap v√† xem th·ª≠ Pod c·ªßa ta c√≥ ƒë∆∞·ª£c t·ª± ƒë·ªông c·∫≠p nh·∫≠t gi√° tr·ªã hay kh√¥ng:

```
$ kubectl apply -f deploy-use-configmap-watcher.yaml
deployment.apps/webapp created

$ kubectl get pod
NAME                                         READY   STATUS              RESTARTS   AGE
config-watcher-controller-547d6547c6-hqpl6   2/2     Running             0          5m59s
webapp-84f8f48c69-k8bb6                      0/1     ContainerCreating   0          6s

$ kubectl exec -it webapp-84f8f48c69-k8bb6 -- sh
/ # env
...
message=Hello configmap watch one
...
/ # exit
```

C·∫≠p nh·∫≠t l·∫°i file confimap-watch.yaml:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: webapp-config
  annotations:
    k8spatterns.io/podDeleteSelector: "app=webapp"
data:
  message: "Hello configmap watch two"
```

```
$ kubectl apply -f confimap-watch.yaml
configmap/webapp-config configured
```

L√∫c n√†y n·∫øu ta get pod, ta s·∫Ω th·∫•y c√≥ m·ªôt th·∫±ng ƒëang b·ªã x√≥a ƒëi v√† m·ªôt th·∫±ng kh√°c ƒë∆∞·ª£c t·∫°o ra:

```
$ kubectl get pod
NAME                                         READY   STATUS        RESTARTS   AGE
config-watcher-controller-547d6547c6-hqpl6   2/2     Running       0          10m
webapp-84f8f48c69-k8bb6                      1/1     Terminating   0          5m6s
webapp-84f8f48c69-r28lw                      1/1     Running       0          14s
```

Khi ta truy c·∫≠p v√†o pod m·ªõi v√† ki·ªÉm tra l·∫°i, ta s·∫Ω th·∫•y env c·ªßa ta ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t:

```
$ kubectl exec -it webapp-84f8f48c69-r28lw -- sh
/ # env
...
message=Hello configmap watch two
...
```

Oke, v·∫≠y l√† custom controller c·ªßa ta ƒë√£ ch·∫°y ƒë√∫ng üòÑ. T·ªõi ƒë√¢y th√¨ ta ƒë√£ bi·∫øt c√°ch vi·∫øt v√† t·∫°o m·ªôt customer controller ph·ª•c v·ª• cho m·ªôt m·ª•c ƒë√≠ch c·ª• th·ªÉ c·ªßa ta, nh∆∞ng m√† tr∆∞·ªõc khi ta l√†m g√¨ ƒë√≥ th√¨ ta xem c√≥ ng∆∞·ªùi n√†o ƒë√£ l√†m tr∆∞·ªõc ch∆∞a, n·∫øu c√≥ r·ªìi th√¨ ta c·ª© s·ª≠ d·ª•ng th√¥i, v√¨ vi·∫øt m·ªôt controller m√† ch·∫°y ƒë∆∞·ª£c trong m√¥i tr∆∞·ªùng production ta c·∫ßn v·ªõi test nhi·ªÅu l·∫ßn n·ªØa, code ·ªü tr√™n ch·ªâ d√†nh cho m√¥i tr∆∞·ªùng dev th√¥i.

## Custom Resource
Sau khi ta n√≥i v·ªÅ custom controller th√¨ b√¢y gi·ªù ta s·∫Ω n√≥i v·ªÅ custom resource. ƒê·ªÉ t·∫°o m·ªôt custom resource trong th√¨ ta s·∫Ω d√πng **CustomResourceDefinition**, ta s·∫Ω vi·∫øt CustomResourceDefinition v√† ƒë·ªãnh nghƒ©a nh·ªØng gi√° tr·ªã custom resource c·ªßa ta trong ƒë√≥. Sau ƒë√≥ ta s·∫Ω t·∫°o CustomResourceDefinition n√†y, r·ªìi ta s·∫Ω vi·∫øt m·ªôt controller ƒë·ªÉ theo d√µi custom resource c·ªßa ta m·ªõi t·∫°o v√† th·ª±c hi·ªán h√†nh ƒë·ªông li√™n quan t·ªõi n√≥. V√≠ d·ª• ta c√≥ m·ªôt file website-crd.yaml v·ªõi config c·ªßa CustomResourceDefinition nh∆∞ sau:

```yaml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: websites.extensions.example.com # The full name of your custom object
spec:
  scope: Namespaced # You want Website resources to be namespaced.
  group: extensions.example.com # Define an API group and version of the Website resource.
  versions:
    - name: v1
      served: true
      storage: true
      schema:
        openAPIV3Schema:
          type: object
          properties:
            spec:
              type: object
              properties:
                gitRepo:
                  type: string
  names: # You need to specify the various forms of the custom object‚Äôs name.
    kind: Website
    singular: website
    plural: websites
```

·ªû file tr√™n tr∆∞·ªùng group v√† version s·∫Ω ƒë·ªãnh nghƒ©a API group v√† version c·ªßa resource n√†y tr√™n API server, gi√° tr·ªã c·ªßa hai tr∆∞·ªùng ƒë√≥ c·ªßa ta ·ªü tr√™n l√† `extensions.example.com` v√† `v1`, v·∫≠y n√™n khi ta khai b√°o resource, ch·ªó apiVersion ta s·∫Ω ch·ªâ ƒë·ªãnh l√† `extensions.example.com/v1`, tr∆∞·ªùng **names** ta s·∫Ω ƒë·ªãnh nghƒ©a kind v√† hai ƒë·ªông t·ª´ d·∫°ng s·ªë √≠t v√† s·ªë nhi·ªÅu c·ªßa custom resource, v·ªõi gi√° tr·ªã tr√™n th√¨ ta s·∫Ω th·ª±c hi·ªán c√¢u l·ªánh `kubectl get website` ƒë·ªÉ list t·∫•t c·∫£ c√°c Website resource. Ta t·∫°o CustomResourceDefinition tr√™n:

```
$ kubectl apply -f website-crd.yaml
customresourcedefinition.apiextensions.k8s.io/websites.extensions.example.com created
```

B√¢y gi·ªù th√¨ ta ƒë√£ ƒë·ªãnh nghƒ©a ƒë∆∞·ª£c custom resource c·ªßa ta tr√™n API server, ƒë·ªÉ t·∫°o resource n√†y, ta t·∫°o m·ªôt file t√™n l√† website.yaml v·ªõi config nh∆∞ sau:

```yaml
apiVersion: extensions.example.com/v1
kind: Website
metadata:
  name: kubia
spec:
  gitRepo: https://github.com/luksa/kubia-website-example.git
```

```
$ kubectl apply -f website.yaml
website.extensions.example.com/kubia created
```

Oke, v·∫≠y l√† ta ƒë√£ ƒë∆∞·ª£c custom resource, ƒë·ªÉ t∆∞∆°ng t√°c v·ªõi n√≥ th√¨ ta c≈©ng d√πng nh·ªØng c√¢u l·ªánh t∆∞∆°ng t√°c nh∆∞ c√°c resource b√¨nh th∆∞·ªùng kh√°c:

```
$ kubectl get website
NAME    AGE
kubia   71s

$ kubectl delete website kubia
website.extensions.example.com "kubia" deleted
```

V·∫≠y l√† custom resource c·ªßa ta ƒë√£ ch·∫°y th√†nh c√¥ng, nh∆∞ng m√† n√≥ s·∫Ω kh√¥ng c√≥ h√†nh ƒë·ªông g√¨ c·∫£, ƒë·ªÉ resource n√†y c√≥ th·ªÉ s·ª≠ d·ª•ng th·ª±c t·∫ø ƒë∆∞·ª£c, ta c·∫ßn t·∫°o m·ªôt controller cho n√≥. Ta s·∫Ω mu·ªën Website resource c·ªßa ta h√†nh ƒë·ªông nh∆∞ sau, ta s·∫Ω ƒë·ªãnh nghƒ©a Website resource v·ªõi ƒë∆∞·ªùng d·∫´n t·ªõi gitlab c·ªßa static website ta c·∫ßn deploy, sau ƒë√≥ ta s·∫Ω t·∫°o Website resource, controller c·ªßa ta s·∫Ω theo d√µi v√† ph√°t hi·ªán c√≥ Website resource m·ªõi ƒë∆∞·ª£c t·∫°o, n√≥ s·∫Ω t·∫°o ra m·ªôt resource Deployment ƒë·ªÉ deploy Pod m√† ch·∫°y static website, sau ƒë√≥ n√≥ s·∫Ω t·∫°o m·ªôt service m√† expose traffic c·ªßa website cho client.

![image.png](https://images.viblo.asia/7adc6411-05e2-48ca-a563-f74958808b4c.png)

Ta t·∫°o m·ªôt controller website-controller.yaml v·ªõi config nh∆∞ sau:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: website-controller
spec:
  replicas: 1
  selector:
    matchLabels:
      app: website-controller
  template:
    metadata:
      name: website-controller
      labels:
        app: website-controller
    spec:
      serviceAccountName: website-controller
      containers:
        - name: main
          image: luksa/website-controller
        - name: proxy
          image: luksa/kubectl-proxy:1.6.2
```

```
$ kubectl create serviceaccount website-controller
serviceaccount/website-controller created

$ kubectl create clusterrolebinding website-controller --clusterrole=cluster-admin --serviceaccount=default:website-controller
clusterrolebinding.rbac.authorization.k8s.io/website-controller created

$ kubectl apply -f website-controller.yaml
deployment.apps/website-controller created
```

Ho·∫°t ƒë·ªông c·ªßa container website-controller c≈©ng gi·ªëng v·ªõi configmap watch controller ta ƒë√£ vi·∫øt ·ªü tr√™n.

![image.png](https://images.viblo.asia/dd7a83fd-5138-493d-8934-38eeb6224122.png)

N·∫øu c√°c b·∫°n mu·ªën xem code th√¨ xem ·ªü github repo n√†y https://github.com/luksa/k8s-website-controller. Gi·ªù ta s·∫Ω t·∫°o Website resource l·∫°i ƒë·ªÉ xem n√≥ ho·∫°t ƒë·ªông:

```
$ kubectl apply -f website.yaml
website.extensions.example.com/kubia created

$ kubectl get website
NAME    AGE
kubia   15s

$ kubectl get deploy,svc,po
NAME                       DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE
deploy/kubia-website       1        1        1           1          4s
deploy/website-controller  1        1        1           1          5m

NAME               CLUSTER-IP    EXTERNAL-IP  PORT(S)       AGE
svc/kubernetes     10.96.0.1     <none>       443/TCP       38d
svc/kubia-website  10.101.48.23  <nodes>      80:32589/TCP  4s

NAME                                    READY  STATUS   RESTARTS  AGE
po/kubia-website-1029415133-rs715       2/2    Running  0         4s
po/website-controller-1571685839-qzmg6  2/2    Running  1         5m
```

Ok, v·∫≠y l√† custom resource v√† controller c·ªßa ta ƒë√£ ho·∫°t ƒë·ªông ch√≠nh x√°c. Thay v√¨ ph·∫£i t·∫°o Deployment v√† Service ri√™ng t·ª´ng c√°i, th√¨ ta ch·ªâ c·∫ßn ƒë·ªãnh nghƒ©a m·ªôt CRD, tuy l√∫c ƒë·∫ßu l√†m c√°i n√†y th√¨ kh√≥ nh∆∞ng v·ªÅ sau th√¨ c√¥ng vi·ªác c·ªßa ta s·∫Ω d·ªÖ d√†ng h∆°n nhi·ªÅu üòÅ.

C√°c c√¥ng vi·ªác DevOps h·∫•p d·∫´n ƒëang ch·ªù c√°c b·∫°n apply ·ªü DevOps VN - [Tuy·ªÉn d·ª•ng DevOps](https://devopsvn.tech/tuyen-dung-devops)

## K·∫øt lu·∫≠n
V·∫≠y l√† ta ƒë√£ t√¨m hi·ªÉu xong v·ªÅ custom controller v√† custom resource, s·ª≠ d·ª•ng ch√∫ng khi b·∫°n mu·ªën t·∫°o resource c·ªßa ri√™ng m√¨nh m√† ph·ª•c v·ª• cho m·ªôt m·ª•c ƒë√≠ch c·ª• th·ªÉ n√†o ƒë√≥ c·ªßa d·ª± √°n. N·∫øu c√≥ th·∫Øc m·∫Øc ho·∫∑c c·∫ßn gi·∫£i th√≠ch r√µ th√™m ch·ªó n√†o th√¨ c√°c b·∫°n c√≥ th·ªÉ h·ªèi d∆∞·ªõi ph·∫ßn comment. ƒê√¢y c√≥ l·∫Ω l√† b√†i cu·ªëi c√πng c·ªßa series n√†y, mong g·∫∑p c√°c b·∫°n ·ªü series kh√°c nh√© üòÑ.

## M·ª•c t√¨m ki·∫øm ƒë·ªìng ƒë·ªôi

![](https://images.viblo.asia/17647fc7-67d1-44a8-aae1-a8a1f2266351.jpg)

Hi·ªán t·∫°i th√¨ c√¥ng ty b√™n m√¨nh, l√† Ho√†ng Ph√∫c International, v·ªõi h∆°n 30 nƒÉm kinh nghi·ªám trong lƒ©nh v·ª±c th·ªùi trang. V√† s·ªü h·ªØu trang th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ v·ªÅ th·ªùi trang l·ªõn nh·∫•t Vi·ªát Nam. Team c√¥ng ngh·ªá c·ªßa HPI ƒëang t√¨m ki·∫øm ƒë·ªìng ƒë·ªôi cho c√°c v·ªã tr√≠ nh∆∞:
+ Senior Backend Engineer (Java, Go). Link JD: https://tuyendung.hoang-phuc.com/job/senior-backend-engineer-1022
+ Senior Front-end Engineer (VueJS). https://tuyendung.hoang-phuc.com/job/senior-frontend-engineer-1021
+ Junior Backend Engineer (Java, Go). https://tuyendung.hoang-phuc.com/job/junior-backend-engineer-1067
+ Junior Front-end Engineer (VueJS). https://tuyendung.hoang-phuc.com/careers/job/1068
+ App (Flutter). https://tuyendung.hoang-phuc.com/job/mobile-app-engineer-flutter-1239
+ Senior Data Engineer. https://tuyendung.hoang-phuc.com/job/seniorjunior-data-engineer-1221
+ Manual QC. https://tuyendung.hoang-phuc.com/job/seniorjunior-manual-qc-1039

V·ªõi m·ª•c ti√™u trong v√≤ng 5 nƒÉm t·ªõi v·ªÅ m·∫£ng c√¥ng ngh·ªá l√†:
+ S·∫Ω c√≥ trang web n·∫±m trong top 10 trang web nhanh nh·∫•t VN v·ªõi 20 tri·ªáu l∆∞·ª£t truy c·∫≠p m·ªói th√°ng.
+ 5 tri·ªáu loyal customers v√† c√≥ h∆°n 10 tri·ªáu transactions m·ªói nƒÉm.

Team ƒëang x√¢y d·ª±ng m·ªôt h·ªá th·ªëng r·∫•t l·ªõn v·ªõi r·∫•t nhi·ªÅu v·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt, v√† s·∫Ω c√≥ r·∫•t nhi·ªÅu b√†i to√°n th√∫ v·ªã cho c√°c b·∫°n. N·∫øu c√°c b·∫°n c√≥ h·ª©ng th√∫ trong vi·ªác x√¢y d·ª±ng m·ªôt h·ªá th·ªëng l·ªõn, linh ho·∫°t, d·ªÖ d√†ng m·ªü r·ªông, v√† performance cao v·ªõi ki·∫øn tr√∫c microservices th√¨ h√£y tham gia v·ªõi t·ª•i m√¨nh.

N·∫øu c√°c b·∫°n quan t√¢m h√£y g·ª≠i CV ·ªü trong trang tuy·ªÉn d·ª•ng c·ªßa Ho√†ng Ph√∫c International ho·∫∑c qua email c·ªßa m√¨nh nha `hmquan08011996@gmail.com`. C·∫£m ∆°n c√°c b·∫°n ƒë√£ ƒë·ªçc.